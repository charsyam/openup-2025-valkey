### Starting server for test 
88273:M 03 May 2025 23:04:18.818 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
88273:M 03 May 2025 23:04:18.820 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
88273:M 03 May 2025 23:04:18.820 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=88273, just started
88273:M 03 May 2025 23:04:18.820 * Configuration loaded
88273:M 03 May 2025 23:04:18.820 * Increased maximum number of open files to 10032 (it was originally set to 256).
88273:M 03 May 2025 23:04:18.820 * monotonic clock: POSIX clock_gettime
88273:M 03 May 2025 23:04:18.820 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 22621
 |###|   .+###############+.   |###|    PID: 88273                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

88273:M 03 May 2025 23:04:18.822 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
88273:M 03 May 2025 23:04:18.822 * No cluster configuration found, I'm 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9
88273:M 03 May 2025 23:04:18.827 * Server initialized
88273:M 03 May 2025 23:04:18.827 * Ready to accept connections tcp
88273:M 03 May 2025 23:04:18.827 * Ready to accept connections unix
88273:M 03 May 2025 23:04:18.942 - Accepted 127.0.0.1:59781
88273:M 03 May 2025 23:04:18.942 - Client closed connection id=2 addr=127.0.0.1:59781 laddr=127.0.0.1:22621 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
88273:M 03 May 2025 23:04:18.949 - Accepted 127.0.0.1:59783
88273:M 03 May 2025 23:04:19.094 # Missing implement of connection type tls
88273:M 03 May 2025 23:04:19.171 - Accepting cluster node connection from 127.0.0.1:59793
88273:M 03 May 2025 23:04:19.171 * IP address for this node updated to 127.0.0.1
88273:M 03 May 2025 23:04:19.274 - Accepting cluster node connection from 127.0.0.1:59808
88273:M 03 May 2025 23:04:19.292 - Accepting cluster node connection from 127.0.0.1:59813
88273:M 03 May 2025 23:04:19.292 * Successfully completed handshake with 829dc125be5e6bed85216fa78b484311a004c590 ()
88273:M 03 May 2025 23:04:19.292 * configEpoch collision with node 829dc125be5e6bed85216fa78b484311a004c590 (). configEpoch set to 1
88273:M 03 May 2025 23:04:19.303 * configEpoch collision with node 829dc125be5e6bed85216fa78b484311a004c590 (). configEpoch set to 2
88273:M 03 May 2025 23:04:19.352 - Accepting cluster node connection from 127.0.0.1:59824
88273:M 03 May 2025 23:04:19.369 - Accepting cluster node connection from 127.0.0.1:59828
88273:M 03 May 2025 23:04:19.374 * Successfully completed handshake with f848f8f2426110f2aa02d85bc35109efb050ee1c ()
88273:M 03 May 2025 23:04:19.384 * configEpoch collision with node 33dca58967ea807f71054db92c9bae8edb838d1a (). configEpoch set to 4
88273:M 03 May 2025 23:04:19.385 - Accepting cluster node connection from 127.0.0.1:59831
88273:M 03 May 2025 23:04:19.404 * configEpoch collision with node 9bef15b514b96cb4317017ff68ef58f60226bd1e (). configEpoch set to 5
88273:M 03 May 2025 23:04:19.489 - Handshake: we already know node 33dca58967ea807f71054db92c9bae8edb838d1a (), updating the address if needed.
88273:M 03 May 2025 23:04:19.590 - Accepting cluster node connection from 127.0.0.1:59851
88273:M 03 May 2025 23:04:20.356 * Node 9bef15b514b96cb4317017ff68ef58f60226bd1e () is no longer primary of shard 5d248352c80d71d4de724058d94e52d31c560130; removed all 0 slot(s) it used to own
88273:M 03 May 2025 23:04:20.356 * Node 9bef15b514b96cb4317017ff68ef58f60226bd1e () is now part of shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
88273:M 03 May 2025 23:04:20.356 * Node 9bef15b514b96cb4317017ff68ef58f60226bd1e () is now a replica of node 3343572579e378b54df1fb6850be8be76dd46e6a () in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
88273:M 03 May 2025 23:04:20.356 * Node c9185f683876252cbd80739f3a7e87a75c65090b () is no longer primary of shard a276c42d034322ac91d4a3be93243a40c26a9e39; removed all 0 slot(s) it used to own
88273:M 03 May 2025 23:04:20.356 * Node c9185f683876252cbd80739f3a7e87a75c65090b () is now part of shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
88273:M 03 May 2025 23:04:20.356 * Node c9185f683876252cbd80739f3a7e87a75c65090b () is now a replica of node 3343572579e378b54df1fb6850be8be76dd46e6a () in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
88273:M 03 May 2025 23:04:20.357 - Accepted 127.0.0.1:59891
88273:M 03 May 2025 23:04:20.357 * Node 829dc125be5e6bed85216fa78b484311a004c590 () is no longer primary of shard d38b636bcfdfe2e0852878f99c6af0c6c58309b1; removed all 0 slot(s) it used to own
88273:M 03 May 2025 23:04:20.357 * Node 829dc125be5e6bed85216fa78b484311a004c590 () is now part of shard 8028c9ca458f8215491dd1a9694897a34d78f998
88273:M 03 May 2025 23:04:20.357 * Node 829dc125be5e6bed85216fa78b484311a004c590 () is now a replica of node 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 () in shard 8028c9ca458f8215491dd1a9694897a34d78f998
88273:M 03 May 2025 23:04:20.358 * Node f848f8f2426110f2aa02d85bc35109efb050ee1c () is no longer primary of shard 79bbcf1834b8414fc6b9bc6ccee1db0d26f47001; removed all 0 slot(s) it used to own
88273:M 03 May 2025 23:04:20.358 * Node f848f8f2426110f2aa02d85bc35109efb050ee1c () is now part of shard 882eb57d01abe0fa09cac5f80857f74f4bbb4591
88273:M 03 May 2025 23:04:20.358 * Node f848f8f2426110f2aa02d85bc35109efb050ee1c () is now a replica of node 33dca58967ea807f71054db92c9bae8edb838d1a () in shard 882eb57d01abe0fa09cac5f80857f74f4bbb4591
88273:M 03 May 2025 23:04:20.358 * Replica 127.0.0.1:22618 asks for synchronization
88273:M 03 May 2025 23:04:20.358 * Full resync requested by replica 127.0.0.1:22618
88273:M 03 May 2025 23:04:20.358 * Replication backlog created, my new replication IDs are '3563a26d9c6254c13b40a1d2ddfd3c60a60635eb' and '0000000000000000000000000000000000000000'
88273:M 03 May 2025 23:04:20.358 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
88273:M 03 May 2025 23:04:20.358 * Background RDB transfer started by pid 88513 to pipe through parent process
88513:C 03 May 2025 23:04:20.359 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
88273:M 03 May 2025 23:04:20.361 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
88273:M 03 May 2025 23:04:20.361 # DEBUG LOG: ========== I am primary 1 ==========
88273:M 03 May 2025 23:04:20.367 * Background RDB transfer terminated with success
88273:M 03 May 2025 23:04:20.367 * Streamed RDB transfer with replica 127.0.0.1:22618 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
88273:M 03 May 2025 23:04:20.368 * Synchronization with replica 127.0.0.1:22618 succeeded
88273:M 03 May 2025 23:04:20.854 * Cluster state changed: ok
### Starting test Cluster is up in tests/unit/cluster/failover2.tcl
### Starting test Cluster is writable in tests/unit/cluster/failover2.tcl
88273:M 03 May 2025 23:04:30.180 - Accepted 127.0.0.1:60504
88273:M 03 May 2025 23:04:30.222 - Client closed connection id=40 addr=127.0.0.1:60504 laddr=127.0.0.1:22621 fd=28 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=2471 tot-net-out=1082 tot-cmds=62
### Starting test Killing one primary node in tests/unit/cluster/failover2.tcl
### Starting test Wait for failover in tests/unit/cluster/failover2.tcl
88273:M 03 May 2025 23:04:33.987 - DB 0: 31 keys (0 volatile) in 217 slots HT.
88273:M 03 May 2025 23:04:35.907 * Node 33dca58967ea807f71054db92c9bae8edb838d1a () reported node 3343572579e378b54df1fb6850be8be76dd46e6a () as not reachable.
88273:M 03 May 2025 23:04:35.907 * Marking node 3343572579e378b54df1fb6850be8be76dd46e6a () as failing (quorum reached).
88273:M 03 May 2025 23:04:35.907 # Cluster state changed: fail
88273:M 03 May 2025 23:04:35.907 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
88273:M 03 May 2025 23:04:36.625 * Failover auth granted to 9bef15b514b96cb4317017ff68ef58f60226bd1e () for epoch 7
### Starting test Killing the new primary node in tests/unit/cluster/failover2.tcl
88273:M 03 May 2025 23:04:36.687 * Node 9bef15b514b96cb4317017ff68ef58f60226bd1e () reported node 3343572579e378b54df1fb6850be8be76dd46e6a () as not reachable.
88273:M 03 May 2025 23:04:36.689 * Cluster state changed: ok
88273:M 03 May 2025 23:04:36.717 * Node c9185f683876252cbd80739f3a7e87a75c65090b () is now a replica of node 9bef15b514b96cb4317017ff68ef58f60226bd1e () in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
### Starting test Cluster should eventually be up again in tests/unit/cluster/failover2.tcl
### Starting test wait for new failover in tests/unit/cluster/failover2.tcl
88273:M 03 May 2025 23:04:39.039 - DB 0: 31 keys (0 volatile) in 217 slots HT.
88273:M 03 May 2025 23:04:42.984 * FAIL message received from c9185f683876252cbd80739f3a7e87a75c65090b () about 9bef15b514b96cb4317017ff68ef58f60226bd1e ()
88273:M 03 May 2025 23:04:42.984 # Cluster state changed: fail
88273:M 03 May 2025 23:04:42.984 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
88273:M 03 May 2025 23:04:43.115 * Node 33dca58967ea807f71054db92c9bae8edb838d1a () reported node 9bef15b514b96cb4317017ff68ef58f60226bd1e () as not reachable.
88273:M 03 May 2025 23:04:43.821 * Failover auth granted to c9185f683876252cbd80739f3a7e87a75c65090b () for epoch 8
### Starting test Restarting the previously killed primary nodes in tests/unit/cluster/failover2.tcl
88273:M 03 May 2025 23:04:43.845 * Node c9185f683876252cbd80739f3a7e87a75c65090b () reported node 9bef15b514b96cb4317017ff68ef58f60226bd1e () as not reachable.
88273:M 03 May 2025 23:04:43.846 * Node c9185f683876252cbd80739f3a7e87a75c65090b () reported node 3343572579e378b54df1fb6850be8be76dd46e6a () as not reachable.
88273:M 03 May 2025 23:04:43.849 * Cluster state changed: ok
### Starting test Make sure there is no failover timeout in tests/unit/cluster/failover2.tcl
88273:M 03 May 2025 23:04:43.866 - Node 3343572579e378b54df1fb6850be8be76dd46e6a has old slots configuration, sending an UPDATE message about c9185f683876252cbd80739f3a7e87a75c65090b
88273:M 03 May 2025 23:04:43.872 - Node 9bef15b514b96cb4317017ff68ef58f60226bd1e has old slots configuration, sending an UPDATE message about c9185f683876252cbd80739f3a7e87a75c65090b
88273:M 03 May 2025 23:04:43.877 * Clear FAIL state for node 3343572579e378b54df1fb6850be8be76dd46e6a (): primary without slots is reachable again.
88273:M 03 May 2025 23:04:43.877 * A failover occurred in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf; node 3343572579e378b54df1fb6850be8be76dd46e6a () failed over to node 9bef15b514b96cb4317017ff68ef58f60226bd1e () with a config epoch of 7
88273:M 03 May 2025 23:04:43.877 * Node 3343572579e378b54df1fb6850be8be76dd46e6a () is now a replica of node 9bef15b514b96cb4317017ff68ef58f60226bd1e () in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
88273:M 03 May 2025 23:04:43.887 * Clear FAIL state for node 9bef15b514b96cb4317017ff68ef58f60226bd1e (): primary without slots is reachable again.
88273:M 03 May 2025 23:04:43.887 * A failover occurred in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf; node 9bef15b514b96cb4317017ff68ef58f60226bd1e () failed over to node c9185f683876252cbd80739f3a7e87a75c65090b () with a config epoch of 8
88273:M 03 May 2025 23:04:43.887 * Node 9bef15b514b96cb4317017ff68ef58f60226bd1e () is now a replica of node c9185f683876252cbd80739f3a7e87a75c65090b () in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
### Starting test Check for memory leaks (pid 88302) in tests/unit/cluster/failover2.tcl
88273:M 03 May 2025 23:04:44.094 - DB 0: 31 keys (0 volatile) in 217 slots HT.
88273:M 03 May 2025 23:04:44.094 * Node c9185f683876252cbd80739f3a7e87a75c65090b () reported node 9bef15b514b96cb4317017ff68ef58f60226bd1e () is back online.
88273:M 03 May 2025 23:04:44.094 * Node c9185f683876252cbd80739f3a7e87a75c65090b () reported node 3343572579e378b54df1fb6850be8be76dd46e6a () is back online.
88273:M 03 May 2025 23:04:44.094 * Node 33dca58967ea807f71054db92c9bae8edb838d1a () reported node 3343572579e378b54df1fb6850be8be76dd46e6a () is back online.
88273:M 03 May 2025 23:04:44.094 * Node 33dca58967ea807f71054db92c9bae8edb838d1a () reported node 9bef15b514b96cb4317017ff68ef58f60226bd1e () is back online.
88273:M 03 May 2025 23:04:45.812 - Client closed connection id=3 addr=127.0.0.1:59783 laddr=127.0.0.1:22621 fd=14 name= age=27 idle=9 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|info user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=2228 tot-net-out=68354 tot-cmds=76
88273:M 03 May 2025 23:04:45.813 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88273:M 03 May 2025 23:04:45.913 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88273:M 03 May 2025 23:04:46.014 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88273:M 03 May 2025 23:04:46.875 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88273:signal-handler (1746281086) Received SIGTERM scheduling shutdown...
88273:M 03 May 2025 23:04:46.976 * User requested shutdown...
88273:M 03 May 2025 23:04:46.976 * 1 of 1 replicas are in sync when shutting down.
88273:M 03 May 2025 23:04:46.976 * Removing the pid file.
88273:M 03 May 2025 23:04:46.976 * Saving the cluster configuration file before exiting.
88273:M 03 May 2025 23:04:46.982 * Removing the unix socket file.
88273:M 03 May 2025 23:04:46.982 # Valkey is now ready to exit, bye bye...
