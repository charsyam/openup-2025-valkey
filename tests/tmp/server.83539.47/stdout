### Starting server for test 
96810:M 03 May 2025 23:05:24.892 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
96810:M 03 May 2025 23:05:24.897 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
96810:M 03 May 2025 23:05:24.907 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=96810, just started
96810:M 03 May 2025 23:05:24.913 * Configuration loaded
96810:M 03 May 2025 23:05:24.916 * Increased maximum number of open files to 10032 (it was originally set to 256).
96810:M 03 May 2025 23:05:24.919 * monotonic clock: POSIX clock_gettime
96810:M 03 May 2025 23:05:24.920 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 28134
 |###|   .+###############+.   |###|    PID: 96810                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

96810:M 03 May 2025 23:05:24.940 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
96810:M 03 May 2025 23:05:24.953 * No cluster configuration found, I'm c2c6ca43fa4c24228277739956fea1b7c183d841
96810:M 03 May 2025 23:05:25.034 * Server initialized
96810:M 03 May 2025 23:05:25.043 * Ready to accept connections tcp
96810:M 03 May 2025 23:05:25.046 * Ready to accept connections unix
96810:M 03 May 2025 23:05:25.111 - Accepted 127.0.0.1:54351
96810:M 03 May 2025 23:05:25.127 - Client closed connection id=2 addr=127.0.0.1:54351 laddr=127.0.0.1:28134 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
96810:M 03 May 2025 23:05:25.164 - Accepted 127.0.0.1:54371
96810:M 03 May 2025 23:05:25.820 - Accepting cluster node connection from 127.0.0.1:54866
96810:M 03 May 2025 23:05:25.823 * IP address for this node updated to 127.0.0.1
96810:M 03 May 2025 23:05:26.021 * configEpoch collision with node de13e24339d4ff7acc1955a3ee606a3d19d76a45 (). configEpoch set to 2
96810:M 03 May 2025 23:05:26.030 - Accepting cluster node connection from 127.0.0.1:54994
96810:M 03 May 2025 23:05:26.079 - Accepting cluster node connection from 127.0.0.1:55021
96810:M 03 May 2025 23:05:26.106 - Accepting cluster node connection from 127.0.0.1:55052
96810:M 03 May 2025 23:05:26.210 - Accepting cluster node connection from 127.0.0.1:55081
96810:M 03 May 2025 23:05:26.213 - Accepting cluster node connection from 127.0.0.1:55082
96810:M 03 May 2025 23:05:26.219 # Missing implement of connection type tls
96810:M 03 May 2025 23:05:26.338 * Node 3d3a9aaa923ca77543710ff8b4a617c35c610fe1 () is no longer primary of shard 7c00b3d168f90a4a199626d3f7a1772268c8c996; removed all 0 slot(s) it used to own
96810:M 03 May 2025 23:05:26.338 * Node 3d3a9aaa923ca77543710ff8b4a617c35c610fe1 () is now part of shard 84c62b06411891110d35dee733ca3e288cdbd695
96810:M 03 May 2025 23:05:26.338 * Node 3d3a9aaa923ca77543710ff8b4a617c35c610fe1 () is now a replica of node de13e24339d4ff7acc1955a3ee606a3d19d76a45 () in shard 84c62b06411891110d35dee733ca3e288cdbd695
96810:M 03 May 2025 23:05:26.338 * Node 2c8e9b9ace519470139431052e08a1eb6fdae92b () is no longer primary of shard 8ad5aa8ae62d12018c3725e4796d80dc2f479380; removed all 0 slot(s) it used to own
96810:M 03 May 2025 23:05:26.338 * Node 2c8e9b9ace519470139431052e08a1eb6fdae92b () is now part of shard 84c62b06411891110d35dee733ca3e288cdbd695
96810:M 03 May 2025 23:05:26.338 * Node 2c8e9b9ace519470139431052e08a1eb6fdae92b () is now a replica of node de13e24339d4ff7acc1955a3ee606a3d19d76a45 () in shard 84c62b06411891110d35dee733ca3e288cdbd695
96810:M 03 May 2025 23:05:26.345 * Node a457adc1f12967e01636eebc7be42e1f1c6a5161 () is no longer primary of shard 8d2f10fdbeec748f5cd732cb467c198b35d51499; removed all 0 slot(s) it used to own
96810:M 03 May 2025 23:05:26.348 * Node a457adc1f12967e01636eebc7be42e1f1c6a5161 () is now part of shard 0f8c2ef8a8a4c6a45a4898c66dcc1edee626bdfd
96810:M 03 May 2025 23:05:26.362 * Node a457adc1f12967e01636eebc7be42e1f1c6a5161 () is now a replica of node 4c8f7204763471d1b43a2021a9e3b0e972c77b93 () in shard 0f8c2ef8a8a4c6a45a4898c66dcc1edee626bdfd
96810:M 03 May 2025 23:05:26.390 - Accepted 127.0.0.1:55205
96810:M 03 May 2025 23:05:26.393 * Node 82218a66383f364fb8b5ad2e45a1926d58d091e5 () is no longer primary of shard 4997817dc7ccddab078b67f876d51a145ed86931; removed all 0 slot(s) it used to own
96810:M 03 May 2025 23:05:26.393 * Node 82218a66383f364fb8b5ad2e45a1926d58d091e5 () is now part of shard 12ecf07cb98495b494daaec988f483de09ffbff0
96810:M 03 May 2025 23:05:26.393 * Node 82218a66383f364fb8b5ad2e45a1926d58d091e5 () is now a replica of node c2c6ca43fa4c24228277739956fea1b7c183d841 () in shard 12ecf07cb98495b494daaec988f483de09ffbff0
96810:M 03 May 2025 23:05:26.394 * Replica 127.0.0.1:28131 asks for synchronization
96810:M 03 May 2025 23:05:26.394 * Full resync requested by replica 127.0.0.1:28131
96810:M 03 May 2025 23:05:26.394 * Replication backlog created, my new replication IDs are '632de4c65fe7c0d1d788de079765b0b1f848dc08' and '0000000000000000000000000000000000000000'
96810:M 03 May 2025 23:05:26.394 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
96810:M 03 May 2025 23:05:26.396 * Background RDB transfer started by pid 96965 to pipe through parent process
96965:C 03 May 2025 23:05:26.396 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
96810:M 03 May 2025 23:05:26.397 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
96810:M 03 May 2025 23:05:26.400 # DEBUG LOG: ========== I am primary 2 ==========
96810:M 03 May 2025 23:05:26.403 * Background RDB transfer terminated with success
96810:M 03 May 2025 23:05:26.403 * Streamed RDB transfer with replica 127.0.0.1:28131 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
96810:M 03 May 2025 23:05:26.403 * Synchronization with replica 127.0.0.1:28131 succeeded
96810:M 03 May 2025 23:05:27.083 * Cluster state changed: ok
### Starting test auto-failover-on-shutdown hands over primaryship to a fully sync'd replica - shutdown - shutdown-timeout: 0 in tests/unit/cluster/auto-failover-on-shutdown.tcl
96810:M 03 May 2025 23:05:37.021 * Failover auth granted to 2c8e9b9ace519470139431052e08a1eb6fdae92b () for epoch 7
96810:M 03 May 2025 23:05:37.100 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
### Starting test Unable to find a replica to perform an auto failover - shutdown in tests/unit/cluster/auto-failover-on-shutdown.tcl
96810:M 03 May 2025 23:05:37.114 * Node 3d3a9aaa923ca77543710ff8b4a617c35c610fe1 () is now a replica of node 2c8e9b9ace519470139431052e08a1eb6fdae92b () in shard 84c62b06411891110d35dee733ca3e288cdbd695
96810:M 03 May 2025 23:05:37.201 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:37.203 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
### Starting test Check for memory leaks (pid 96841) in tests/unit/cluster/auto-failover-on-shutdown.tcl
96810:M 03 May 2025 23:05:37.302 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:37.304 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
96810:M 03 May 2025 23:05:37.403 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:37.405 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
96810:M 03 May 2025 23:05:37.504 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:37.505 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
96810:M 03 May 2025 23:05:37.605 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:37.606 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
96810:M 03 May 2025 23:05:37.705 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:37.706 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
96810:M 03 May 2025 23:05:37.805 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:37.806 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
96810:M 03 May 2025 23:05:37.906 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:37.909 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
96810:M 03 May 2025 23:05:38.006 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:38.006 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
96810:M 03 May 2025 23:05:38.106 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:38.112 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
96810:M 03 May 2025 23:05:38.164 - Client closed connection id=3 addr=127.0.0.1:54371 laddr=127.0.0.1:28134 fd=14 name= age=13 idle=2 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=604 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|info user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=294 tot-net-out=4551 tot-cmds=8
96810:M 03 May 2025 23:05:38.207 - Connection with Node 4c8f7204763471d1b43a2021a9e3b0e972c77b93 at 127.0.0.1:38135 failed: Connection refused
96810:M 03 May 2025 23:05:38.210 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:38.210 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
96810:M 03 May 2025 23:05:38.905 - Connection with Node 4c8f7204763471d1b43a2021a9e3b0e972c77b93 at 127.0.0.1:38135 failed: Connection refused
96810:M 03 May 2025 23:05:38.907 - Connection with Node de13e24339d4ff7acc1955a3ee606a3d19d76a45 at 127.0.0.1:38136 failed: Connection refused
96810:M 03 May 2025 23:05:38.912 - Connection with Node 2c8e9b9ace519470139431052e08a1eb6fdae92b at 127.0.0.1:38130 failed: Connection refused
96810:signal-handler (1746281138) Received SIGTERM scheduling shutdown...
96810:M 03 May 2025 23:05:39.005 * User requested shutdown...
96810:M 03 May 2025 23:05:39.006 * 1 of 1 replicas are in sync when shutting down.
96810:M 03 May 2025 23:05:39.008 * Removing the pid file.
96810:M 03 May 2025 23:05:39.012 * Saving the cluster configuration file before exiting.
96810:M 03 May 2025 23:05:39.025 * Removing the unix socket file.
96810:M 03 May 2025 23:05:39.025 # Valkey is now ready to exit, bye bye...
