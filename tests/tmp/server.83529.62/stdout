### Starting server for test 
96718:M 03 May 2025 23:05:23.900 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
96718:M 03 May 2025 23:05:23.908 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
96718:M 03 May 2025 23:05:23.918 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=96718, just started
96718:M 03 May 2025 23:05:23.924 * Configuration loaded
96718:M 03 May 2025 23:05:23.927 * Increased maximum number of open files to 10032 (it was originally set to 256).
96718:M 03 May 2025 23:05:23.929 * monotonic clock: POSIX clock_gettime
96718:M 03 May 2025 23:05:23.930 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 23141
 |###|   .+###############+.   |###|    PID: 96718                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

96718:M 03 May 2025 23:05:23.943 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
96718:M 03 May 2025 23:05:23.972 * No cluster configuration found, I'm e82c99ffd9bb93f7c175caeb66dd2e02715490a3
96718:M 03 May 2025 23:05:24.104 * Server initialized
96718:M 03 May 2025 23:05:24.106 * Ready to accept connections tcp
96718:M 03 May 2025 23:05:24.110 * Ready to accept connections unix
96718:M 03 May 2025 23:05:24.142 - Accepted 127.0.0.1:53634
96718:M 03 May 2025 23:05:24.157 - Client closed connection id=2 addr=127.0.0.1:53634 laddr=127.0.0.1:23141 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=7 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
96718:M 03 May 2025 23:05:24.194 - Accepted 127.0.0.1:53698
96718:M 03 May 2025 23:05:25.337 - Accepting cluster node connection from 127.0.0.1:54489
96718:M 03 May 2025 23:05:25.343 * IP address for this node updated to 127.0.0.1
96718:M 03 May 2025 23:05:25.464 - Accepting cluster node connection from 127.0.0.1:54608
96718:M 03 May 2025 23:05:25.522 * Successfully completed handshake with 9d0ff4e112df42adf2d237496778dd53367591dd ()
96718:M 03 May 2025 23:05:25.537 - Accepting cluster node connection from 127.0.0.1:54662
96718:M 03 May 2025 23:05:25.628 - Accepting cluster node connection from 127.0.0.1:54722
96718:M 03 May 2025 23:05:25.628 - Accepting cluster node connection from 127.0.0.1:54732
96718:M 03 May 2025 23:05:25.644 - Accepting cluster node connection from 127.0.0.1:54743
96718:M 03 May 2025 23:05:25.714 * Successfully completed handshake with 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 ()
96718:M 03 May 2025 23:05:25.717 - Accepting cluster node connection from 127.0.0.1:54800
96718:M 03 May 2025 23:05:25.914 # Missing implement of connection type tls
96718:M 03 May 2025 23:05:25.925 * Node 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () is no longer primary of shard 2133c642a69cdd26c7f8a87b3df596640acf7724; removed all 0 slot(s) it used to own
96718:M 03 May 2025 23:05:25.925 * Node 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () is now part of shard 3c0f2d12e009cf7a3fdc026cd704db747342c2e0
96718:M 03 May 2025 23:05:25.928 * Node 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () is now a replica of node 139b8b617769bcf955027b35f67766fd204d74a7 () in shard 3c0f2d12e009cf7a3fdc026cd704db747342c2e0
96718:M 03 May 2025 23:05:25.935 * Node cb908827d84879b0fc4ea509db18193e9bf19aef () is no longer primary of shard d1ac0228cb7988986b3227e69191418398022f31; removed all 0 slot(s) it used to own
96718:M 03 May 2025 23:05:25.936 * Node cb908827d84879b0fc4ea509db18193e9bf19aef () is now part of shard 68f90d2ed82ce2be406370dbbbd387e97255d06a
96718:M 03 May 2025 23:05:25.940 * Node cb908827d84879b0fc4ea509db18193e9bf19aef () is now a replica of node 9d0ff4e112df42adf2d237496778dd53367591dd () in shard 68f90d2ed82ce2be406370dbbbd387e97255d06a
96718:M 03 May 2025 23:05:25.981 - Accepted 127.0.0.1:54971
96718:M 03 May 2025 23:05:26.003 * Node e3df85ca7382ee5044e82b8abb48e6a1b6cf0a17 () is no longer primary of shard 09d007f303aa946879e422391e13d670f874b7a8; removed all 0 slot(s) it used to own
96718:M 03 May 2025 23:05:26.004 * Node e3df85ca7382ee5044e82b8abb48e6a1b6cf0a17 () is now part of shard 51a89e686d5e76a2a71b7b3f08d38cc493d84d2c
96718:M 03 May 2025 23:05:26.004 * Node e3df85ca7382ee5044e82b8abb48e6a1b6cf0a17 () is now a replica of node e82c99ffd9bb93f7c175caeb66dd2e02715490a3 () in shard 51a89e686d5e76a2a71b7b3f08d38cc493d84d2c
96718:M 03 May 2025 23:05:26.009 * Replica 127.0.0.1:23137 asks for synchronization
96718:M 03 May 2025 23:05:26.011 * Full resync requested by replica 127.0.0.1:23137
96718:M 03 May 2025 23:05:26.013 * Replication backlog created, my new replication IDs are '861745757f5eaa4f127e3d73a218d87af046d1ee' and '0000000000000000000000000000000000000000'
96718:M 03 May 2025 23:05:26.013 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
96718:M 03 May 2025 23:05:26.015 * Background RDB transfer started by pid 96928 to pipe through parent process
96718:M 03 May 2025 23:05:26.015 * Node 2e358ba80d831dcbc9894e9a5d65a38d6fa75409 () is no longer primary of shard e0b8fd84212a878f7d11275a1c24464b7d4869c6; removed all 0 slot(s) it used to own
96718:M 03 May 2025 23:05:26.015 * Node 2e358ba80d831dcbc9894e9a5d65a38d6fa75409 () is now part of shard 1100b3f5187b33ced2be7cc1567d5a2ccdb23c30
96718:M 03 May 2025 23:05:26.015 * Node 2e358ba80d831dcbc9894e9a5d65a38d6fa75409 () is now a replica of node 754eaa6d4212c4c22df909e2b18845ed54848e4e () in shard 1100b3f5187b33ced2be7cc1567d5a2ccdb23c30
96928:C 03 May 2025 23:05:26.015 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
96718:M 03 May 2025 23:05:26.016 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
96718:M 03 May 2025 23:05:26.020 # DEBUG LOG: ========== I am primary 2 ==========
96718:M 03 May 2025 23:05:26.020 * Background RDB transfer terminated with success
96718:M 03 May 2025 23:05:26.020 * Streamed RDB transfer with replica 127.0.0.1:23137 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
96718:M 03 May 2025 23:05:26.020 * Synchronization with replica 127.0.0.1:23137 succeeded
96718:M 03 May 2025 23:05:26.178 * Cluster state changed: ok
### Starting test Migrated replica reports zero repl offset and rank, and fails to win election - sigstop in tests/unit/cluster/replica-migration.tcl
96718:M 03 May 2025 23:05:36.391 - Accepted 127.0.0.1:56619
96718:M 03 May 2025 23:05:36.407 * Slot 0 is migrated from node 754eaa6d4212c4c22df909e2b18845ed54848e4e () in shard 1100b3f5187b33ced2be7cc1567d5a2ccdb23c30 to node 139b8b617769bcf955027b35f67766fd204d74a7 () in shard 3c0f2d12e009cf7a3fdc026cd704db747342c2e0.
96718:M 03 May 2025 23:05:36.469 * Node 754eaa6d4212c4c22df909e2b18845ed54848e4e () is no longer primary of shard 1100b3f5187b33ced2be7cc1567d5a2ccdb23c30; removed all 0 slot(s) it used to own
96718:M 03 May 2025 23:05:36.471 * Node 754eaa6d4212c4c22df909e2b18845ed54848e4e () is now part of shard 3c0f2d12e009cf7a3fdc026cd704db747342c2e0
96718:M 03 May 2025 23:05:36.474 * Node 754eaa6d4212c4c22df909e2b18845ed54848e4e () is now a replica of node 139b8b617769bcf955027b35f67766fd204d74a7 () in shard 3c0f2d12e009cf7a3fdc026cd704db747342c2e0
96718:M 03 May 2025 23:05:36.478 * Assigning slot 0 to node 139b8b617769bcf955027b35f67766fd204d74a7 () in shard 3c0f2d12e009cf7a3fdc026cd704db747342c2e0
96718:M 03 May 2025 23:05:36.478 - Client closed connection id=7 addr=127.0.0.1:56619 laddr=127.0.0.1:23141 fd=30 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=cluster|setslot user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=150 tot-net-out=1979 tot-cmds=4
96718:M 03 May 2025 23:05:37.519 * Node 139b8b617769bcf955027b35f67766fd204d74a7 () reported node 2e358ba80d831dcbc9894e9a5d65a38d6fa75409 () as not reachable.
96718:M 03 May 2025 23:05:37.552 * FAIL message received from 9d0ff4e112df42adf2d237496778dd53367591dd () about 2e358ba80d831dcbc9894e9a5d65a38d6fa75409 ()
96718:M 03 May 2025 23:05:37.689 * Node 9d0ff4e112df42adf2d237496778dd53367591dd () reported node 2e358ba80d831dcbc9894e9a5d65a38d6fa75409 () as not reachable.
96718:M 03 May 2025 23:05:46.461 * Node 2e358ba80d831dcbc9894e9a5d65a38d6fa75409 () is now a replica of node 139b8b617769bcf955027b35f67766fd204d74a7 () in shard 3c0f2d12e009cf7a3fdc026cd704db747342c2e0
96718:M 03 May 2025 23:05:46.469 * Clear FAIL state for node 2e358ba80d831dcbc9894e9a5d65a38d6fa75409 (): replica is reachable again.
96718:M 03 May 2025 23:05:46.563 - Accepting cluster node connection from 127.0.0.1:58059
96718:M 03 May 2025 23:05:46.661 * Node 9d0ff4e112df42adf2d237496778dd53367591dd () reported node 2e358ba80d831dcbc9894e9a5d65a38d6fa75409 () is back online.
96718:M 03 May 2025 23:05:47.769 * Node 9d0ff4e112df42adf2d237496778dd53367591dd () reported node 139b8b617769bcf955027b35f67766fd204d74a7 () as not reachable.
96718:M 03 May 2025 23:05:47.771 * Marking node 139b8b617769bcf955027b35f67766fd204d74a7 () as failing (quorum reached).
96718:M 03 May 2025 23:05:47.775 # Cluster state changed: fail
96718:M 03 May 2025 23:05:47.778 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
96718:M 03 May 2025 23:05:48.610 * Failover auth granted to 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () for epoch 9
96718:M 03 May 2025 23:05:48.689 * Node 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () reported node 139b8b617769bcf955027b35f67766fd204d74a7 () as not reachable.
96718:M 03 May 2025 23:05:48.694 * Cluster state changed: ok
96718:M 03 May 2025 23:05:48.748 * Node 754eaa6d4212c4c22df909e2b18845ed54848e4e () is now a replica of node 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () in shard 3c0f2d12e009cf7a3fdc026cd704db747342c2e0
96718:M 03 May 2025 23:05:48.748 * Node 2e358ba80d831dcbc9894e9a5d65a38d6fa75409 () is now a replica of node 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () in shard 3c0f2d12e009cf7a3fdc026cd704db747342c2e0
96718:M 03 May 2025 23:05:48.932 - Node 139b8b617769bcf955027b35f67766fd204d74a7 has old slots configuration, sending an UPDATE message about 37d1c1b7274abecb8397f3ea3e9288b7c75855c0
96718:M 03 May 2025 23:05:48.946 * Clear FAIL state for node 139b8b617769bcf955027b35f67766fd204d74a7 (): primary without slots is reachable again.
96718:M 03 May 2025 23:05:48.946 * A failover occurred in shard 3c0f2d12e009cf7a3fdc026cd704db747342c2e0; node 139b8b617769bcf955027b35f67766fd204d74a7 () failed over to node 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () with a config epoch of 9
96718:M 03 May 2025 23:05:48.946 * Node 139b8b617769bcf955027b35f67766fd204d74a7 () is now a replica of node 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () in shard 3c0f2d12e009cf7a3fdc026cd704db747342c2e0
### Starting test Check for memory leaks (pid 96805) in tests/unit/cluster/replica-migration.tcl
96718:M 03 May 2025 23:05:49.081 * Node 9d0ff4e112df42adf2d237496778dd53367591dd () reported node 139b8b617769bcf955027b35f67766fd204d74a7 () is back online.
96718:M 03 May 2025 23:05:49.081 * Node 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () reported node 139b8b617769bcf955027b35f67766fd204d74a7 () is back online.
96718:M 03 May 2025 23:05:50.295 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
### Starting test Check for memory leaks (pid 96760) in tests/unit/cluster/replica-migration.tcl
96718:M 03 May 2025 23:05:50.396 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:50.497 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:50.598 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:50.698 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:50.799 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:50.901 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:51.001 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:51.102 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:51.203 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:51.304 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:51.328 * Node 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () reported node 139b8b617769bcf955027b35f67766fd204d74a7 () as not reachable.
96718:M 03 May 2025 23:05:51.340 * Marking node 139b8b617769bcf955027b35f67766fd204d74a7 () as failing (quorum reached).
96718:M 03 May 2025 23:05:51.405 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:51.506 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:51.576 - Client closed connection id=3 addr=127.0.0.1:53698 laddr=127.0.0.1:23141 fd=14 name= age=27 idle=16 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|info user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=295 tot-net-out=6365 tot-cmds=8
96718:M 03 May 2025 23:05:51.606 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:51.608 - Connection with Node 9d0ff4e112df42adf2d237496778dd53367591dd at 127.0.0.1:33142 failed: Connection refused
96718:M 03 May 2025 23:05:51.706 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:51.707 - Connection with Node 9d0ff4e112df42adf2d237496778dd53367591dd at 127.0.0.1:33142 failed: Connection refused
96718:M 03 May 2025 23:05:52.635 - Accepting cluster node connection from 127.0.0.1:60668
96718:M 03 May 2025 23:05:52.638 - Accepting cluster node connection from 127.0.0.1:60672
96718:M 03 May 2025 23:05:52.646 - Accepting cluster node connection from 127.0.0.1:60692
96718:M 03 May 2025 23:05:52.646 - Accepting cluster node connection from 127.0.0.1:60700
96718:M 03 May 2025 23:05:52.646 - Accepting cluster node connection from 127.0.0.1:60715
96718:M 03 May 2025 23:05:52.646 - Connection with Node 139b8b617769bcf955027b35f67766fd204d74a7 at 127.0.0.1:33143 failed: Connection refused
96718:M 03 May 2025 23:05:52.649 - Connection with Node 9d0ff4e112df42adf2d237496778dd53367591dd at 127.0.0.1:33142 failed: Connection refused
96718:M 03 May 2025 23:05:52.650 * Node 37d1c1b7274abecb8397f3ea3e9288b7c75855c0 () reported node 9d0ff4e112df42adf2d237496778dd53367591dd () as not reachable.
96718:M 03 May 2025 23:05:52.652 * Marking node 9d0ff4e112df42adf2d237496778dd53367591dd () as failing (quorum reached).
96718:M 03 May 2025 23:05:52.653 # Cluster state changed: fail
96718:M 03 May 2025 23:05:52.654 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
96718:signal-handler (1746281152) Received SIGTERM scheduling shutdown...
96718:M 03 May 2025 23:05:52.736 * User requested shutdown...
96718:M 03 May 2025 23:05:52.736 * 1 of 1 replicas are in sync when shutting down.
96718:M 03 May 2025 23:05:52.736 * Removing the pid file.
96718:M 03 May 2025 23:05:52.739 * Saving the cluster configuration file before exiting.
96718:M 03 May 2025 23:05:52.781 * Removing the unix socket file.
96718:M 03 May 2025 23:05:52.784 # Valkey is now ready to exit, bye bye...
