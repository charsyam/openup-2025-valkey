### Starting server for test 
89538:M 03 May 2025 23:04:28.047 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
89538:M 03 May 2025 23:04:28.047 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
89538:M 03 May 2025 23:04:28.047 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=89538, just started
89538:M 03 May 2025 23:04:28.047 * Configuration loaded
89538:M 03 May 2025 23:04:28.047 * Increased maximum number of open files to 10032 (it was originally set to 256).
89538:M 03 May 2025 23:04:28.047 * monotonic clock: POSIX clock_gettime
89538:M 03 May 2025 23:04:28.047 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 25637
 |###|   .+###############+.   |###|    PID: 89538                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

89538:M 03 May 2025 23:04:28.047 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
89538:M 03 May 2025 23:04:28.047 * No cluster configuration found, I'm d4a541da210418dce028e0274341a55c129fc825
89538:M 03 May 2025 23:04:28.052 * Server initialized
89538:M 03 May 2025 23:04:28.052 * Ready to accept connections tcp
89538:M 03 May 2025 23:04:28.052 * Ready to accept connections unix
89538:M 03 May 2025 23:04:28.171 - Accepted 127.0.0.1:60347
89538:M 03 May 2025 23:04:28.171 - Client closed connection id=2 addr=127.0.0.1:60347 laddr=127.0.0.1:25637 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
89538:M 03 May 2025 23:04:28.179 - Accepted 127.0.0.1:60348
89538:M 03 May 2025 23:04:28.179 * Cluster meet 127.0.0.1:25636 (user request from 'id=3 addr=127.0.0.1:60348 laddr=127.0.0.1:25637 fd=14 name= user=default lib-name= lib-ver=').
89538:M 03 May 2025 23:04:28.179 * Cluster meet 127.0.0.1:25635 (user request from 'id=3 addr=127.0.0.1:60348 laddr=127.0.0.1:25637 fd=14 name= user=default lib-name= lib-ver=').
89538:M 03 May 2025 23:04:28.180 * Cluster meet 127.0.0.1:25634 (user request from 'id=3 addr=127.0.0.1:60348 laddr=127.0.0.1:25637 fd=14 name= user=default lib-name= lib-ver=').
89538:M 03 May 2025 23:04:28.180 * Cluster meet 127.0.0.1:25633 (user request from 'id=3 addr=127.0.0.1:60348 laddr=127.0.0.1:25637 fd=14 name= user=default lib-name= lib-ver=').
89538:M 03 May 2025 23:04:28.180 * Cluster meet 127.0.0.1:25632 (user request from 'id=3 addr=127.0.0.1:60348 laddr=127.0.0.1:25637 fd=14 name= user=default lib-name= lib-ver=').
89538:M 03 May 2025 23:04:28.180 * Cluster meet 127.0.0.1:25631 (user request from 'id=3 addr=127.0.0.1:60348 laddr=127.0.0.1:25637 fd=14 name= user=default lib-name= lib-ver=').
89538:M 03 May 2025 23:04:28.180 * Cluster meet 127.0.0.1:25630 (user request from 'id=3 addr=127.0.0.1:60348 laddr=127.0.0.1:25637 fd=14 name= user=default lib-name= lib-ver=').
89538:M 03 May 2025 23:04:28.180 * Cluster meet 127.0.0.1:25629 (user request from 'id=3 addr=127.0.0.1:60348 laddr=127.0.0.1:25637 fd=14 name= user=default lib-name= lib-ver=').
89538:M 03 May 2025 23:04:28.180 * Cluster meet 127.0.0.1:25628 (user request from 'id=3 addr=127.0.0.1:60348 laddr=127.0.0.1:25637 fd=14 name= user=default lib-name= lib-ver=').
89538:M 03 May 2025 23:04:28.185 # Missing implement of connection type tls
89538:M 03 May 2025 23:04:28.263 - Accepting cluster node connection from 127.0.0.1:60358
89538:M 03 May 2025 23:04:28.263 * IP address for this node updated to 127.0.0.1
89538:M 03 May 2025 23:04:28.263 * Successfully completed handshake with b5d2cb99493e03b95f5b4ceef666b6c146b8483f ()
89538:M 03 May 2025 23:04:28.267 - Accepting cluster node connection from 127.0.0.1:60359
89538:M 03 May 2025 23:04:28.267 * Successfully completed handshake with 49a6b2e00b53bcbb34b88b4d5b256badd9c9bf73 ()
89538:M 03 May 2025 23:04:28.286 - Accepting cluster node connection from 127.0.0.1:60360
89538:M 03 May 2025 23:04:28.286 * Successfully completed handshake with 117e239bcf937f1a7fd42246b67e12a4580dbdf1 ()
89538:M 03 May 2025 23:04:28.294 - Accepting cluster node connection from 127.0.0.1:60361
89538:M 03 May 2025 23:04:28.294 * Successfully completed handshake with b783e43cd90a371c2a8bfb9381f7136b60cec8f3 ()
89538:M 03 May 2025 23:04:28.302 - Accepting cluster node connection from 127.0.0.1:60362
89538:M 03 May 2025 23:04:28.303 * Successfully completed handshake with e8f7d0ef9915c7d538829f6e3533c532bafa8a39 ()
89538:M 03 May 2025 23:04:28.303 * configEpoch collision with node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 (). configEpoch set to 1
89538:M 03 May 2025 23:04:28.317 - Accepting cluster node connection from 127.0.0.1:60363
89538:M 03 May 2025 23:04:28.320 - Accepting cluster node connection from 127.0.0.1:60364
89538:M 03 May 2025 23:04:28.320 * Successfully completed handshake with c9c069e00f372ad4e0c059a17b2fe3dd61352384 ()
89538:M 03 May 2025 23:04:28.324 * Successfully completed handshake with 3a80752b0eb90f9593f1ca7c29a1cc73b38435b7 ()
89538:M 03 May 2025 23:04:28.334 - Accepting cluster node connection from 127.0.0.1:60365
89538:M 03 May 2025 23:04:28.336 * Successfully completed handshake with 830ac93a68bd546bc68f0d28099d68dec5e610e3 ()
89538:M 03 May 2025 23:04:28.349 - Accepting cluster node connection from 127.0.0.1:60367
89538:M 03 May 2025 23:04:28.349 * Successfully completed handshake with 298cbb5912fa1c49173b389864ea1d9e8949d312 ()
89538:M 03 May 2025 23:04:28.970 - Accepted 127.0.0.1:60471
89538:M 03 May 2025 23:04:28.971 * Node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () is no longer primary of shard 9eb746c79cb1fc7bdec65de386ac6a3de8061dbb; removed all 0 slot(s) it used to own
89538:M 03 May 2025 23:04:28.971 * Node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () is now part of shard ce1ce2d40fc11540b4d4fbf433a95aba39ce96d0
89538:M 03 May 2025 23:04:28.971 * Node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () is now a replica of node d4a541da210418dce028e0274341a55c129fc825 () in shard ce1ce2d40fc11540b4d4fbf433a95aba39ce96d0
89538:M 03 May 2025 23:04:28.973 * Replica 127.0.0.1:25632 asks for synchronization
89538:M 03 May 2025 23:04:28.973 * Full resync requested by replica 127.0.0.1:25632
89538:M 03 May 2025 23:04:28.973 * Replication backlog created, my new replication IDs are '2b9a0b3258cf04417fc3f75cbb5f49b33c5dc6a6' and '0000000000000000000000000000000000000000'
89538:M 03 May 2025 23:04:28.973 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
89538:M 03 May 2025 23:04:28.973 * Background RDB transfer started by pid 89741 to pipe through parent process
89538:M 03 May 2025 23:04:28.974 * Node c9c069e00f372ad4e0c059a17b2fe3dd61352384 () is no longer primary of shard 49d1c37e6da3c41dc6095f8ed615dffa0215d0b5; removed all 0 slot(s) it used to own
89538:M 03 May 2025 23:04:28.974 * Node c9c069e00f372ad4e0c059a17b2fe3dd61352384 () is now part of shard e1de41ffd5b22c7cef240a4331f5b9c2bd1ec141
89538:M 03 May 2025 23:04:28.974 * Node c9c069e00f372ad4e0c059a17b2fe3dd61352384 () is now a replica of node b783e43cd90a371c2a8bfb9381f7136b60cec8f3 () in shard e1de41ffd5b22c7cef240a4331f5b9c2bd1ec141
89741:C 03 May 2025 23:04:28.974 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
89538:M 03 May 2025 23:04:28.975 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
89538:M 03 May 2025 23:04:28.976 * Node b5d2cb99493e03b95f5b4ceef666b6c146b8483f () is no longer primary of shard 18e491ac0ebbc1c9eda07c64fb7b5e3da97db16f; removed all 0 slot(s) it used to own
89538:M 03 May 2025 23:04:28.978 * Node b5d2cb99493e03b95f5b4ceef666b6c146b8483f () is now part of shard fb98a0ec1aacfb366246894eefaed2af2f7c4c4e
89538:M 03 May 2025 23:04:28.978 * Node b5d2cb99493e03b95f5b4ceef666b6c146b8483f () is now a replica of node 830ac93a68bd546bc68f0d28099d68dec5e610e3 () in shard fb98a0ec1aacfb366246894eefaed2af2f7c4c4e
89538:M 03 May 2025 23:04:28.979 * Background RDB transfer terminated with success
89538:M 03 May 2025 23:04:28.979 * Streamed RDB transfer with replica 127.0.0.1:25632 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
89538:M 03 May 2025 23:04:28.979 * Synchronization with replica 127.0.0.1:25632 succeeded
89538:M 03 May 2025 23:04:28.980 * Node 49a6b2e00b53bcbb34b88b4d5b256badd9c9bf73 () is no longer primary of shard 52aceec9bf4978473ecde4c43e0799720fa9483c; removed all 0 slot(s) it used to own
89538:M 03 May 2025 23:04:28.980 * Node 49a6b2e00b53bcbb34b88b4d5b256badd9c9bf73 () is now part of shard d60eefbdbbd13d383fe3ab08148a31ced81848f0
89538:M 03 May 2025 23:04:28.980 * Node 49a6b2e00b53bcbb34b88b4d5b256badd9c9bf73 () is now a replica of node 117e239bcf937f1a7fd42246b67e12a4580dbdf1 () in shard d60eefbdbbd13d383fe3ab08148a31ced81848f0
89538:M 03 May 2025 23:04:28.987 * Node 3a80752b0eb90f9593f1ca7c29a1cc73b38435b7 () is no longer primary of shard 34b9589abeb4712483c0fff534f6c42c6e0692e1; removed all 0 slot(s) it used to own
89538:M 03 May 2025 23:04:28.990 * Node 3a80752b0eb90f9593f1ca7c29a1cc73b38435b7 () is now part of shard 13401c2fb3be710e34a5d8b768c60923088230ef
89538:M 03 May 2025 23:04:28.995 * Node 3a80752b0eb90f9593f1ca7c29a1cc73b38435b7 () is now a replica of node 298cbb5912fa1c49173b389864ea1d9e8949d312 () in shard 13401c2fb3be710e34a5d8b768c60923088230ef
89538:M 03 May 2025 23:04:28.997 # DEBUG LOG: ========== I am primary 0 ==========
89538:M 03 May 2025 23:04:30.062 * Cluster state changed: ok
### Starting test Cluster is up in tests/unit/cluster/failover.tcl
### Starting test Cluster is writable in tests/unit/cluster/failover.tcl
89538:M 03 May 2025 23:04:38.560 - Accepted 127.0.0.1:62576
89538:M 03 May 2025 23:04:38.560 - Client closed connection id=13 addr=127.0.0.1:62576 laddr=127.0.0.1:25637 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=cluster|nodes user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=28 tot-net-out=1244 tot-cmds=1
89538:M 03 May 2025 23:04:38.560 - Accepted 127.0.0.1:62577
89538:M 03 May 2025 23:04:38.589 - Client closed connection id=14 addr=127.0.0.1:62577 laddr=127.0.0.1:25637 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=1831 tot-net-out=802 tot-cmds=46
### Starting test Instance #5 is a slave in tests/unit/cluster/failover.tcl
### Starting test Instance #5 synced with the master in tests/unit/cluster/failover.tcl
### Starting test Killing one master node in tests/unit/cluster/failover.tcl
### Starting test Wait for failover in tests/unit/cluster/failover.tcl
### Starting test Cluster should eventually be up again in tests/unit/cluster/failover.tcl
### Starting test Cluster is writable in tests/unit/cluster/failover.tcl
### Starting test Instance #5 is now a master in tests/unit/cluster/failover.tcl
### Starting test Restarting the previously killed master node in tests/unit/cluster/failover.tcl
89538:M 03 May 2025 23:04:43.026 - Accepting cluster node connection from 127.0.0.1:63171
89538:M 03 May 2025 23:04:43.026 - Accepting cluster node connection from 127.0.0.1:63172
89538:M 03 May 2025 23:04:43.026 - Accepting cluster node connection from 127.0.0.1:63173
89538:M 03 May 2025 23:04:43.026 - Accepting cluster node connection from 127.0.0.1:63174
89538:M 03 May 2025 23:04:43.026 - Accepting cluster node connection from 127.0.0.1:63195
### Starting test Instance #0 gets converted into a slave in tests/unit/cluster/failover.tcl
89538:M 03 May 2025 23:04:43.026 - Accepting cluster node connection from 127.0.0.1:63196
89538:M 03 May 2025 23:04:43.026 - Accepting cluster node connection from 127.0.0.1:63208
89538:M 03 May 2025 23:04:43.026 - Accepting cluster node connection from 127.0.0.1:63207
89538:M 03 May 2025 23:04:43.026 - Accepting cluster node connection from 127.0.0.1:63244
89538:M 03 May 2025 23:04:43.026 - Accepted 127.0.0.1:63959
89538:M 03 May 2025 23:04:43.026 - Client closed connection id=11 addr=127.0.0.1:60471 laddr=127.0.0.1:25637 fd=33 name= age=15 idle=0 flags=S capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=1 omem=16920 tot-mem=35352 events=r cmd=replconf user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=816 tot-net-out=1323 tot-cmds=21
89538:M 03 May 2025 23:04:43.026 * Connection with replica 127.0.0.1:25632 lost.
89538:M 03 May 2025 23:04:43.026 # Failover auth denied to e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () for epoch 10: its primary is up
89538:M 03 May 2025 23:04:43.026 * Configuration change detected. Reconfiguring myself as a replica of node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () in shard ce1ce2d40fc11540b4d4fbf433a95aba39ce96d0
89538:S 03 May 2025 23:04:43.026 * Before turning into a replica, using my own primary parameters to synthesize a cached primary: I may be able to synchronize with the new primary with just a partial transfer.
89538:S 03 May 2025 23:04:43.026 * Connecting to PRIMARY 127.0.0.1:25632
89538:S 03 May 2025 23:04:43.026 * PRIMARY <-> REPLICA sync started
89538:S 03 May 2025 23:04:43.027 - Client closed connection id=15 addr=127.0.0.1:63959 laddr=127.0.0.1:25637 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=NULL user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=0 tot-net-out=0 tot-cmds=0
89538:S 03 May 2025 23:04:43.032 * Non blocking connect for SYNC fired the event.
89538:S 03 May 2025 23:04:43.033 * Primary replied to PING, replication can continue...
89538:S 03 May 2025 23:04:43.033 * Trying a partial resynchronization (request 2b9a0b3258cf04417fc3f75cbb5f49b33c5dc6a6:1297).
89538:S 03 May 2025 23:04:43.033 * Successful partial resynchronization with primary.
89538:S 03 May 2025 23:04:43.033 * Primary replication ID changed to b1adb1e0fb0d3626f9651a45c928c76479862b61
89538:S 03 May 2025 23:04:43.033 * PRIMARY <-> REPLICA sync: Primary accepted a Partial Resynchronization.
89538:S 03 May 2025 23:04:43.042 - Client closed connection id=3 addr=127.0.0.1:60348 laddr=127.0.0.1:25637 fd=14 name= age=15 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=1024 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|slots user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=6078 tot-net-out=416117 tot-cmds=201
89538:signal-handler (1746281084) Received SIGTERM scheduling shutdown...
89538:S 03 May 2025 23:04:44.322 * User requested shutdown...
89538:S 03 May 2025 23:04:44.322 * Removing the pid file.
89538:S 03 May 2025 23:04:44.322 * Saving the cluster configuration file before exiting.
89538:S 03 May 2025 23:04:44.330 * Removing the unix socket file.
89538:S 03 May 2025 23:04:44.336 # Valkey is now ready to exit, bye bye...
