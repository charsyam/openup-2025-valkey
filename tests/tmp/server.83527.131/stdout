### Starting server for test 
12018:M 03 May 2025 23:07:56.593 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
12018:M 03 May 2025 23:07:56.593 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
12018:M 03 May 2025 23:07:56.593 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=12018, just started
12018:M 03 May 2025 23:07:56.593 * Configuration loaded
12018:M 03 May 2025 23:07:56.593 * Increased maximum number of open files to 10032 (it was originally set to 256).
12018:M 03 May 2025 23:07:56.593 * monotonic clock: POSIX clock_gettime
12018:M 03 May 2025 23:07:56.594 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 22176
 |###|   .+###############+.   |###|    PID: 12018                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

12018:M 03 May 2025 23:07:56.594 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
12018:M 03 May 2025 23:07:56.594 * No cluster configuration found, I'm 6f81b2cbab6093de36e66536aafb71fd2d7728d9
12018:M 03 May 2025 23:07:56.599 * Server initialized
12018:M 03 May 2025 23:07:56.599 * Ready to accept connections tcp
12018:M 03 May 2025 23:07:56.599 * Ready to accept connections unix
12018:M 03 May 2025 23:07:56.731 - Accepted 127.0.0.1:59479
12018:M 03 May 2025 23:07:56.732 - Client closed connection id=2 addr=127.0.0.1:59479 laddr=127.0.0.1:22176 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
12018:M 03 May 2025 23:07:56.747 - Accepted 127.0.0.1:59480
12018:M 03 May 2025 23:07:56.747 * Cluster meet 127.0.0.1:22175 (user request from 'id=3 addr=127.0.0.1:59480 laddr=127.0.0.1:22176 fd=14 name= user=default lib-name= lib-ver=').
12018:M 03 May 2025 23:07:56.747 * Cluster meet 127.0.0.1:22174 (user request from 'id=3 addr=127.0.0.1:59480 laddr=127.0.0.1:22176 fd=14 name= user=default lib-name= lib-ver=').
12018:M 03 May 2025 23:07:56.747 * Cluster meet 127.0.0.1:22173 (user request from 'id=3 addr=127.0.0.1:59480 laddr=127.0.0.1:22176 fd=14 name= user=default lib-name= lib-ver=').
12018:M 03 May 2025 23:07:56.751 # Missing implement of connection type tls
12018:M 03 May 2025 23:07:56.824 - Accepting cluster node connection from 127.0.0.1:59485
12018:M 03 May 2025 23:07:56.824 * IP address for this node updated to 127.0.0.1
12018:M 03 May 2025 23:07:56.824 * Successfully completed handshake with 8ff3785e0ff75ee6d71787198ab8cfd4a987a76c ()
12018:M 03 May 2025 23:07:56.824 * configEpoch collision with node 8ff3785e0ff75ee6d71787198ab8cfd4a987a76c (). configEpoch set to 1
12018:M 03 May 2025 23:07:56.841 - Accepting cluster node connection from 127.0.0.1:59487
12018:M 03 May 2025 23:07:56.841 * Successfully completed handshake with be61d9b3fcb528263b426c39329debea4bb47f02 ()
12018:M 03 May 2025 23:07:56.863 - Accepting cluster node connection from 127.0.0.1:59488
12018:M 03 May 2025 23:07:56.863 * Successfully completed handshake with 56feb27fa10f2da6b23a7de12d289d07167b0146 ()
12018:M 03 May 2025 23:07:57.955 - Accepted 127.0.0.1:59516
12018:M 03 May 2025 23:07:57.956 * Node 56feb27fa10f2da6b23a7de12d289d07167b0146 () is no longer primary of shard 1804ffd1b165df5b45e4a7ea9a4a83d84b4c6f15; removed all 0 slot(s) it used to own
12018:M 03 May 2025 23:07:57.956 * Node 56feb27fa10f2da6b23a7de12d289d07167b0146 () is now part of shard 0d5fa7fec298ed4adc30376f4db7d1c01d502091
12018:M 03 May 2025 23:07:57.956 * Node 56feb27fa10f2da6b23a7de12d289d07167b0146 () is now a replica of node 6f81b2cbab6093de36e66536aafb71fd2d7728d9 () in shard 0d5fa7fec298ed4adc30376f4db7d1c01d502091
12018:M 03 May 2025 23:07:57.957 # DEBUG LOG: ========== I am primary 0 ==========
12018:M 03 May 2025 23:07:57.957 * Replica 127.0.0.1:22173 asks for synchronization
12018:M 03 May 2025 23:07:57.957 * Full resync requested by replica 127.0.0.1:22173
12018:M 03 May 2025 23:07:57.957 * Replication backlog created, my new replication IDs are 'f60233a252297641527506126c75a7485c9d3ee8' and '0000000000000000000000000000000000000000'
12018:M 03 May 2025 23:07:57.957 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
12018:M 03 May 2025 23:07:57.959 * Background RDB transfer started by pid 12076 to pipe through parent process
12076:C 03 May 2025 23:07:57.959 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
12018:M 03 May 2025 23:07:57.959 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
12018:M 03 May 2025 23:07:57.964 * Background RDB transfer terminated with success
12018:M 03 May 2025 23:07:57.964 * Streamed RDB transfer with replica 127.0.0.1:22173 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
12018:M 03 May 2025 23:07:57.964 * Synchronization with replica 127.0.0.1:22173 succeeded
12018:M 03 May 2025 23:07:58.617 * Cluster state changed: ok
### Starting test Automatic failover vote is not limited by two times the node timeout - mixed failover in tests/unit/cluster/manual-failover.tcl
12018:M 03 May 2025 23:08:07.258 * Manual failover requested by replica 56feb27fa10f2da6b23a7de12d289d07167b0146 ().
12018:M 03 May 2025 23:08:07.259 * Failover auth granted to 56feb27fa10f2da6b23a7de12d289d07167b0146 () for epoch 4
12018:M 03 May 2025 23:08:07.279 - Client closed connection id=26 addr=127.0.0.1:59516 laddr=127.0.0.1:22176 fd=21 name= age=10 idle=0 flags=S capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=1 omem=16920 tot-mem=35352 events=r cmd=replconf user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=668 tot-net-out=41 tot-cmds=17
12018:M 03 May 2025 23:08:07.279 * Connection with replica 127.0.0.1:22173 lost.
12018:M 03 May 2025 23:08:07.288 * Configuration change detected. Reconfiguring myself as a replica of node 56feb27fa10f2da6b23a7de12d289d07167b0146 () in shard 0d5fa7fec298ed4adc30376f4db7d1c01d502091
12018:S 03 May 2025 23:08:07.288 * Before turning into a replica, using my own primary parameters to synthesize a cached primary: I may be able to synchronize with the new primary with just a partial transfer.
12018:S 03 May 2025 23:08:07.292 * Connecting to PRIMARY 127.0.0.1:22173
12018:S 03 May 2025 23:08:07.292 * PRIMARY <-> REPLICA sync started
12018:S 03 May 2025 23:08:07.305 * Non blocking connect for SYNC fired the event.
12018:S 03 May 2025 23:08:07.306 * Primary replied to PING, replication can continue...
12018:S 03 May 2025 23:08:07.309 * Trying a partial resynchronization (request f60233a252297641527506126c75a7485c9d3ee8:15).
12018:S 03 May 2025 23:08:07.310 * Successful partial resynchronization with primary.
12018:S 03 May 2025 23:08:07.310 * Primary replication ID changed to 2a8fd9816e4de5dd718a74bf923fcf94c16d9bd4
12018:S 03 May 2025 23:08:07.310 * PRIMARY <-> REPLICA sync: Primary accepted a Partial Resynchronization.
12018:S 03 May 2025 23:08:07.314 * Manual failover user request accepted (user request from 'id=3 addr=127.0.0.1:59480 laddr=127.0.0.1:22176 fd=14 name= user=default lib-name= lib-ver=').
12018:S 03 May 2025 23:08:07.315 * Received replication offset for paused primary manual failover: 14
12018:S 03 May 2025 23:08:07.315 * All primary replication stream processed, manual failover can start.
12018:S 03 May 2025 23:08:07.315 * Start of election delayed for 0 milliseconds (rank #0, primary rank #0, offset 14).
12018:S 03 May 2025 23:08:07.315 * Starting a failover election for epoch 5, node config epoch is 4
12018:S 03 May 2025 23:08:07.333 * Currently unable to failover: Waiting for votes, but majority still not reached.
12018:S 03 May 2025 23:08:07.333 * Needed quorum: 2. Number of votes received so far: 1
12018:S 03 May 2025 23:08:07.333 * Failover election won: I'm the new primary.
12018:S 03 May 2025 23:08:07.334 * configEpoch set to 5 after successful failover
12018:S 03 May 2025 23:08:07.334 * Setting myself to primary in shard 0d5fa7fec298ed4adc30376f4db7d1c01d502091 after failover; my old primary is 56feb27fa10f2da6b23a7de12d289d07167b0146 ()
12018:M 03 May 2025 23:08:07.334 * Connection with primary lost.
12018:M 03 May 2025 23:08:07.334 * Caching the disconnected primary state.
12018:M 03 May 2025 23:08:07.335 * Discarding previously cached primary state.
12018:M 03 May 2025 23:08:07.335 * Setting secondary replication ID to 2a8fd9816e4de5dd718a74bf923fcf94c16d9bd4, valid up to offset: 15. New replication ID is bccfacd02e4c820f71ed82ed2240c43fb111f220
12018:M 03 May 2025 23:08:07.342 - Accepted 127.0.0.1:59909
12018:M 03 May 2025 23:08:07.353 * A failover occurred in shard 0d5fa7fec298ed4adc30376f4db7d1c01d502091; node 56feb27fa10f2da6b23a7de12d289d07167b0146 () failed over to node 6f81b2cbab6093de36e66536aafb71fd2d7728d9 () with a config epoch of 5
12018:M 03 May 2025 23:08:07.355 * Node 56feb27fa10f2da6b23a7de12d289d07167b0146 () is now a replica of node 6f81b2cbab6093de36e66536aafb71fd2d7728d9 () in shard 0d5fa7fec298ed4adc30376f4db7d1c01d502091
12018:M 03 May 2025 23:08:07.356 * Replica 127.0.0.1:22173 asks for synchronization
12018:M 03 May 2025 23:08:07.356 * Partial resynchronization request from 127.0.0.1:22173 accepted. Sending 0 bytes of backlog starting from offset 15.
12018:signal-handler (1746281294) Received SIGTERM scheduling shutdown...
12018:M 03 May 2025 23:08:14.735 * User requested shutdown...
12018:M 03 May 2025 23:08:14.735 * Waiting for replicas before shutting down.
12018:M 03 May 2025 23:08:14.735 - Accepting cluster node connection from 127.0.0.1:60045
12018:M 03 May 2025 23:08:14.736 - Accepting cluster node connection from 127.0.0.1:60113
12018:M 03 May 2025 23:08:14.736 - Accepting cluster node connection from 127.0.0.1:60140
12018:M 03 May 2025 23:08:14.736 - Accepting cluster node connection from 127.0.0.1:60319
12018:M 03 May 2025 23:08:14.736 - Accepting cluster node connection from 127.0.0.1:60420
12018:M 03 May 2025 23:08:14.736 - Accepting cluster node connection from 127.0.0.1:60454
12018:M 03 May 2025 23:08:14.736 - Accepting cluster node connection from 127.0.0.1:60682
12018:M 03 May 2025 23:08:14.736 - Accepting cluster node connection from 127.0.0.1:60885
12018:M 03 May 2025 23:08:14.736 - Accepting cluster node connection from 127.0.0.1:60949
12018:M 03 May 2025 23:08:14.736 - Client closed connection id=3 addr=127.0.0.1:59480 laddr=127.0.0.1:22176 fd=14 name= age=18 idle=7 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=4096 rbp=0 obl=0 oll=0 omem=0 tot-mem=21504 events=r cmd=cluster|slots user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=6861 tot-net-out=223050 tot-cmds=235
12018:M 03 May 2025 23:08:14.736 - Reading from client: Connection reset by peer
12018:M 03 May 2025 23:08:14.736 * Connection with replica client id #32 lost.
12018:M 03 May 2025 23:08:14.736 * Configuration change detected. Reconfiguring myself as a replica of node 56feb27fa10f2da6b23a7de12d289d07167b0146 () in shard 0d5fa7fec298ed4adc30376f4db7d1c01d502091
12018:S 03 May 2025 23:08:14.736 * Before turning into a replica, using my own primary parameters to synthesize a cached primary: I may be able to synchronize with the new primary with just a partial transfer.
12018:S 03 May 2025 23:08:14.736 * Connecting to PRIMARY 127.0.0.1:22173
12018:S 03 May 2025 23:08:14.736 * PRIMARY <-> REPLICA sync started
12018:S 03 May 2025 23:08:14.741 * Non blocking connect for SYNC fired the event.
12018:S 03 May 2025 23:08:14.742 * Primary replied to PING, replication can continue...
12018:S 03 May 2025 23:08:14.742 * Trying a partial resynchronization (request bccfacd02e4c820f71ed82ed2240c43fb111f220:52).
12018:S 03 May 2025 23:08:14.742 * Full resync from primary: db1b62d0fbb772d8653478dbee83e4e898735ecd:14
12018:S 03 May 2025 23:08:14.744 * PRIMARY <-> REPLICA sync: receiving streamed RDB from primary with EOF to disk
12018:S 03 May 2025 23:08:14.748 * Discarding previously cached primary state.
12018:S 03 May 2025 23:08:14.748 * PRIMARY <-> REPLICA sync: Flushing old data
12018:S 03 May 2025 23:08:14.748 * PRIMARY <-> REPLICA sync: Loading DB in memory
12018:S 03 May 2025 23:08:14.748 * Loading RDB produced by Valkey version 255.255.255
12018:S 03 May 2025 23:08:14.748 * RDB age 0 seconds
12018:S 03 May 2025 23:08:14.748 * RDB memory usage when created 2.98 Mb
12018:S 03 May 2025 23:08:14.748 * Done loading RDB, keys loaded: 0, keys expired: 0.
12018:S 03 May 2025 23:08:14.748 * PRIMARY <-> REPLICA sync: Finished with success
12018:S 03 May 2025 23:08:14.836 * Removing the pid file.
12018:S 03 May 2025 23:08:14.836 * Saving the cluster configuration file before exiting.
12018:S 03 May 2025 23:08:14.842 * Removing the unix socket file.
12018:S 03 May 2025 23:08:14.842 # Valkey is now ready to exit, bye bye...
