### Starting server for test 
97137:M 03 May 2025 23:05:28.640 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
97137:M 03 May 2025 23:05:28.647 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
97137:M 03 May 2025 23:05:28.648 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=97137, just started
97137:M 03 May 2025 23:05:28.649 * Configuration loaded
97137:M 03 May 2025 23:05:28.650 * Increased maximum number of open files to 10032 (it was originally set to 256).
97137:M 03 May 2025 23:05:28.656 * monotonic clock: POSIX clock_gettime
97137:M 03 May 2025 23:05:28.657 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 25649
 |###|   .+###############+.   |###|    PID: 97137                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

97137:M 03 May 2025 23:05:28.657 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
97137:M 03 May 2025 23:05:28.657 * No cluster configuration found, I'm 940f25bab80d655fae5d2c00f7e5d053f18a0aa3
97137:M 03 May 2025 23:05:28.669 * Server initialized
97137:M 03 May 2025 23:05:28.669 * Ready to accept connections tcp
97137:M 03 May 2025 23:05:28.669 * Ready to accept connections unix
97137:M 03 May 2025 23:05:28.810 - Accepted 127.0.0.1:56035
97137:M 03 May 2025 23:05:28.814 - Client closed connection id=2 addr=127.0.0.1:56035 laddr=127.0.0.1:25649 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
97137:M 03 May 2025 23:05:28.825 - Accepted 127.0.0.1:56044
97137:M 03 May 2025 23:05:29.746 - Accepting cluster node connection from 127.0.0.1:56237
97137:M 03 May 2025 23:05:29.747 * IP address for this node updated to 127.0.0.1
97137:M 03 May 2025 23:05:29.977 - Accepting cluster node connection from 127.0.0.1:56285
97137:M 03 May 2025 23:05:29.980 - Accepting cluster node connection from 127.0.0.1:56287
97137:M 03 May 2025 23:05:30.009 # Missing implement of connection type tls
97137:M 03 May 2025 23:05:30.014 * configEpoch collision with node 9eb390e8ded52cf641b33887797c00ff53872c26 (). configEpoch set to 4
97137:M 03 May 2025 23:05:30.054 - Accepting cluster node connection from 127.0.0.1:56292
97137:M 03 May 2025 23:05:30.083 - Accepting cluster node connection from 127.0.0.1:56293
97137:S 03 May 2025 23:05:30.149 * Connecting to PRIMARY 127.0.0.1:25652
97137:S 03 May 2025 23:05:30.149 * PRIMARY <-> REPLICA sync started
97137:S 03 May 2025 23:05:30.149 * Cluster state changed: ok
97137:S 03 May 2025 23:05:30.149 * Non blocking connect for SYNC fired the event.
97137:S 03 May 2025 23:05:30.155 * Primary replied to PING, replication can continue...
97137:S 03 May 2025 23:05:30.159 * Partial resynchronization not possible (no cached primary)
97137:S 03 May 2025 23:05:30.159 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () is no longer primary of shard ec45c5094d9c5aa67b32f0a89ad6ef1885439f7f; removed all 0 slot(s) it used to own
97137:S 03 May 2025 23:05:30.159 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () is now part of shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853
97137:S 03 May 2025 23:05:30.159 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () is now a replica of node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853
97137:S 03 May 2025 23:05:30.161 * Full resync from primary: 169ebabccddec7bb73f1c42d6db8255a6eb79bca:0
97137:S 03 May 2025 23:05:30.166 * PRIMARY <-> REPLICA sync: receiving streamed RDB from primary with EOF to disk
97137:S 03 May 2025 23:05:30.170 * PRIMARY <-> REPLICA sync: Flushing old data
97137:S 03 May 2025 23:05:30.174 * PRIMARY <-> REPLICA sync: Loading DB in memory
97137:S 03 May 2025 23:05:30.179 * Loading RDB produced by Valkey version 255.255.255
97137:S 03 May 2025 23:05:30.188 * RDB age 0 seconds
97137:S 03 May 2025 23:05:30.195 * RDB memory usage when created 2.91 Mb
97137:S 03 May 2025 23:05:30.195 * Done loading RDB, keys loaded: 0, keys expired: 0.
97137:S 03 May 2025 23:05:30.195 * PRIMARY <-> REPLICA sync: Finished with success
97137:S 03 May 2025 23:05:30.195 * Node 3db47b5fc2b7f4cbe1582927946a84d5c923646e () is no longer primary of shard 18d4d063be1d57c64b124b0528cd553b3fed1068; removed all 0 slot(s) it used to own
97137:S 03 May 2025 23:05:30.195 * Node 3db47b5fc2b7f4cbe1582927946a84d5c923646e () is now part of shard 0618c300f6ba0c0f36756b1aa5de671e6ee48e93
97137:S 03 May 2025 23:05:30.195 * Node 3db47b5fc2b7f4cbe1582927946a84d5c923646e () is now a replica of node 9eb390e8ded52cf641b33887797c00ff53872c26 () in shard 0618c300f6ba0c0f36756b1aa5de671e6ee48e93
97137:S 03 May 2025 23:05:30.214 # DEBUG LOG: ========== I am replica 3 ==========
### Starting test Slot migration states are replicated in tests/unit/cluster/slot-migration.tcl
97137:S 03 May 2025 23:05:39.840 * Migrating slot 609 to node 6d062984222c6b8fea11f573fcb0ebcb21d117bb ()
### Starting test Migration target is auto-updated after failover in target shard in tests/unit/cluster/slot-migration.tcl
97137:S 03 May 2025 23:05:40.911 * NODE 6d062984222c6b8fea11f573fcb0ebcb21d117bb () possibly failing.
97137:S 03 May 2025 23:05:41.063 * FAIL message received from 13aa946ae073b283903d0b625ce1c86adb50c18e () about 6d062984222c6b8fea11f573fcb0ebcb21d117bb ()
97137:S 03 May 2025 23:05:41.063 * Node 13aa946ae073b283903d0b625ce1c86adb50c18e () reported node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () as not reachable.
97137:S 03 May 2025 23:05:41.063 # Cluster state changed: fail
97137:S 03 May 2025 23:05:41.063 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
97137:S 03 May 2025 23:05:41.140 * Node 9eb390e8ded52cf641b33887797c00ff53872c26 () reported node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () as not reachable.
97137:S 03 May 2025 23:05:42.073 * Failover occurred in migration target. Slot 609 is now being migrated to node 7784938381600c37ae962ee96f2a2eac0a305a61 () in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853.
97137:S 03 May 2025 23:05:42.073 * Cluster state changed: ok
97137:S 03 May 2025 23:05:42.122 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () reported node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () as not reachable.
97137:S 03 May 2025 23:05:42.869 - Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb has old slots configuration, sending an UPDATE message about 7784938381600c37ae962ee96f2a2eac0a305a61
97137:S 03 May 2025 23:05:42.890 * Clear FAIL state for node 6d062984222c6b8fea11f573fcb0ebcb21d117bb (): primary without slots is reachable again.
97137:S 03 May 2025 23:05:42.892 * A failover occurred in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853; node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () failed over to node 7784938381600c37ae962ee96f2a2eac0a305a61 () with a config epoch of 6
97137:S 03 May 2025 23:05:42.894 * Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () is now a replica of node 7784938381600c37ae962ee96f2a2eac0a305a61 () in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853
97137:S 03 May 2025 23:05:42.929 * Node 9eb390e8ded52cf641b33887797c00ff53872c26 () reported node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () is back online.
97137:S 03 May 2025 23:05:42.929 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () reported node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () is back online.
97137:S 03 May 2025 23:05:42.974 * Node 13aa946ae073b283903d0b625ce1c86adb50c18e () reported node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () is back online.
97137:S 03 May 2025 23:05:43.048 * Failover occurred in migration target. Slot 609 is now being migrated to node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853.
97137:S 03 May 2025 23:05:43.073 * A failover occurred in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853; node 7784938381600c37ae962ee96f2a2eac0a305a61 () failed over to node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () with a config epoch of 7
97137:S 03 May 2025 23:05:43.073 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () is now a replica of node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853
### Starting test Migration source is auto-updated after failover in source shard in tests/unit/cluster/slot-migration.tcl
97137:S 03 May 2025 23:05:43.838 - DB 0: 1 keys (0 volatile) in 7 slots HT.
97137:S 03 May 2025 23:05:44.245 * NODE 13aa946ae073b283903d0b625ce1c86adb50c18e () possibly failing.
97137:S 03 May 2025 23:05:44.381 * Node 9eb390e8ded52cf641b33887797c00ff53872c26 () reported node 13aa946ae073b283903d0b625ce1c86adb50c18e () as not reachable.
97137:S 03 May 2025 23:05:44.385 * Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () reported node 13aa946ae073b283903d0b625ce1c86adb50c18e () as not reachable.
97137:S 03 May 2025 23:05:44.397 * Marking node 13aa946ae073b283903d0b625ce1c86adb50c18e () as failing (quorum reached).
97137:S 03 May 2025 23:05:44.405 # Cluster state changed: fail
97137:S 03 May 2025 23:05:44.406 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
97137:S 03 May 2025 23:05:44.450 * Start of election delayed for 950 milliseconds (rank #0, primary rank #0, offset 212).
97137:S 03 May 2025 23:05:44.553 * Currently unable to failover: Waiting the delay before I can start a new failover.
97137:S 03 May 2025 23:05:45.056 * Currently unable to failover: Waiting the delay before I can start a new failover.
97137:S 03 May 2025 23:05:45.460 * Starting a failover election for epoch 8, node config epoch is 1
97137:S 03 May 2025 23:05:45.523 * Failover election won: I'm the new primary.
97137:S 03 May 2025 23:05:45.523 * configEpoch set to 8 after successful failover
97137:S 03 May 2025 23:05:45.523 * Setting myself to primary in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555 after failover; my old primary is 13aa946ae073b283903d0b625ce1c86adb50c18e ()
97137:M 03 May 2025 23:05:45.523 * Connection with primary lost.
97137:M 03 May 2025 23:05:45.523 * Caching the disconnected primary state.
97137:M 03 May 2025 23:05:45.523 * Discarding previously cached primary state.
97137:M 03 May 2025 23:05:45.523 * Setting secondary replication ID to 169ebabccddec7bb73f1c42d6db8255a6eb79bca, valid up to offset: 213. New replication ID is 4e0eada19d35228c629927ad4a1a2a67301d1422
97137:M 03 May 2025 23:05:45.523 * Cluster state changed: ok
97137:M 03 May 2025 23:05:46.184 - Node 13aa946ae073b283903d0b625ce1c86adb50c18e has old slots configuration, sending an UPDATE message about 940f25bab80d655fae5d2c00f7e5d053f18a0aa3
97137:M 03 May 2025 23:05:46.187 - Accepted 127.0.0.1:57917
97137:M 03 May 2025 23:05:46.193 * Clear FAIL state for node 13aa946ae073b283903d0b625ce1c86adb50c18e (): primary without slots is reachable again.
97137:M 03 May 2025 23:05:46.193 * A failover occurred in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555; node 13aa946ae073b283903d0b625ce1c86adb50c18e () failed over to node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () with a config epoch of 8
97137:M 03 May 2025 23:05:46.193 * Node 13aa946ae073b283903d0b625ce1c86adb50c18e () is now a replica of node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555
97137:M 03 May 2025 23:05:46.196 * Replica 127.0.0.1:25652 asks for synchronization
97137:M 03 May 2025 23:05:46.196 * Partial resynchronization request from 127.0.0.1:25652 accepted. Sending 0 bytes of backlog starting from offset 213.
97137:M 03 May 2025 23:05:46.201 * Node 9eb390e8ded52cf641b33887797c00ff53872c26 () reported node 13aa946ae073b283903d0b625ce1c86adb50c18e () is back online.
97137:M 03 May 2025 23:05:46.202 * Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () reported node 13aa946ae073b283903d0b625ce1c86adb50c18e () is back online.
97137:M 03 May 2025 23:05:46.314 * Manual failover requested by replica 13aa946ae073b283903d0b625ce1c86adb50c18e ().
97137:M 03 May 2025 23:05:46.314 * Failover auth granted to 13aa946ae073b283903d0b625ce1c86adb50c18e () for epoch 9
97137:M 03 May 2025 23:05:46.335 - Client closed connection id=10 addr=127.0.0.1:57917 laddr=127.0.0.1:25649 fd=25 name= age=0 idle=0 flags=S capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=0 obl=0 oll=1 omem=16920 tot-mem=50712 events=r cmd=psync user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=334 tot-net-out=27 tot-cmds=6
97137:M 03 May 2025 23:05:46.335 * Connection with replica 127.0.0.1:25652 lost.
97137:M 03 May 2025 23:05:46.344 * Configuration change detected. Reconfiguring myself as a replica of node 13aa946ae073b283903d0b625ce1c86adb50c18e () in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555
97137:S 03 May 2025 23:05:46.346 * Before turning into a replica, using my own primary parameters to synthesize a cached primary: I may be able to synchronize with the new primary with just a partial transfer.
97137:S 03 May 2025 23:05:46.349 * Connecting to PRIMARY 127.0.0.1:25652
97137:S 03 May 2025 23:05:46.356 * PRIMARY <-> REPLICA sync started
97137:S 03 May 2025 23:05:46.405 * Non blocking connect for SYNC fired the event.
97137:S 03 May 2025 23:05:46.406 * Primary replied to PING, replication can continue...
97137:S 03 May 2025 23:05:46.407 * Trying a partial resynchronization (request 4e0eada19d35228c629927ad4a1a2a67301d1422:213).
97137:S 03 May 2025 23:05:46.407 * Successful partial resynchronization with primary.
97137:S 03 May 2025 23:05:46.407 * Primary replication ID changed to cad40f6b6cfef867df1c266c776114578b046c64
97137:S 03 May 2025 23:05:46.407 * PRIMARY <-> REPLICA sync: Primary accepted a Partial Resynchronization.
### Starting test Replica redirects key access in migrating slots in tests/unit/cluster/slot-migration.tcl
### Starting test Replica of migrating node returns ASK redirect after READONLY in tests/unit/cluster/slot-migration.tcl
### Starting test Replica of migrating node returns TRYAGAIN after READONLY in tests/unit/cluster/slot-migration.tcl
### Starting test Replica of importing node returns TRYAGAIN after READONLY and ASKING in tests/unit/cluster/slot-migration.tcl
### Starting test New replica inherits migrating slot in tests/unit/cluster/slot-migration.tcl
97137:S 03 May 2025 23:05:46.490 * Cluster reset (user request from 'id=3 addr=127.0.0.1:56044 laddr=127.0.0.1:25649 fd=14 name= user=default lib-name= lib-ver=').
97137:M 03 May 2025 23:05:46.490 * Connection with primary lost.
97137:M 03 May 2025 23:05:46.490 * Caching the disconnected primary state.
97137:M 03 May 2025 23:05:46.490 * Discarding previously cached primary state.
97137:M 03 May 2025 23:05:46.490 * Setting secondary replication ID to cad40f6b6cfef867df1c266c776114578b046c64, valid up to offset: 213. New replication ID is 107877839f710cca35d06dae7ad9f365f1e3e65c
97137:M 03 May 2025 23:05:46.491 # Cluster state changed: fail
97137:M 03 May 2025 23:05:46.491 # Cluster is currently down: I am part of a minority partition.
97137:M 03 May 2025 23:05:46.499 * Cluster meet 127.0.0.1:25652 (user request from 'id=3 addr=127.0.0.1:56044 laddr=127.0.0.1:25649 fd=14 name= user=default lib-name= lib-ver=').
97137:M 03 May 2025 23:05:46.504 - Accepting cluster node connection from 127.0.0.1:58031
97137:M 03 May 2025 23:05:46.506 - Accepting cluster node connection from 127.0.0.1:58032
97137:M 03 May 2025 23:05:46.534 - Accepting cluster node connection from 127.0.0.1:58046
97137:M 03 May 2025 23:05:46.535 - Accepting cluster node connection from 127.0.0.1:58047
97137:M 03 May 2025 23:05:46.574 - Accepting cluster node connection from 127.0.0.1:58068
97137:M 03 May 2025 23:05:46.580 * Successfully completed handshake with 13aa946ae073b283903d0b625ce1c86adb50c18e ()
97137:M 03 May 2025 23:05:46.584 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
97137:M 03 May 2025 23:05:46.612 * Node 3db47b5fc2b7f4cbe1582927946a84d5c923646e () is now a replica of node 9eb390e8ded52cf641b33887797c00ff53872c26 () in shard a8f24420ce195a825a7009a0834112760d52a7b1
97137:M 03 May 2025 23:05:46.716 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () is now a replica of node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853
97137:S 03 May 2025 23:05:46.748 * Connecting to PRIMARY 127.0.0.1:25652
97137:S 03 May 2025 23:05:46.750 * PRIMARY <-> REPLICA sync started
97137:S 03 May 2025 23:05:46.754 * Cluster state changed: ok
97137:S 03 May 2025 23:05:46.782 * Non blocking connect for SYNC fired the event.
97137:S 03 May 2025 23:05:46.792 * Primary replied to PING, replication can continue...
97137:S 03 May 2025 23:05:46.792 * Partial resynchronization not possible (no cached primary)
97137:S 03 May 2025 23:05:46.792 * Full resync from primary: cad40f6b6cfef867df1c266c776114578b046c64:212
97137:S 03 May 2025 23:05:46.793 * PRIMARY <-> REPLICA sync: receiving streamed RDB from primary with EOF to disk
97137:S 03 May 2025 23:05:46.795 * PRIMARY <-> REPLICA sync: Flushing old data
97137:S 03 May 2025 23:05:46.795 * PRIMARY <-> REPLICA sync: Loading DB in memory
97137:S 03 May 2025 23:05:46.795 * Loading RDB produced by Valkey version 255.255.255
97137:S 03 May 2025 23:05:46.795 * RDB age 0 seconds
97137:S 03 May 2025 23:05:46.795 * RDB memory usage when created 3.16 Mb
97137:S 03 May 2025 23:05:46.795 * Done loading RDB, keys loaded: 1, keys expired: 0.
97137:S 03 May 2025 23:05:46.795 * PRIMARY <-> REPLICA sync: Finished with success
### Starting test New replica inherits importing slot in tests/unit/cluster/slot-migration.tcl
97137:S 03 May 2025 23:05:47.139 - Accepting cluster node connection from 127.0.0.1:58265
97137:S 03 May 2025 23:05:47.214 * A failover occurred in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853; node 7784938381600c37ae962ee96f2a2eac0a305a61 () failed over to node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () with a config epoch of 7
97137:S 03 May 2025 23:05:47.217 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () is now a replica of node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853
### Starting test Check for memory leaks (pid 97246) in tests/unit/cluster/slot-migration.tcl
97137:S 03 May 2025 23:05:48.574 - Client closed connection id=17 addr=127.0.0.1:25652 laddr=127.0.0.1:58140 fd=25 name= age=2 idle=2 flags=M capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=36 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=NULL user=(superuser) redir=-1 resp=2 lib-name= lib-ver= tot-net-in=0 tot-net-out=108 tot-cmds=0
97137:S 03 May 2025 23:05:48.574 * Connection with primary lost.
97137:S 03 May 2025 23:05:48.574 * Caching the disconnected primary state.
97137:S 03 May 2025 23:05:48.574 * Reconnecting to PRIMARY 127.0.0.1:25652
97137:S 03 May 2025 23:05:48.575 * PRIMARY <-> REPLICA sync started
97137:S 03 May 2025 23:05:48.575 # Error condition on socket for SYNC: Connection refused
97137:S 03 May 2025 23:05:48.632 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
### Starting test Check for memory leaks (pid 97221) in tests/unit/cluster/slot-migration.tcl
97137:S 03 May 2025 23:05:48.732 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:48.834 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:48.936 - DB 0: 1 keys (0 volatile) in 7 slots HT.
97137:S 03 May 2025 23:05:48.936 * Connecting to PRIMARY 127.0.0.1:25652
97137:S 03 May 2025 23:05:48.936 * PRIMARY <-> REPLICA sync started
97137:S 03 May 2025 23:05:48.936 # Error condition on socket for SYNC: Connection refused
97137:S 03 May 2025 23:05:48.936 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:49.037 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:49.138 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:49.239 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:49.340 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:49.443 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:49.543 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:49.644 * NODE 13aa946ae073b283903d0b625ce1c86adb50c18e () possibly failing.
97137:S 03 May 2025 23:05:49.648 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:49.749 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:49.751 * Node 9eb390e8ded52cf641b33887797c00ff53872c26 () reported node 13aa946ae073b283903d0b625ce1c86adb50c18e () as not reachable.
97137:S 03 May 2025 23:05:49.850 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:49.856 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
### Starting test Check for memory leaks (pid 97181) in tests/unit/cluster/slot-migration.tcl
97137:S 03 May 2025 23:05:49.950 * Connecting to PRIMARY 127.0.0.1:25652
97137:S 03 May 2025 23:05:49.957 * PRIMARY <-> REPLICA sync started
97137:S 03 May 2025 23:05:49.967 # Error condition on socket for SYNC: Connection refused
97137:S 03 May 2025 23:05:49.972 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:49.972 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:50.067 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:50.069 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:50.168 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:50.172 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:50.271 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:50.278 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:50.372 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:50.377 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:50.473 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:50.474 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:50.573 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:50.575 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:50.674 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:50.675 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:50.775 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:50.777 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:50.876 * NODE 6d062984222c6b8fea11f573fcb0ebcb21d117bb () possibly failing.
97137:S 03 May 2025 23:05:50.877 # Cluster state changed: fail
97137:S 03 May 2025 23:05:50.880 # Cluster is currently down: I am part of a minority partition.
97137:S 03 May 2025 23:05:50.883 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:50.883 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:50.984 * Connecting to PRIMARY 127.0.0.1:25652
97137:S 03 May 2025 23:05:50.989 * PRIMARY <-> REPLICA sync started
97137:S 03 May 2025 23:05:50.995 # Error condition on socket for SYNC: Connection refused
97137:S 03 May 2025 23:05:50.997 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:51.002 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:51.097 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:51.098 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:51.198 - Connection with Node 9eb390e8ded52cf641b33887797c00ff53872c26 at 127.0.0.1:35650 failed: Connection refused
97137:S 03 May 2025 23:05:51.201 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:51.203 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:51.212 - Client closed connection id=3 addr=127.0.0.1:56044 laddr=127.0.0.1:25649 fd=14 name= age=23 idle=4 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|slots user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=2032 tot-net-out=56662 tot-cmds=66
97137:S 03 May 2025 23:05:51.299 - Connection with Node 9eb390e8ded52cf641b33887797c00ff53872c26 at 127.0.0.1:35650 failed: Connection refused
97137:S 03 May 2025 23:05:51.299 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:51.299 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:51.400 - Connection with Node 9eb390e8ded52cf641b33887797c00ff53872c26 at 127.0.0.1:35650 failed: Connection refused
97137:S 03 May 2025 23:05:51.404 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:51.410 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:S 03 May 2025 23:05:52.256 * NODE 9eb390e8ded52cf641b33887797c00ff53872c26 () possibly failing.
97137:S 03 May 2025 23:05:52.259 - Accepting cluster node connection from 127.0.0.1:60526
97137:S 03 May 2025 23:05:52.262 - Accepting cluster node connection from 127.0.0.1:60542
97137:S 03 May 2025 23:05:52.268 - Connection with Node 9eb390e8ded52cf641b33887797c00ff53872c26 at 127.0.0.1:35650 failed: Connection refused
97137:S 03 May 2025 23:05:52.271 - Connection with Node 6d062984222c6b8fea11f573fcb0ebcb21d117bb at 127.0.0.1:35651 failed: Connection refused
97137:S 03 May 2025 23:05:52.271 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97137:signal-handler (1746281152) Received SIGTERM scheduling shutdown...
97137:S 03 May 2025 23:05:52.360 * User requested shutdown...
97137:S 03 May 2025 23:05:52.360 * Removing the pid file.
97137:S 03 May 2025 23:05:52.360 * Saving the cluster configuration file before exiting.
97137:S 03 May 2025 23:05:52.364 * Removing the unix socket file.
97137:S 03 May 2025 23:05:52.364 # Valkey is now ready to exit, bye bye...
