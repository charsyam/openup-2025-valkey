### Starting server for test 
9786:M 03 May 2025 23:07:25.181 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
9786:M 03 May 2025 23:07:25.181 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
9786:M 03 May 2025 23:07:25.181 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=9786, just started
9786:M 03 May 2025 23:07:25.181 * Configuration loaded
9786:M 03 May 2025 23:07:25.181 * Increased maximum number of open files to 10032 (it was originally set to 256).
9786:M 03 May 2025 23:07:25.181 * monotonic clock: POSIX clock_gettime
9786:M 03 May 2025 23:07:25.182 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 22172
 |###|   .+###############+.   |###|    PID: 9786                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

9786:M 03 May 2025 23:07:25.182 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
9786:M 03 May 2025 23:07:25.182 * No cluster configuration found, I'm 9037ea57c2a11049ab686ea5b2d1a9d841cc261f
9786:M 03 May 2025 23:07:25.191 * Server initialized
9786:M 03 May 2025 23:07:25.191 * Ready to accept connections tcp
9786:M 03 May 2025 23:07:25.191 * Ready to accept connections unix
9786:M 03 May 2025 23:07:25.322 - Accepted 127.0.0.1:55723
9786:M 03 May 2025 23:07:25.322 - Client closed connection id=2 addr=127.0.0.1:55723 laddr=127.0.0.1:22172 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
9786:M 03 May 2025 23:07:25.346 - Accepted 127.0.0.1:55725
9786:M 03 May 2025 23:07:25.347 * Cluster meet 127.0.0.1:22171 (user request from 'id=3 addr=127.0.0.1:55725 laddr=127.0.0.1:22172 fd=14 name= user=default lib-name= lib-ver=').
9786:M 03 May 2025 23:07:25.347 * Cluster meet 127.0.0.1:22170 (user request from 'id=3 addr=127.0.0.1:55725 laddr=127.0.0.1:22172 fd=14 name= user=default lib-name= lib-ver=').
9786:M 03 May 2025 23:07:25.347 * Cluster meet 127.0.0.1:22169 (user request from 'id=3 addr=127.0.0.1:55725 laddr=127.0.0.1:22172 fd=14 name= user=default lib-name= lib-ver=').
9786:M 03 May 2025 23:07:25.350 # Missing implement of connection type tls
9786:M 03 May 2025 23:07:25.395 - Accepting cluster node connection from 127.0.0.1:55730
9786:M 03 May 2025 23:07:25.396 * IP address for this node updated to 127.0.0.1
9786:M 03 May 2025 23:07:25.396 * Successfully completed handshake with 234aa23c7e2cfef9d242b2a5a46360bced592609 ()
9786:M 03 May 2025 23:07:25.408 - Accepting cluster node connection from 127.0.0.1:55732
9786:M 03 May 2025 23:07:25.408 * Successfully completed handshake with a523968ece1c43bdfd2c71d1ebb2bc15af1c4b88 ()
9786:M 03 May 2025 23:07:25.408 * configEpoch collision with node a523968ece1c43bdfd2c71d1ebb2bc15af1c4b88 (). configEpoch set to 1
9786:M 03 May 2025 23:07:25.476 - Accepting cluster node connection from 127.0.0.1:55738
9786:M 03 May 2025 23:07:25.476 * Successfully completed handshake with a94f7f189a45c0e46571fb8851d88282a7fb1f95 ()
9786:M 03 May 2025 23:07:25.898 - Accepted 127.0.0.1:55779
9786:M 03 May 2025 23:07:25.898 * Node 234aa23c7e2cfef9d242b2a5a46360bced592609 () is no longer primary of shard d7206f107358a6db4f39fa3adc76f51f302e066c; removed all 0 slot(s) it used to own
9786:M 03 May 2025 23:07:25.898 * Node 234aa23c7e2cfef9d242b2a5a46360bced592609 () is now part of shard 2c01afe7c657d1ad6a90aaa96fa67d64f5c4602a
9786:M 03 May 2025 23:07:25.898 * Node 234aa23c7e2cfef9d242b2a5a46360bced592609 () is now a replica of node 9037ea57c2a11049ab686ea5b2d1a9d841cc261f () in shard 2c01afe7c657d1ad6a90aaa96fa67d64f5c4602a
9786:M 03 May 2025 23:07:25.899 * Replica 127.0.0.1:22169 asks for synchronization
9786:M 03 May 2025 23:07:25.899 * Full resync requested by replica 127.0.0.1:22169
9786:M 03 May 2025 23:07:25.899 * Replication backlog created, my new replication IDs are '7766c07837b03ee0d5b09d32b5fdddd738bb028e' and '0000000000000000000000000000000000000000'
9786:M 03 May 2025 23:07:25.899 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
9786:M 03 May 2025 23:07:25.901 * Background RDB transfer started by pid 9798 to pipe through parent process
9786:M 03 May 2025 23:07:25.901 # DEBUG LOG: ========== I am primary 0 ==========
9798:C 03 May 2025 23:07:25.901 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
9786:M 03 May 2025 23:07:25.901 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
9786:M 03 May 2025 23:07:25.904 * Background RDB transfer terminated with success
9786:M 03 May 2025 23:07:25.904 * Streamed RDB transfer with replica 127.0.0.1:22169 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
9786:M 03 May 2025 23:07:25.904 * Synchronization with replica 127.0.0.1:22169 succeeded
9786:M 03 May 2025 23:07:27.208 * Cluster state changed: ok
### Starting test Manual failover vote is not limited by two times the node timeout - mixed failover in tests/unit/cluster/manual-failover.tcl
9786:M 03 May 2025 23:07:39.766 - Accepting cluster node connection from 127.0.0.1:57540
9786:M 03 May 2025 23:07:39.769 - Accepting cluster node connection from 127.0.0.1:57548
9786:M 03 May 2025 23:07:39.772 - Accepting cluster node connection from 127.0.0.1:57549
9786:M 03 May 2025 23:07:39.775 - Accepting cluster node connection from 127.0.0.1:57911
9786:M 03 May 2025 23:07:39.778 - Accepting cluster node connection from 127.0.0.1:57918
9786:M 03 May 2025 23:07:39.778 - Accepting cluster node connection from 127.0.0.1:57919
9786:M 03 May 2025 23:07:39.778 - Client closed connection id=15 addr=127.0.0.1:55779 laddr=127.0.0.1:22172 fd=21 name= age=14 idle=0 flags=S capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=1 omem=16920 tot-mem=35352 events=r cmd=replconf user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=808 tot-net-out=41 tot-cmds=21
9786:M 03 May 2025 23:07:39.778 * Connection with replica 127.0.0.1:22169 lost.
9786:M 03 May 2025 23:07:39.780 * Configuration change detected. Reconfiguring myself as a replica of node 234aa23c7e2cfef9d242b2a5a46360bced592609 () in shard 2c01afe7c657d1ad6a90aaa96fa67d64f5c4602a
9786:S 03 May 2025 23:07:39.782 * Before turning into a replica, using my own primary parameters to synthesize a cached primary: I may be able to synchronize with the new primary with just a partial transfer.
9786:S 03 May 2025 23:07:39.783 * Connecting to PRIMARY 127.0.0.1:22169
9786:S 03 May 2025 23:07:39.783 * PRIMARY <-> REPLICA sync started
9786:S 03 May 2025 23:07:39.783 * Ignore stale message from 234aa23c7e2cfef9d242b2a5a46360bced592609 () in shard 2c01afe7c657d1ad6a90aaa96fa67d64f5c4602a; gossip config epoch: 1, current config epoch: 4
9786:S 03 May 2025 23:07:39.783 * Node 234aa23c7e2cfef9d242b2a5a46360bced592609 () is now a replica of node 9037ea57c2a11049ab686ea5b2d1a9d841cc261f () in shard 2c01afe7c657d1ad6a90aaa96fa67d64f5c4602a
9786:S 03 May 2025 23:07:39.792 * Non blocking connect for SYNC fired the event.
9786:S 03 May 2025 23:07:39.795 * Primary replied to PING, replication can continue...
9786:S 03 May 2025 23:07:39.797 * Trying a partial resynchronization (request 7766c07837b03ee0d5b09d32b5fdddd738bb028e:15).
9786:S 03 May 2025 23:07:39.799 * Successful partial resynchronization with primary.
9786:S 03 May 2025 23:07:39.799 * Primary replication ID changed to e399b4c15042cb882dfa14bf4c4556fcd5356120
9786:S 03 May 2025 23:07:39.799 * PRIMARY <-> REPLICA sync: Primary accepted a Partial Resynchronization.
9786:S 03 May 2025 23:07:40.925 * Manual failover user request accepted (user request from 'id=3 addr=127.0.0.1:55725 laddr=127.0.0.1:22172 fd=14 name= user=default lib-name= lib-ver=').
9786:S 03 May 2025 23:07:40.925 * Received replication offset for paused primary manual failover: 14
9786:S 03 May 2025 23:07:40.925 * All primary replication stream processed, manual failover can start.
9786:S 03 May 2025 23:07:40.925 * Start of election delayed for 0 milliseconds (rank #0, primary rank #0, offset 14).
9786:S 03 May 2025 23:07:40.925 * Starting a failover election for epoch 5, node config epoch is 4
9786:S 03 May 2025 23:07:40.941 * Currently unable to failover: Waiting for votes, but majority still not reached.
9786:S 03 May 2025 23:07:40.941 * Needed quorum: 2. Number of votes received so far: 1
9786:S 03 May 2025 23:07:40.941 * Failover election won: I'm the new primary.
9786:S 03 May 2025 23:07:40.941 * configEpoch set to 5 after successful failover
9786:S 03 May 2025 23:07:40.942 * Setting myself to primary in shard 2c01afe7c657d1ad6a90aaa96fa67d64f5c4602a after failover; my old primary is 234aa23c7e2cfef9d242b2a5a46360bced592609 ()
9786:M 03 May 2025 23:07:40.942 * Connection with primary lost.
9786:M 03 May 2025 23:07:40.942 * Caching the disconnected primary state.
9786:M 03 May 2025 23:07:40.942 * Discarding previously cached primary state.
9786:M 03 May 2025 23:07:40.942 * Setting secondary replication ID to e399b4c15042cb882dfa14bf4c4556fcd5356120, valid up to offset: 15. New replication ID is 3a6ce2b8a4782a5c9ac3726fb4d4362919ea7659
9786:M 03 May 2025 23:07:40.949 - Node 234aa23c7e2cfef9d242b2a5a46360bced592609 has old slots configuration, sending an UPDATE message about 9037ea57c2a11049ab686ea5b2d1a9d841cc261f
9786:M 03 May 2025 23:07:40.950 - Accepted 127.0.0.1:58177
9786:M 03 May 2025 23:07:40.963 * A failover occurred in shard 2c01afe7c657d1ad6a90aaa96fa67d64f5c4602a; node 234aa23c7e2cfef9d242b2a5a46360bced592609 () failed over to node 9037ea57c2a11049ab686ea5b2d1a9d841cc261f () with a config epoch of 5
9786:M 03 May 2025 23:07:40.963 * Node 234aa23c7e2cfef9d242b2a5a46360bced592609 () is now a replica of node 9037ea57c2a11049ab686ea5b2d1a9d841cc261f () in shard 2c01afe7c657d1ad6a90aaa96fa67d64f5c4602a
9786:M 03 May 2025 23:07:40.964 * Replica 127.0.0.1:22169 asks for synchronization
9786:M 03 May 2025 23:07:40.964 * Partial resynchronization request from 127.0.0.1:22169 accepted. Sending 0 bytes of backlog starting from offset 15.
9786:M 03 May 2025 23:07:40.984 * Manual failover requested by replica 234aa23c7e2cfef9d242b2a5a46360bced592609 ().
9786:M 03 May 2025 23:07:40.984 * Failover auth granted to 234aa23c7e2cfef9d242b2a5a46360bced592609 () for epoch 6
9786:M 03 May 2025 23:07:40.999 - Client closed connection id=40 addr=127.0.0.1:58177 laddr=127.0.0.1:22172 fd=18 name= age=0 idle=0 flags=S capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=0 obl=0 oll=1 omem=16920 tot-mem=50712 events=r cmd=psync user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=333 tot-net-out=27 tot-cmds=6
9786:M 03 May 2025 23:07:41.001 * Connection with replica 127.0.0.1:22169 lost.
9786:M 03 May 2025 23:07:41.006 * Configuration change detected. Reconfiguring myself as a replica of node 234aa23c7e2cfef9d242b2a5a46360bced592609 () in shard 2c01afe7c657d1ad6a90aaa96fa67d64f5c4602a
9786:S 03 May 2025 23:07:41.006 * Before turning into a replica, using my own primary parameters to synthesize a cached primary: I may be able to synchronize with the new primary with just a partial transfer.
9786:S 03 May 2025 23:07:41.006 * Connecting to PRIMARY 127.0.0.1:22169
9786:S 03 May 2025 23:07:41.006 * PRIMARY <-> REPLICA sync started
9786:S 03 May 2025 23:07:41.021 * Non blocking connect for SYNC fired the event.
9786:S 03 May 2025 23:07:41.022 * Primary replied to PING, replication can continue...
9786:S 03 May 2025 23:07:41.025 * Trying a partial resynchronization (request 3a6ce2b8a4782a5c9ac3726fb4d4362919ea7659:15).
9786:S 03 May 2025 23:07:41.025 * Successful partial resynchronization with primary.
9786:S 03 May 2025 23:07:41.025 * Primary replication ID changed to bd02c3bc3c8c6ad298a3eaab941247b5db8d9b45
9786:S 03 May 2025 23:07:41.025 * PRIMARY <-> REPLICA sync: Primary accepted a Partial Resynchronization.
9786:S 03 May 2025 23:07:41.043 - Client closed connection id=3 addr=127.0.0.1:55725 laddr=127.0.0.1:22172 fd=14 name= age=16 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=2048 rbp=2048 obl=0 oll=0 omem=0 tot-mem=19456 events=r cmd=cluster|slots user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7605 tot-net-out=254530 tot-cmds=262
9786:S 03 May 2025 23:07:47.524 - Accepting cluster node connection from 127.0.0.1:58951
9786:S 03 May 2025 23:07:47.524 - Accepting cluster node connection from 127.0.0.1:58953
9786:S 03 May 2025 23:07:47.524 - Accepting cluster node connection from 127.0.0.1:58954
9786:signal-handler (1746281267) Received SIGTERM scheduling shutdown...
9786:S 03 May 2025 23:07:47.625 * User requested shutdown...
9786:S 03 May 2025 23:07:47.625 * Removing the pid file.
9786:S 03 May 2025 23:07:47.625 * Saving the cluster configuration file before exiting.
9786:S 03 May 2025 23:07:47.632 * Removing the unix socket file.
9786:S 03 May 2025 23:07:47.632 # Valkey is now ready to exit, bye bye...
