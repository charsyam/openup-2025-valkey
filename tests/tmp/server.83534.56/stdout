### Starting server for test 
89527:M 03 May 2025 23:04:27.884 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
89527:M 03 May 2025 23:04:27.884 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
89527:M 03 May 2025 23:04:27.884 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=89527, just started
89527:M 03 May 2025 23:04:27.884 * Configuration loaded
89527:M 03 May 2025 23:04:27.884 * Increased maximum number of open files to 10032 (it was originally set to 256).
89527:M 03 May 2025 23:04:27.884 * monotonic clock: POSIX clock_gettime
89527:M 03 May 2025 23:04:27.884 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 25636
 |###|   .+###############+.   |###|    PID: 89527                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

89527:M 03 May 2025 23:04:27.884 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
89527:M 03 May 2025 23:04:27.885 * No cluster configuration found, I'm b783e43cd90a371c2a8bfb9381f7136b60cec8f3
89527:M 03 May 2025 23:04:27.889 * Server initialized
89527:M 03 May 2025 23:04:27.889 * Ready to accept connections tcp
89527:M 03 May 2025 23:04:27.889 * Ready to accept connections unix
89527:M 03 May 2025 23:04:28.013 - Accepted 127.0.0.1:60342
89527:M 03 May 2025 23:04:28.015 - Client closed connection id=2 addr=127.0.0.1:60342 laddr=127.0.0.1:25636 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
89527:M 03 May 2025 23:04:28.027 - Accepted 127.0.0.1:60343
89527:M 03 May 2025 23:04:28.185 # Missing implement of connection type tls
89527:M 03 May 2025 23:04:28.255 - Accepting cluster node connection from 127.0.0.1:60350
89527:M 03 May 2025 23:04:28.255 * IP address for this node updated to 127.0.0.1
89527:M 03 May 2025 23:04:28.458 * Successfully completed handshake with c9c069e00f372ad4e0c059a17b2fe3dd61352384 ()
89527:M 03 May 2025 23:04:28.458 * configEpoch collision with node c9c069e00f372ad4e0c059a17b2fe3dd61352384 (). configEpoch set to 4
89527:M 03 May 2025 23:04:28.463 - Accepting cluster node connection from 127.0.0.1:60395
89527:M 03 May 2025 23:04:28.466 * Successfully completed handshake with 3a80752b0eb90f9593f1ca7c29a1cc73b38435b7 ()
89527:M 03 May 2025 23:04:28.496 * configEpoch collision with node c9c069e00f372ad4e0c059a17b2fe3dd61352384 (). configEpoch set to 5
89527:M 03 May 2025 23:04:28.553 - Accepting cluster node connection from 127.0.0.1:60417
89527:M 03 May 2025 23:04:28.556 - Accepting cluster node connection from 127.0.0.1:60419
89527:M 03 May 2025 23:04:28.559 - Accepting cluster node connection from 127.0.0.1:60421
89527:M 03 May 2025 23:04:28.690 - Accepting cluster node connection from 127.0.0.1:60448
89527:M 03 May 2025 23:04:28.691 - Accepting cluster node connection from 127.0.0.1:60451
89527:M 03 May 2025 23:04:28.706 - Accepting cluster node connection from 127.0.0.1:60452
89527:M 03 May 2025 23:04:28.708 - Accepting cluster node connection from 127.0.0.1:60453
89527:M 03 May 2025 23:04:28.708 - Accepting cluster node connection from 127.0.0.1:60454
89527:M 03 May 2025 23:04:28.711 - Accepting cluster node connection from 127.0.0.1:60458
89527:M 03 May 2025 23:04:28.810 - Accepting cluster node connection from 127.0.0.1:60461
89527:M 03 May 2025 23:04:28.971 * Node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () is no longer primary of shard 9eb746c79cb1fc7bdec65de386ac6a3de8061dbb; removed all 0 slot(s) it used to own
89527:M 03 May 2025 23:04:28.971 * Node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () is now part of shard ce1ce2d40fc11540b4d4fbf433a95aba39ce96d0
89527:M 03 May 2025 23:04:28.971 * Node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () is now a replica of node d4a541da210418dce028e0274341a55c129fc825 () in shard ce1ce2d40fc11540b4d4fbf433a95aba39ce96d0
89527:M 03 May 2025 23:04:28.973 - Accepted 127.0.0.1:60472
89527:M 03 May 2025 23:04:28.973 * Node c9c069e00f372ad4e0c059a17b2fe3dd61352384 () is no longer primary of shard 49d1c37e6da3c41dc6095f8ed615dffa0215d0b5; removed all 0 slot(s) it used to own
89527:M 03 May 2025 23:04:28.973 * Node c9c069e00f372ad4e0c059a17b2fe3dd61352384 () is now part of shard e1de41ffd5b22c7cef240a4331f5b9c2bd1ec141
89527:M 03 May 2025 23:04:28.973 * Node c9c069e00f372ad4e0c059a17b2fe3dd61352384 () is now a replica of node b783e43cd90a371c2a8bfb9381f7136b60cec8f3 () in shard e1de41ffd5b22c7cef240a4331f5b9c2bd1ec141
89527:M 03 May 2025 23:04:28.976 * Node b5d2cb99493e03b95f5b4ceef666b6c146b8483f () is no longer primary of shard 18e491ac0ebbc1c9eda07c64fb7b5e3da97db16f; removed all 0 slot(s) it used to own
89527:M 03 May 2025 23:04:28.978 * Node b5d2cb99493e03b95f5b4ceef666b6c146b8483f () is now part of shard fb98a0ec1aacfb366246894eefaed2af2f7c4c4e
89527:M 03 May 2025 23:04:28.978 * Node b5d2cb99493e03b95f5b4ceef666b6c146b8483f () is now a replica of node 830ac93a68bd546bc68f0d28099d68dec5e610e3 () in shard fb98a0ec1aacfb366246894eefaed2af2f7c4c4e
89527:M 03 May 2025 23:04:28.978 * Replica 127.0.0.1:25631 asks for synchronization
89527:M 03 May 2025 23:04:28.978 * Full resync requested by replica 127.0.0.1:25631
89527:M 03 May 2025 23:04:28.978 * Replication backlog created, my new replication IDs are 'a858cc8aa3aaa067ddce79dc68aa81c2b69c5764' and '0000000000000000000000000000000000000000'
89527:M 03 May 2025 23:04:28.978 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
89527:M 03 May 2025 23:04:28.980 * Background RDB transfer started by pid 89742 to pipe through parent process
89527:M 03 May 2025 23:04:28.980 * Node 49a6b2e00b53bcbb34b88b4d5b256badd9c9bf73 () is no longer primary of shard 52aceec9bf4978473ecde4c43e0799720fa9483c; removed all 0 slot(s) it used to own
89527:M 03 May 2025 23:04:28.980 * Node 49a6b2e00b53bcbb34b88b4d5b256badd9c9bf73 () is now part of shard d60eefbdbbd13d383fe3ab08148a31ced81848f0
89527:M 03 May 2025 23:04:28.980 * Node 49a6b2e00b53bcbb34b88b4d5b256badd9c9bf73 () is now a replica of node 117e239bcf937f1a7fd42246b67e12a4580dbdf1 () in shard d60eefbdbbd13d383fe3ab08148a31ced81848f0
89742:C 03 May 2025 23:04:28.981 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
89527:M 03 May 2025 23:04:28.982 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
89527:M 03 May 2025 23:04:28.987 * Background RDB transfer terminated with success
89527:M 03 May 2025 23:04:28.990 * Streamed RDB transfer with replica 127.0.0.1:25631 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
89527:M 03 May 2025 23:04:28.995 * Synchronization with replica 127.0.0.1:25631 succeeded
89527:M 03 May 2025 23:04:28.995 * Node 3a80752b0eb90f9593f1ca7c29a1cc73b38435b7 () is no longer primary of shard 34b9589abeb4712483c0fff534f6c42c6e0692e1; removed all 0 slot(s) it used to own
89527:M 03 May 2025 23:04:28.997 * Node 3a80752b0eb90f9593f1ca7c29a1cc73b38435b7 () is now part of shard 13401c2fb3be710e34a5d8b768c60923088230ef
89527:M 03 May 2025 23:04:28.997 * Node 3a80752b0eb90f9593f1ca7c29a1cc73b38435b7 () is now a replica of node 298cbb5912fa1c49173b389864ea1d9e8949d312 () in shard 13401c2fb3be710e34a5d8b768c60923088230ef
89527:M 03 May 2025 23:04:28.999 # DEBUG LOG: ========== I am primary 1 ==========
89527:M 03 May 2025 23:04:29.926 * Cluster state changed: ok
### Starting test Cluster is up in tests/unit/cluster/failover.tcl
### Starting test Cluster is writable in tests/unit/cluster/failover.tcl
89527:M 03 May 2025 23:04:38.560 - Accepted 127.0.0.1:62582
89527:M 03 May 2025 23:04:38.589 - Client closed connection id=13 addr=127.0.0.1:62582 laddr=127.0.0.1:25636 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=1671 tot-net-out=732 tot-cmds=42
### Starting test Instance #5 is a slave in tests/unit/cluster/failover.tcl
### Starting test Instance #5 synced with the master in tests/unit/cluster/failover.tcl
### Starting test Killing one master node in tests/unit/cluster/failover.tcl
### Starting test Wait for failover in tests/unit/cluster/failover.tcl
89527:M 03 May 2025 23:04:41.835 * Node 298cbb5912fa1c49173b389864ea1d9e8949d312 () reported node d4a541da210418dce028e0274341a55c129fc825 () as not reachable.
89527:M 03 May 2025 23:04:41.835 * Node 830ac93a68bd546bc68f0d28099d68dec5e610e3 () reported node d4a541da210418dce028e0274341a55c129fc825 () as not reachable.
89527:M 03 May 2025 23:04:41.835 * Marking node d4a541da210418dce028e0274341a55c129fc825 () as failing (quorum reached).
89527:M 03 May 2025 23:04:41.835 # Cluster state changed: fail
89527:M 03 May 2025 23:04:41.835 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
89527:M 03 May 2025 23:04:42.039 * Node 117e239bcf937f1a7fd42246b67e12a4580dbdf1 () reported node d4a541da210418dce028e0274341a55c129fc825 () as not reachable.
89527:M 03 May 2025 23:04:42.829 * Failover auth granted to e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () for epoch 10
### Starting test Cluster should eventually be up again in tests/unit/cluster/failover.tcl
89527:M 03 May 2025 23:04:42.889 * Node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () reported node d4a541da210418dce028e0274341a55c129fc825 () as not reachable.
89527:M 03 May 2025 23:04:42.889 * Cluster state changed: ok
### Starting test Cluster is writable in tests/unit/cluster/failover.tcl
89527:M 03 May 2025 23:04:42.990 - Accepted 127.0.0.1:63952
89527:M 03 May 2025 23:04:42.990 - Client closed connection id=14 addr=127.0.0.1:63952 laddr=127.0.0.1:25636 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=cluster|nodes user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=28 tot-net-out=1224 tot-cmds=1
89527:M 03 May 2025 23:04:42.990 - Accepted 127.0.0.1:63953
89527:M 03 May 2025 23:04:43.019 - Client closed connection id=15 addr=127.0.0.1:63953 laddr=127.0.0.1:25636 fd=34 name= age=1 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=1671 tot-net-out=732 tot-cmds=42
### Starting test Instance #5 is now a master in tests/unit/cluster/failover.tcl
### Starting test Restarting the previously killed master node in tests/unit/cluster/failover.tcl
### Starting test Instance #0 gets converted into a slave in tests/unit/cluster/failover.tcl
89527:M 03 May 2025 23:04:43.027 - Node d4a541da210418dce028e0274341a55c129fc825 has old slots configuration, sending an UPDATE message about e8f7d0ef9915c7d538829f6e3533c532bafa8a39
89527:M 03 May 2025 23:04:43.032 * Clear FAIL state for node d4a541da210418dce028e0274341a55c129fc825 (): primary without slots is reachable again.
89527:M 03 May 2025 23:04:43.032 * A failover occurred in shard ce1ce2d40fc11540b4d4fbf433a95aba39ce96d0; node d4a541da210418dce028e0274341a55c129fc825 () failed over to node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () with a config epoch of 10
89527:M 03 May 2025 23:04:43.032 * Node d4a541da210418dce028e0274341a55c129fc825 () is now a replica of node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () in shard ce1ce2d40fc11540b4d4fbf433a95aba39ce96d0
### Starting test Check for memory leaks (pid 89538) in tests/unit/cluster/failover.tcl
89527:M 03 May 2025 23:04:43.074 * Node 117e239bcf937f1a7fd42246b67e12a4580dbdf1 () reported node d4a541da210418dce028e0274341a55c129fc825 () is back online.
89527:M 03 May 2025 23:04:43.090 * Node e8f7d0ef9915c7d538829f6e3533c532bafa8a39 () reported node d4a541da210418dce028e0274341a55c129fc825 () is back online.
89527:M 03 May 2025 23:04:43.175 - DB 0: 21 keys (0 volatile) in 147 slots HT.
89527:M 03 May 2025 23:04:43.285 * Node 298cbb5912fa1c49173b389864ea1d9e8949d312 () reported node d4a541da210418dce028e0274341a55c129fc825 () is back online.
89527:M 03 May 2025 23:04:43.786 * Node 830ac93a68bd546bc68f0d28099d68dec5e610e3 () reported node d4a541da210418dce028e0274341a55c129fc825 () is back online.
89527:M 03 May 2025 23:04:44.390 - Connection with Node d4a541da210418dce028e0274341a55c129fc825 at 127.0.0.1:35637 failed: Connection refused
89527:M 03 May 2025 23:04:44.394 - Client closed connection id=3 addr=127.0.0.1:60343 laddr=127.0.0.1:25636 fd=14 name= age=16 idle=1 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|slots user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=2932 tot-net-out=66325 tot-cmds=105
89527:M 03 May 2025 23:04:44.491 - Connection with Node d4a541da210418dce028e0274341a55c129fc825 at 127.0.0.1:35637 failed: Connection refused
89527:M 03 May 2025 23:04:44.592 - Connection with Node d4a541da210418dce028e0274341a55c129fc825 at 127.0.0.1:35637 failed: Connection refused
89527:M 03 May 2025 23:04:44.692 - Connection with Node d4a541da210418dce028e0274341a55c129fc825 at 127.0.0.1:35637 failed: Connection refused
89527:M 03 May 2025 23:04:44.793 - Connection with Node d4a541da210418dce028e0274341a55c129fc825 at 127.0.0.1:35637 failed: Connection refused
89527:M 03 May 2025 23:04:45.811 - Connection with Node d4a541da210418dce028e0274341a55c129fc825 at 127.0.0.1:35637 failed: Connection refused
89527:signal-handler (1746281085) Received SIGTERM scheduling shutdown...
89527:M 03 May 2025 23:04:45.912 * User requested shutdown...
89527:M 03 May 2025 23:04:45.912 * 1 of 1 replicas are in sync when shutting down.
89527:M 03 May 2025 23:04:45.912 * Removing the pid file.
89527:M 03 May 2025 23:04:45.912 * Saving the cluster configuration file before exiting.
89527:M 03 May 2025 23:04:45.923 * Removing the unix socket file.
89527:M 03 May 2025 23:04:45.924 # Valkey is now ready to exit, bye bye...
