### Starting server for test 
93617:M 03 May 2025 23:04:55.519 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
93617:M 03 May 2025 23:04:55.519 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
93617:M 03 May 2025 23:04:55.519 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=93617, just started
93617:M 03 May 2025 23:04:55.519 * Configuration loaded
93617:M 03 May 2025 23:04:55.519 * Increased maximum number of open files to 10032 (it was originally set to 256).
93617:M 03 May 2025 23:04:55.519 * monotonic clock: POSIX clock_gettime
93617:M 03 May 2025 23:04:55.520 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 26140
 |###|   .+###############+.   |###|    PID: 93617                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

93617:M 03 May 2025 23:04:55.520 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
93617:M 03 May 2025 23:04:55.520 * No cluster configuration found, I'm ab4466c74c3d688ae92a2d9293213bec01550e26
93617:M 03 May 2025 23:04:55.527 * Server initialized
93617:M 03 May 2025 23:04:55.527 * Ready to accept connections tcp
93617:M 03 May 2025 23:04:55.527 * Ready to accept connections unix
93617:M 03 May 2025 23:04:55.642 - Accepted 127.0.0.1:52251
93617:M 03 May 2025 23:04:55.645 - Client closed connection id=2 addr=127.0.0.1:52251 laddr=127.0.0.1:26140 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
93617:M 03 May 2025 23:04:55.659 - Accepted 127.0.0.1:52252
93617:M 03 May 2025 23:04:55.862 # Missing implement of connection type tls
93617:M 03 May 2025 23:04:55.892 - Accepting cluster node connection from 127.0.0.1:52303
93617:M 03 May 2025 23:04:55.892 * IP address for this node updated to 127.0.0.1
93617:M 03 May 2025 23:04:56.087 - Accepting cluster node connection from 127.0.0.1:52345
93617:M 03 May 2025 23:04:56.115 - Accepting cluster node connection from 127.0.0.1:52364
93617:M 03 May 2025 23:04:56.158 - Accepting cluster node connection from 127.0.0.1:52371
93617:M 03 May 2025 23:04:56.161 - Accepting cluster node connection from 127.0.0.1:52376
93617:M 03 May 2025 23:04:56.164 * configEpoch collision with node e85401c6f9d7f6a5a714efed4e0aac6259a80f0b (). configEpoch set to 5
93617:M 03 May 2025 23:04:56.249 * Node 540eba87ce564b2813f56f84a5e4d0050da83472 () is no longer primary of shard 8c8bc8d0bdec464ac6506f2a89ff40bb1fd941a2; removed all 0 slot(s) it used to own
93617:M 03 May 2025 23:04:56.249 * Node 540eba87ce564b2813f56f84a5e4d0050da83472 () is now part of shard 2dc0273f3dfffb5751b1acf65d47cfb45c7f3a5b
93617:M 03 May 2025 23:04:56.249 * Node 540eba87ce564b2813f56f84a5e4d0050da83472 () is now a replica of node 37ca2c0ba82c84f451cdf605c032e650b7a616b9 () in shard 2dc0273f3dfffb5751b1acf65d47cfb45c7f3a5b
93617:M 03 May 2025 23:04:56.255 - Accepted 127.0.0.1:52417
93617:M 03 May 2025 23:04:56.255 * Node c6938be0182a41850aafba2206a9aa0a5566580b () is no longer primary of shard 96138559a8e1fbecff05076abf91cd018fd8062f; removed all 0 slot(s) it used to own
93617:M 03 May 2025 23:04:56.255 * Node c6938be0182a41850aafba2206a9aa0a5566580b () is now part of shard 4d5b4cab0111eafb995f56df64414eff13db5ef0
93617:M 03 May 2025 23:04:56.255 * Node c6938be0182a41850aafba2206a9aa0a5566580b () is now a replica of node ab4466c74c3d688ae92a2d9293213bec01550e26 () in shard 4d5b4cab0111eafb995f56df64414eff13db5ef0
93617:M 03 May 2025 23:04:56.256 * Replica 127.0.0.1:26137 asks for synchronization
93617:M 03 May 2025 23:04:56.256 * Full resync requested by replica 127.0.0.1:26137
93617:M 03 May 2025 23:04:56.256 * Replication backlog created, my new replication IDs are 'dd61f19287d0d197260fb9fd35492e84d03e3b4d' and '0000000000000000000000000000000000000000'
93617:M 03 May 2025 23:04:56.256 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
93617:M 03 May 2025 23:04:56.257 * Background RDB transfer started by pid 93798 to pipe through parent process
93617:M 03 May 2025 23:04:56.258 * Node e85401c6f9d7f6a5a714efed4e0aac6259a80f0b () is no longer primary of shard cf9139eab8fecc9fadac17877f69e9281e11c86f; removed all 0 slot(s) it used to own
93617:M 03 May 2025 23:04:56.260 * Node e85401c6f9d7f6a5a714efed4e0aac6259a80f0b () is now part of shard 28be1ac2e8f69c061f4c3e1f3a67ab3a103da86a
93617:M 03 May 2025 23:04:56.260 * Node e85401c6f9d7f6a5a714efed4e0aac6259a80f0b () is now a replica of node 43b79764445dcae918f44e4373aaf81a82e26451 () in shard 28be1ac2e8f69c061f4c3e1f3a67ab3a103da86a
93798:C 03 May 2025 23:04:56.258 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
93617:M 03 May 2025 23:04:56.260 # DEBUG LOG: ========== I am primary 1 ==========
93617:M 03 May 2025 23:04:56.261 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
93617:M 03 May 2025 23:04:56.266 * Background RDB transfer terminated with success
93617:M 03 May 2025 23:04:56.266 * Streamed RDB transfer with replica 127.0.0.1:26137 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
93617:M 03 May 2025 23:04:56.266 * Synchronization with replica 127.0.0.1:26137 succeeded
93617:M 03 May 2025 23:04:57.542 * Cluster state changed: ok
### Starting test Cluster is up in tests/unit/cluster/no-failover-option.tcl
### Starting test Instance #3 is a replica in tests/unit/cluster/no-failover-option.tcl
### Starting test Instance #3 synced with the master in tests/unit/cluster/no-failover-option.tcl
### Starting test The nofailover flag is propagated in tests/unit/cluster/no-failover-option.tcl
### Starting test Killing one master node in tests/unit/cluster/no-failover-option.tcl
### Starting test Cluster should be still down after some time in tests/unit/cluster/no-failover-option.tcl
93617:M 03 May 2025 23:05:09.584 * FAIL message received from 43b79764445dcae918f44e4373aaf81a82e26451 () about 37ca2c0ba82c84f451cdf605c032e650b7a616b9 ()
93617:M 03 May 2025 23:05:09.584 * Node 43b79764445dcae918f44e4373aaf81a82e26451 () reported node 37ca2c0ba82c84f451cdf605c032e650b7a616b9 () as not reachable.
93617:M 03 May 2025 23:05:09.584 # Cluster state changed: fail
93617:M 03 May 2025 23:05:09.584 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
### Starting test Instance #3 is still a replica in tests/unit/cluster/no-failover-option.tcl
### Starting test Restarting the previously killed master node in tests/unit/cluster/no-failover-option.tcl
### Starting test Check for memory leaks (pid 93671) in tests/unit/cluster/no-failover-option.tcl
93617:M 03 May 2025 23:05:10.757 - Connection with Node 37ca2c0ba82c84f451cdf605c032e650b7a616b9 at 127.0.0.1:36141 failed: Connection refused
93617:M 03 May 2025 23:05:10.858 - Connection with Node 37ca2c0ba82c84f451cdf605c032e650b7a616b9 at 127.0.0.1:36141 failed: Connection refused
93617:M 03 May 2025 23:05:10.907 - Client closed connection id=3 addr=127.0.0.1:52252 laddr=127.0.0.1:26140 fd=14 name= age=15 idle=1 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|info user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=2366 tot-net-out=43917 tot-cmds=84
93617:M 03 May 2025 23:05:10.959 - Connection with Node 37ca2c0ba82c84f451cdf605c032e650b7a616b9 at 127.0.0.1:36141 failed: Connection refused
93617:M 03 May 2025 23:05:11.060 - Connection with Node 37ca2c0ba82c84f451cdf605c032e650b7a616b9 at 127.0.0.1:36141 failed: Connection refused
93617:M 03 May 2025 23:05:11.161 - Connection with Node 37ca2c0ba82c84f451cdf605c032e650b7a616b9 at 127.0.0.1:36141 failed: Connection refused
93617:M 03 May 2025 23:05:11.987 - Connection with Node 37ca2c0ba82c84f451cdf605c032e650b7a616b9 at 127.0.0.1:36141 failed: Connection refused
93617:signal-handler (1746281112) Received SIGTERM scheduling shutdown...
93617:M 03 May 2025 23:05:12.088 * User requested shutdown...
93617:M 03 May 2025 23:05:12.089 * 1 of 1 replicas are in sync when shutting down.
93617:M 03 May 2025 23:05:12.089 * Removing the pid file.
93617:M 03 May 2025 23:05:12.089 * Saving the cluster configuration file before exiting.
93617:M 03 May 2025 23:05:12.115 * Removing the unix socket file.
93617:M 03 May 2025 23:05:12.122 # Valkey is now ready to exit, bye bye...
