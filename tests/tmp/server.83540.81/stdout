### Starting server for test 
693:M 03 May 2025 23:06:05.344 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
693:M 03 May 2025 23:06:05.344 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
693:M 03 May 2025 23:06:05.347 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=693, just started
693:M 03 May 2025 23:06:05.350 * Configuration loaded
693:M 03 May 2025 23:06:05.355 * Increased maximum number of open files to 10032 (it was originally set to 256).
693:M 03 May 2025 23:06:05.358 * monotonic clock: POSIX clock_gettime
693:M 03 May 2025 23:06:05.364 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 28653
 |###|   .+###############+.   |###|    PID: 693                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

693:M 03 May 2025 23:06:05.368 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
693:M 03 May 2025 23:06:05.377 * No cluster configuration found, I'm a1c65be42a7f66fab44e893d7369a3b98a52727f
693:M 03 May 2025 23:06:05.383 * Server initialized
693:M 03 May 2025 23:06:05.383 * Ready to accept connections tcp
693:M 03 May 2025 23:06:05.383 * Ready to accept connections unix
693:M 03 May 2025 23:06:05.500 - Accepted 127.0.0.1:50039
693:M 03 May 2025 23:06:05.500 - Client closed connection id=2 addr=127.0.0.1:50039 laddr=127.0.0.1:28653 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
693:M 03 May 2025 23:06:05.511 - Accepted 127.0.0.1:50056
693:M 03 May 2025 23:06:05.771 # Missing implement of connection type tls
693:M 03 May 2025 23:06:05.816 - Accepting cluster node connection from 127.0.0.1:50355
693:M 03 May 2025 23:06:05.817 * IP address for this node updated to 127.0.0.1
693:M 03 May 2025 23:06:06.018 * configEpoch collision with node e8b2464666b970c892eee259e7e9e58024cb3308 (). configEpoch set to 1
693:M 03 May 2025 23:06:06.080 - Accepting cluster node connection from 127.0.0.1:50564
693:M 03 May 2025 23:06:06.082 * configEpoch collision with node e85c74114b901253d72c6508d1ec95ea80db30a2 (). configEpoch set to 2
693:M 03 May 2025 23:06:06.108 - Accepting cluster node connection from 127.0.0.1:50567
693:M 03 May 2025 23:06:06.149 * Node e600b263dd64dbf12bb81865b04d2080e1080ae7 () is no longer primary of shard f4d14c8ad04f933bc18eac97517ef1fbd4210c50; removed all 0 slot(s) it used to own
693:M 03 May 2025 23:06:06.149 * Node e600b263dd64dbf12bb81865b04d2080e1080ae7 () is now part of shard c27b7cc462b5bdd7da16492115abd78447116be5
693:M 03 May 2025 23:06:06.149 * Node e600b263dd64dbf12bb81865b04d2080e1080ae7 () is now a replica of node e8b2464666b970c892eee259e7e9e58024cb3308 () in shard c27b7cc462b5bdd7da16492115abd78447116be5
693:M 03 May 2025 23:06:06.149 - Accepted 127.0.0.1:50609
693:M 03 May 2025 23:06:06.150 * Node e85c74114b901253d72c6508d1ec95ea80db30a2 () is no longer primary of shard eac5124ca4ae3f8311cbe7b302abe1a6ecda5f68; removed all 0 slot(s) it used to own
693:M 03 May 2025 23:06:06.150 * Node e85c74114b901253d72c6508d1ec95ea80db30a2 () is now part of shard 49fd8b2e68aeea5aaa7178e5b8b052c919bffd8e
693:M 03 May 2025 23:06:06.150 * Node e85c74114b901253d72c6508d1ec95ea80db30a2 () is now a replica of node a1c65be42a7f66fab44e893d7369a3b98a52727f () in shard 49fd8b2e68aeea5aaa7178e5b8b052c919bffd8e
693:M 03 May 2025 23:06:06.151 * Replica 127.0.0.1:28651 asks for synchronization
693:M 03 May 2025 23:06:06.151 * Full resync requested by replica 127.0.0.1:28651
693:M 03 May 2025 23:06:06.151 * Replication backlog created, my new replication IDs are '1a5432230d8e36788b2b41db37dc07015e865ba0' and '0000000000000000000000000000000000000000'
693:M 03 May 2025 23:06:06.151 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
693:M 03 May 2025 23:06:06.152 * Background RDB transfer started by pid 774 to pipe through parent process
774:C 03 May 2025 23:06:06.152 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
693:M 03 May 2025 23:06:06.155 # DEBUG LOG: ========== I am primary 1 ==========
693:M 03 May 2025 23:06:06.155 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
693:M 03 May 2025 23:06:06.157 * Background RDB transfer terminated with success
693:M 03 May 2025 23:06:06.157 * Streamed RDB transfer with replica 127.0.0.1:28651 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
693:M 03 May 2025 23:06:06.157 * Synchronization with replica 127.0.0.1:28651 succeeded
693:M 03 May 2025 23:06:07.427 * Cluster state changed: ok
### Starting test Verify that slot ownership transfer through gossip propagates deletes to replicas in tests/unit/cluster/slot-ownership.tcl
693:M 03 May 2025 23:06:15.871 * Assigning slot 3028 to node a1c65be42a7f66fab44e893d7369a3b98a52727f () in shard 49fd8b2e68aeea5aaa7178e5b8b052c919bffd8e
693:M 03 May 2025 23:06:15.926 - Node e8b2464666b970c892eee259e7e9e58024cb3308 has old slots configuration, sending an UPDATE message about a1c65be42a7f66fab44e893d7369a3b98a52727f
### Starting test Check for memory leaks (pid 720) in tests/unit/cluster/slot-ownership.tcl
693:M 03 May 2025 23:06:18.141 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:18.144 - Client closed connection id=3 addr=127.0.0.1:50056 laddr=127.0.0.1:28653 fd=14 name= age=13 idle=3 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=698 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|slots user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=954 tot-net-out=10068 tot-cmds=29
693:M 03 May 2025 23:06:18.242 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:18.342 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:18.443 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:18.544 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:18.646 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:18.747 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:18.851 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:18.952 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:19.053 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:19.153 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:19.253 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:19.354 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:M 03 May 2025 23:06:20.562 - Connection with Node e8b2464666b970c892eee259e7e9e58024cb3308 at 127.0.0.1:38654 failed: Connection refused
693:signal-handler (1746281180) Received SIGTERM scheduling shutdown...
693:M 03 May 2025 23:06:20.662 * User requested shutdown...
693:M 03 May 2025 23:06:20.662 * 1 of 1 replicas are in sync when shutting down.
693:M 03 May 2025 23:06:20.662 * Removing the pid file.
693:M 03 May 2025 23:06:20.662 * Saving the cluster configuration file before exiting.
693:M 03 May 2025 23:06:20.670 * Removing the unix socket file.
693:M 03 May 2025 23:06:20.670 # Valkey is now ready to exit, bye bye...
