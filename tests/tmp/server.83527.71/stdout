### Starting server for test 
96151:M 03 May 2025 23:05:20.283 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
96151:M 03 May 2025 23:05:20.283 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
96151:M 03 May 2025 23:05:20.283 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=96151, just started
96151:M 03 May 2025 23:05:20.283 * Configuration loaded
96151:M 03 May 2025 23:05:20.283 * Increased maximum number of open files to 10032 (it was originally set to 256).
96151:M 03 May 2025 23:05:20.283 * monotonic clock: POSIX clock_gettime
96151:M 03 May 2025 23:05:20.283 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 22146
 |###|   .+###############+.   |###|    PID: 96151                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

96151:M 03 May 2025 23:05:20.283 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
96151:M 03 May 2025 23:05:20.283 * No cluster configuration found, I'm 571ea23bf5cdffbe95dc1727682f4f31e6399d29
96151:M 03 May 2025 23:05:20.341 * Server initialized
96151:M 03 May 2025 23:05:20.348 * Ready to accept connections tcp
96151:M 03 May 2025 23:05:20.352 * Ready to accept connections unix
96151:M 03 May 2025 23:05:20.505 - Accepted 127.0.0.1:50357
96151:M 03 May 2025 23:05:20.513 - Client closed connection id=2 addr=127.0.0.1:50357 laddr=127.0.0.1:22146 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
96151:M 03 May 2025 23:05:20.581 - Accepted 127.0.0.1:50410
96151:M 03 May 2025 23:05:21.826 - Accepting cluster node connection from 127.0.0.1:51319
96151:M 03 May 2025 23:05:21.833 * IP address for this node updated to 127.0.0.1
96151:M 03 May 2025 23:05:22.050 - Accepting cluster node connection from 127.0.0.1:51482
96151:M 03 May 2025 23:05:22.072 - Accepting cluster node connection from 127.0.0.1:51510
96151:M 03 May 2025 23:05:22.074 * configEpoch collision with node a21e86dd7d6844054a7c3186a4d33006a7ef97bd (). configEpoch set to 2
96151:M 03 May 2025 23:05:22.120 - Accepting cluster node connection from 127.0.0.1:51550
96151:M 03 May 2025 23:05:22.124 - Accepting cluster node connection from 127.0.0.1:51559
96151:M 03 May 2025 23:05:22.159 * configEpoch collision with node a59eb002dc5e0d938f7c474975db2c8b6a5620b0 (). configEpoch set to 3
96151:M 03 May 2025 23:05:22.246 - Accepting cluster node connection from 127.0.0.1:51596
96151:M 03 May 2025 23:05:22.254 - Accepting cluster node connection from 127.0.0.1:51626
96151:M 03 May 2025 23:05:22.304 - Accepting cluster node connection from 127.0.0.1:51662
96151:M 03 May 2025 23:05:22.373 - Accepting cluster node connection from 127.0.0.1:51736
96151:M 03 May 2025 23:05:22.394 * configEpoch collision with node a83b12f99ba80124eba788598806542c5da37d9e (). configEpoch set to 4
96151:M 03 May 2025 23:05:22.399 * configEpoch collision with node e2d292eade1e654dfcbaf0199c4085fd7be41119 (). configEpoch set to 5
96151:M 03 May 2025 23:05:22.403 * configEpoch collision with node 588865ad810a9a2a0c032336635c16fcfda1ae87 (). configEpoch set to 6
96151:M 03 May 2025 23:05:22.410 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
96151:M 03 May 2025 23:05:22.474 * Cluster state changed: ok
96151:M 03 May 2025 23:05:22.520 * configEpoch collision with node a59eb002dc5e0d938f7c474975db2c8b6a5620b0 (). configEpoch set to 7
96151:M 03 May 2025 23:05:22.601 # Missing implement of connection type tls
96151:M 03 May 2025 23:05:22.608 * configEpoch collision with node 588865ad810a9a2a0c032336635c16fcfda1ae87 (). configEpoch set to 8
96151:M 03 May 2025 23:05:22.785 * Node e2d292eade1e654dfcbaf0199c4085fd7be41119 () is no longer primary of shard 256f6dcdec4fe78f1a1e4e1da9762f32a8d53933; removed all 0 slot(s) it used to own
96151:M 03 May 2025 23:05:22.785 * Node e2d292eade1e654dfcbaf0199c4085fd7be41119 () is now part of shard 346ab41bb3203a84bc575e43be5ac11721355613
96151:M 03 May 2025 23:05:22.785 * Node e2d292eade1e654dfcbaf0199c4085fd7be41119 () is now a replica of node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () in shard 346ab41bb3203a84bc575e43be5ac11721355613
96151:M 03 May 2025 23:05:22.787 * Node cec11f5fa752abac24462ce05cbfbbcbf0f028f5 () is no longer primary of shard 938293520c68b674cb49633335610e25dd52713f; removed all 0 slot(s) it used to own
96151:M 03 May 2025 23:05:22.788 * Node cec11f5fa752abac24462ce05cbfbbcbf0f028f5 () is now part of shard c00ccb0e3de2bd2ae4befbae1ce2aca411aa8671
96151:M 03 May 2025 23:05:22.792 * Node cec11f5fa752abac24462ce05cbfbbcbf0f028f5 () is now a replica of node 588865ad810a9a2a0c032336635c16fcfda1ae87 () in shard c00ccb0e3de2bd2ae4befbae1ce2aca411aa8671
96151:M 03 May 2025 23:05:22.793 * Node 48ce29c51389b534d0e756dbed048497c93bcc04 () is no longer primary of shard ce52f3ca12bf12223b54157bb8cdc9b3aab689a5; removed all 0 slot(s) it used to own
96151:M 03 May 2025 23:05:22.793 * Node 48ce29c51389b534d0e756dbed048497c93bcc04 () is now part of shard 7a9129f307605f9fc2e9e070fc3b91cb77372395
96151:M 03 May 2025 23:05:22.793 * Node 48ce29c51389b534d0e756dbed048497c93bcc04 () is now a replica of node fe8678675cc9fa5a6fedbade0150f28aff7c28b6 () in shard 7a9129f307605f9fc2e9e070fc3b91cb77372395
96151:M 03 May 2025 23:05:22.811 - Accepted 127.0.0.1:52056
96151:M 03 May 2025 23:05:22.851 * Node a21e86dd7d6844054a7c3186a4d33006a7ef97bd () is no longer primary of shard 74397b408645fd96aa93c7a5707da778711f43d3; removed all 0 slot(s) it used to own
96151:M 03 May 2025 23:05:22.853 * Node a21e86dd7d6844054a7c3186a4d33006a7ef97bd () is now part of shard 1aacca3a9c7a750d76f6c800a57f4c1bd132846a
96151:M 03 May 2025 23:05:22.853 * Node a21e86dd7d6844054a7c3186a4d33006a7ef97bd () is now a replica of node 571ea23bf5cdffbe95dc1727682f4f31e6399d29 () in shard 1aacca3a9c7a750d76f6c800a57f4c1bd132846a
96151:M 03 May 2025 23:05:22.871 * Node a83b12f99ba80124eba788598806542c5da37d9e () is no longer primary of shard cf87ecc3efdcdfd3cac14e27b809f09893af48d2; removed all 0 slot(s) it used to own
96151:M 03 May 2025 23:05:22.871 * Node a83b12f99ba80124eba788598806542c5da37d9e () is now part of shard 3d0e9edcdf7533db82632130cb5a60794f38dd25
96151:M 03 May 2025 23:05:22.871 * Node a83b12f99ba80124eba788598806542c5da37d9e () is now a replica of node a59eb002dc5e0d938f7c474975db2c8b6a5620b0 () in shard 3d0e9edcdf7533db82632130cb5a60794f38dd25
96151:M 03 May 2025 23:05:22.872 # DEBUG LOG: ========== I am primary 3 ==========
96151:M 03 May 2025 23:05:22.874 * Replica 127.0.0.1:22141 asks for synchronization
96151:M 03 May 2025 23:05:22.874 * Full resync requested by replica 127.0.0.1:22141
96151:M 03 May 2025 23:05:22.874 * Replication backlog created, my new replication IDs are '6941765d0fa5334302483a3fa20935fe26d27bba' and '0000000000000000000000000000000000000000'
96151:M 03 May 2025 23:05:22.874 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
96151:M 03 May 2025 23:05:22.877 * Background RDB transfer started by pid 96612 to pipe through parent process
96612:C 03 May 2025 23:05:22.878 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
96151:M 03 May 2025 23:05:22.880 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
96151:M 03 May 2025 23:05:22.885 * Background RDB transfer terminated with success
96151:M 03 May 2025 23:05:22.885 * Streamed RDB transfer with replica 127.0.0.1:22141 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
96151:M 03 May 2025 23:05:22.885 * Synchronization with replica 127.0.0.1:22141 succeeded
### Starting test Cluster is up in tests/unit/cluster/manual-failover.tcl
### Starting test Cluster is writable in tests/unit/cluster/manual-failover.tcl
96151:M 03 May 2025 23:05:32.438 - Accepted 127.0.0.1:56463
96151:M 03 May 2025 23:05:32.501 - Client closed connection id=9 addr=127.0.0.1:56463 laddr=127.0.0.1:22146 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=30 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=1120 tot-net-out=490 tot-cmds=28
### Starting test Instance #5 is a slave in tests/unit/cluster/manual-failover.tcl
### Starting test Instance #5 synced with the master in tests/unit/cluster/manual-failover.tcl
### Starting test Make instance #0 unreachable without killing it in tests/unit/cluster/manual-failover.tcl
### Starting test Send CLUSTER FAILOVER to instance #5 in tests/unit/cluster/manual-failover.tcl
### Starting test Instance #5 is still a slave after some time (no failover) in tests/unit/cluster/manual-failover.tcl
96151:M 03 May 2025 23:05:35.701 - DB 0: 14 keys (0 volatile) in 98 slots HT.
96151:M 03 May 2025 23:05:35.719 * Node 588865ad810a9a2a0c032336635c16fcfda1ae87 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as not reachable.
96151:M 03 May 2025 23:05:35.731 * Node a59eb002dc5e0d938f7c474975db2c8b6a5620b0 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as not reachable.
96151:M 03 May 2025 23:05:35.732 * Marking node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as failing (quorum reached).
96151:M 03 May 2025 23:05:35.736 # Cluster state changed: fail
96151:M 03 May 2025 23:05:35.742 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
96151:M 03 May 2025 23:05:35.809 * Failover auth granted to e2d292eade1e654dfcbaf0199c4085fd7be41119 () for epoch 10
96151:M 03 May 2025 23:05:35.841 * Cluster state changed: ok
96151:M 03 May 2025 23:05:35.914 * Node fe8678675cc9fa5a6fedbade0150f28aff7c28b6 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as not reachable.
96151:M 03 May 2025 23:05:36.306 * Node e2d292eade1e654dfcbaf0199c4085fd7be41119 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as not reachable.
### Starting test Wait for instance #0 to return back alive in tests/unit/cluster/manual-failover.tcl
96151:M 03 May 2025 23:05:40.735 - DB 0: 14 keys (0 volatile) in 98 slots HT.
96151:M 03 May 2025 23:05:42.579 - Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 has old slots configuration, sending an UPDATE message about e2d292eade1e654dfcbaf0199c4085fd7be41119
96151:M 03 May 2025 23:05:42.585 * Clear FAIL state for node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 (): primary without slots is reachable again.
96151:M 03 May 2025 23:05:42.585 * A failover occurred in shard 346ab41bb3203a84bc575e43be5ac11721355613; node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () failed over to node e2d292eade1e654dfcbaf0199c4085fd7be41119 () with a config epoch of 10
96151:M 03 May 2025 23:05:42.585 * Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () is now a replica of node e2d292eade1e654dfcbaf0199c4085fd7be41119 () in shard 346ab41bb3203a84bc575e43be5ac11721355613
### Starting test Check for memory leaks (pid 96406) in tests/unit/cluster/manual-failover.tcl
96151:M 03 May 2025 23:05:42.649 * Node e2d292eade1e654dfcbaf0199c4085fd7be41119 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () is back online.
96151:M 03 May 2025 23:05:42.783 * Node 588865ad810a9a2a0c032336635c16fcfda1ae87 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () is back online.
96151:M 03 May 2025 23:05:42.852 * Node a59eb002dc5e0d938f7c474975db2c8b6a5620b0 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () is back online.
96151:M 03 May 2025 23:05:42.874 * Node fe8678675cc9fa5a6fedbade0150f28aff7c28b6 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () is back online.
96151:M 03 May 2025 23:05:43.556 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:43.657 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
### Starting test Check for memory leaks (pid 96354) in tests/unit/cluster/manual-failover.tcl
96151:M 03 May 2025 23:05:43.758 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:43.858 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:43.960 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:44.061 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:44.162 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:44.264 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:44.365 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:44.466 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:44.567 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:44.668 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:44.769 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:44.871 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:44.872 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
### Starting test Check for memory leaks (pid 96264) in tests/unit/cluster/manual-failover.tcl
96151:M 03 May 2025 23:05:44.972 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:44.972 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:45.076 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:45.076 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:45.176 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:45.177 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:45.277 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:45.277 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:45.378 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:45.378 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:45.478 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:45.482 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:45.579 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:45.598 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:45.679 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:45.688 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:45.780 - DB 0: 14 keys (0 volatile) in 98 slots HT.
96151:M 03 May 2025 23:05:45.785 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:45.787 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:45.886 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:45.886 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:45.986 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:45.992 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:46.087 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:46.093 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:46.189 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:46.190 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:46.254 - Client closed connection id=3 addr=127.0.0.1:50410 laddr=127.0.0.1:22146 fd=14 name= age=26 idle=14 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|info user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=434 tot-net-out=13595 tot-cmds=13
96151:M 03 May 2025 23:05:46.289 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:46.294 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:46.297 - Connection with Node fe8678675cc9fa5a6fedbade0150f28aff7c28b6 at 127.0.0.1:32147 failed: Connection refused
96151:M 03 May 2025 23:05:46.390 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:46.398 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:46.400 - Connection with Node fe8678675cc9fa5a6fedbade0150f28aff7c28b6 at 127.0.0.1:32147 failed: Connection refused
96151:M 03 May 2025 23:05:46.492 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:46.492 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:46.492 - Connection with Node fe8678675cc9fa5a6fedbade0150f28aff7c28b6 at 127.0.0.1:32147 failed: Connection refused
96151:M 03 May 2025 23:05:47.431 * Node e2d292eade1e654dfcbaf0199c4085fd7be41119 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as not reachable.
96151:M 03 May 2025 23:05:47.434 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96151:M 03 May 2025 23:05:47.436 - Connection with Node 588865ad810a9a2a0c032336635c16fcfda1ae87 at 127.0.0.1:32148 failed: Connection refused
96151:M 03 May 2025 23:05:47.442 - Connection with Node fe8678675cc9fa5a6fedbade0150f28aff7c28b6 at 127.0.0.1:32147 failed: Connection refused
96151:M 03 May 2025 23:05:47.452 * Node a59eb002dc5e0d938f7c474975db2c8b6a5620b0 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as not reachable.
96151:M 03 May 2025 23:05:47.455 * Marking node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as failing (quorum reached).
96151:signal-handler (1746281147) Received SIGTERM scheduling shutdown...
96151:M 03 May 2025 23:05:47.532 * User requested shutdown...
96151:M 03 May 2025 23:05:47.533 * 1 of 1 replicas are in sync when shutting down.
96151:M 03 May 2025 23:05:47.538 * Removing the pid file.
96151:M 03 May 2025 23:05:47.541 * Saving the cluster configuration file before exiting.
96151:M 03 May 2025 23:05:47.565 * Removing the unix socket file.
96151:M 03 May 2025 23:05:47.565 # Valkey is now ready to exit, bye bye...
