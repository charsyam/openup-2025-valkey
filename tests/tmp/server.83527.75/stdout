### Starting server for test 
96354:M 03 May 2025 23:05:21.079 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
96354:M 03 May 2025 23:05:21.082 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
96354:M 03 May 2025 23:05:21.088 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=96354, just started
96354:M 03 May 2025 23:05:21.093 * Configuration loaded
96354:M 03 May 2025 23:05:21.103 * Increased maximum number of open files to 10032 (it was originally set to 256).
96354:M 03 May 2025 23:05:21.121 * monotonic clock: POSIX clock_gettime
96354:M 03 May 2025 23:05:21.137 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 22148
 |###|   .+###############+.   |###|    PID: 96354                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

96354:M 03 May 2025 23:05:21.158 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
96354:M 03 May 2025 23:05:21.170 * No cluster configuration found, I'm 588865ad810a9a2a0c032336635c16fcfda1ae87
96354:M 03 May 2025 23:05:21.261 * Server initialized
96354:M 03 May 2025 23:05:21.267 * Ready to accept connections tcp
96354:M 03 May 2025 23:05:21.273 * Ready to accept connections unix
96354:M 03 May 2025 23:05:21.351 - Accepted 127.0.0.1:50921
96354:M 03 May 2025 23:05:21.361 - Client closed connection id=2 addr=127.0.0.1:50921 laddr=127.0.0.1:22148 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
96354:M 03 May 2025 23:05:21.386 - Accepted 127.0.0.1:50942
96354:M 03 May 2025 23:05:21.750 # Missing implement of connection type tls
96354:M 03 May 2025 23:05:21.826 - Accepting cluster node connection from 127.0.0.1:51311
96354:M 03 May 2025 23:05:21.833 * IP address for this node updated to 127.0.0.1
96354:M 03 May 2025 23:05:21.937 - Accepting cluster node connection from 127.0.0.1:51413
96354:M 03 May 2025 23:05:22.070 - Accepting cluster node connection from 127.0.0.1:51481
96354:M 03 May 2025 23:05:22.074 - Accepting cluster node connection from 127.0.0.1:51511
96354:M 03 May 2025 23:05:22.077 - Accepting cluster node connection from 127.0.0.1:51516
96354:M 03 May 2025 23:05:22.077 * configEpoch collision with node a59eb002dc5e0d938f7c474975db2c8b6a5620b0 (). configEpoch set to 2
96354:M 03 May 2025 23:05:22.133 - Accepting cluster node connection from 127.0.0.1:51558
96354:M 03 May 2025 23:05:22.140 - Accepting cluster node connection from 127.0.0.1:51567
96354:M 03 May 2025 23:05:22.255 * configEpoch collision with node a59eb002dc5e0d938f7c474975db2c8b6a5620b0 (). configEpoch set to 4
96354:M 03 May 2025 23:05:22.262 - Accepting cluster node connection from 127.0.0.1:51622
96354:M 03 May 2025 23:05:22.364 - Accepting cluster node connection from 127.0.0.1:51734
96354:M 03 May 2025 23:05:22.364 * configEpoch collision with node e2d292eade1e654dfcbaf0199c4085fd7be41119 (). configEpoch set to 5
96354:M 03 May 2025 23:05:22.479 * configEpoch collision with node a21e86dd7d6844054a7c3186a4d33006a7ef97bd (). configEpoch set to 7
96354:M 03 May 2025 23:05:22.785 * Node e2d292eade1e654dfcbaf0199c4085fd7be41119 () is no longer primary of shard 256f6dcdec4fe78f1a1e4e1da9762f32a8d53933; removed all 0 slot(s) it used to own
96354:M 03 May 2025 23:05:22.785 * Node e2d292eade1e654dfcbaf0199c4085fd7be41119 () is now part of shard 346ab41bb3203a84bc575e43be5ac11721355613
96354:M 03 May 2025 23:05:22.785 * Node e2d292eade1e654dfcbaf0199c4085fd7be41119 () is now a replica of node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () in shard 346ab41bb3203a84bc575e43be5ac11721355613
96354:M 03 May 2025 23:05:22.786 - Accepted 127.0.0.1:52029
96354:M 03 May 2025 23:05:22.787 * Node cec11f5fa752abac24462ce05cbfbbcbf0f028f5 () is no longer primary of shard 938293520c68b674cb49633335610e25dd52713f; removed all 0 slot(s) it used to own
96354:M 03 May 2025 23:05:22.787 * Node cec11f5fa752abac24462ce05cbfbbcbf0f028f5 () is now part of shard c00ccb0e3de2bd2ae4befbae1ce2aca411aa8671
96354:M 03 May 2025 23:05:22.787 * Node cec11f5fa752abac24462ce05cbfbbcbf0f028f5 () is now a replica of node 588865ad810a9a2a0c032336635c16fcfda1ae87 () in shard c00ccb0e3de2bd2ae4befbae1ce2aca411aa8671
96354:M 03 May 2025 23:05:22.793 * Node 48ce29c51389b534d0e756dbed048497c93bcc04 () is no longer primary of shard ce52f3ca12bf12223b54157bb8cdc9b3aab689a5; removed all 0 slot(s) it used to own
96354:M 03 May 2025 23:05:22.794 * Node 48ce29c51389b534d0e756dbed048497c93bcc04 () is now part of shard 7a9129f307605f9fc2e9e070fc3b91cb77372395
96354:M 03 May 2025 23:05:22.797 * Node 48ce29c51389b534d0e756dbed048497c93bcc04 () is now a replica of node fe8678675cc9fa5a6fedbade0150f28aff7c28b6 () in shard 7a9129f307605f9fc2e9e070fc3b91cb77372395
96354:M 03 May 2025 23:05:22.798 * Replica 127.0.0.1:22143 asks for synchronization
96354:M 03 May 2025 23:05:22.798 * Full resync requested by replica 127.0.0.1:22143
96354:M 03 May 2025 23:05:22.798 * Replication backlog created, my new replication IDs are '62095e1df7d321763392f325e3d5373eb7153034' and '0000000000000000000000000000000000000000'
96354:M 03 May 2025 23:05:22.798 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
96354:M 03 May 2025 23:05:22.799 * Background RDB transfer started by pid 96592 to pipe through parent process
96592:C 03 May 2025 23:05:22.800 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
96354:M 03 May 2025 23:05:22.806 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
96354:M 03 May 2025 23:05:22.850 * Background RDB transfer terminated with success
96354:M 03 May 2025 23:05:22.852 * Streamed RDB transfer with replica 127.0.0.1:22143 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
96354:M 03 May 2025 23:05:22.852 * Synchronization with replica 127.0.0.1:22143 succeeded
96354:M 03 May 2025 23:05:22.853 * Node a21e86dd7d6844054a7c3186a4d33006a7ef97bd () is no longer primary of shard 74397b408645fd96aa93c7a5707da778711f43d3; removed all 0 slot(s) it used to own
96354:M 03 May 2025 23:05:22.858 * Node a21e86dd7d6844054a7c3186a4d33006a7ef97bd () is now part of shard 1aacca3a9c7a750d76f6c800a57f4c1bd132846a
96354:M 03 May 2025 23:05:22.858 * Node a21e86dd7d6844054a7c3186a4d33006a7ef97bd () is now a replica of node 571ea23bf5cdffbe95dc1727682f4f31e6399d29 () in shard 1aacca3a9c7a750d76f6c800a57f4c1bd132846a
96354:M 03 May 2025 23:05:22.871 * Node a83b12f99ba80124eba788598806542c5da37d9e () is no longer primary of shard cf87ecc3efdcdfd3cac14e27b809f09893af48d2; removed all 0 slot(s) it used to own
96354:M 03 May 2025 23:05:22.871 * Node a83b12f99ba80124eba788598806542c5da37d9e () is now part of shard 3d0e9edcdf7533db82632130cb5a60794f38dd25
96354:M 03 May 2025 23:05:22.871 * Node a83b12f99ba80124eba788598806542c5da37d9e () is now a replica of node a59eb002dc5e0d938f7c474975db2c8b6a5620b0 () in shard 3d0e9edcdf7533db82632130cb5a60794f38dd25
96354:M 03 May 2025 23:05:22.871 # DEBUG LOG: ========== I am primary 1 ==========
96354:M 03 May 2025 23:05:23.286 * Cluster state changed: ok
### Starting test Cluster is up in tests/unit/cluster/manual-failover.tcl
### Starting test Cluster is writable in tests/unit/cluster/manual-failover.tcl
96354:M 03 May 2025 23:05:32.438 - Accepted 127.0.0.1:56461
96354:M 03 May 2025 23:05:32.501 - Client closed connection id=15 addr=127.0.0.1:56461 laddr=127.0.0.1:22148 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=30 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=1671 tot-net-out=732 tot-cmds=42
### Starting test Instance #5 is a slave in tests/unit/cluster/manual-failover.tcl
### Starting test Instance #5 synced with the master in tests/unit/cluster/manual-failover.tcl
### Starting test Make instance #0 unreachable without killing it in tests/unit/cluster/manual-failover.tcl
### Starting test Send CLUSTER FAILOVER to instance #5 in tests/unit/cluster/manual-failover.tcl
### Starting test Instance #5 is still a slave after some time (no failover) in tests/unit/cluster/manual-failover.tcl
96354:M 03 May 2025 23:05:35.723 * Node 571ea23bf5cdffbe95dc1727682f4f31e6399d29 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as not reachable.
96354:M 03 May 2025 23:05:35.731 * Node a59eb002dc5e0d938f7c474975db2c8b6a5620b0 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as not reachable.
96354:M 03 May 2025 23:05:35.732 * Marking node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as failing (quorum reached).
96354:M 03 May 2025 23:05:35.736 # Cluster state changed: fail
96354:M 03 May 2025 23:05:35.741 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
96354:M 03 May 2025 23:05:35.792 * Node fe8678675cc9fa5a6fedbade0150f28aff7c28b6 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as not reachable.
96354:M 03 May 2025 23:05:35.809 * Failover auth granted to e2d292eade1e654dfcbaf0199c4085fd7be41119 () for epoch 10
96354:M 03 May 2025 23:05:35.841 * Node e2d292eade1e654dfcbaf0199c4085fd7be41119 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () as not reachable.
96354:M 03 May 2025 23:05:35.843 * Cluster state changed: ok
96354:M 03 May 2025 23:05:36.731 - DB 0: 21 keys (0 volatile) in 147 slots HT.
### Starting test Wait for instance #0 to return back alive in tests/unit/cluster/manual-failover.tcl
96354:M 03 May 2025 23:05:41.775 - DB 0: 21 keys (0 volatile) in 147 slots HT.
96354:M 03 May 2025 23:05:42.579 - Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 has old slots configuration, sending an UPDATE message about e2d292eade1e654dfcbaf0199c4085fd7be41119
### Starting test Check for memory leaks (pid 96406) in tests/unit/cluster/manual-failover.tcl
96354:M 03 May 2025 23:05:42.586 * Clear FAIL state for node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 (): primary without slots is reachable again.
96354:M 03 May 2025 23:05:42.586 * A failover occurred in shard 346ab41bb3203a84bc575e43be5ac11721355613; node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () failed over to node e2d292eade1e654dfcbaf0199c4085fd7be41119 () with a config epoch of 10
96354:M 03 May 2025 23:05:42.586 * Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () is now a replica of node e2d292eade1e654dfcbaf0199c4085fd7be41119 () in shard 346ab41bb3203a84bc575e43be5ac11721355613
96354:M 03 May 2025 23:05:42.649 * Node 571ea23bf5cdffbe95dc1727682f4f31e6399d29 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () is back online.
96354:M 03 May 2025 23:05:42.684 * Node fe8678675cc9fa5a6fedbade0150f28aff7c28b6 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () is back online.
96354:M 03 May 2025 23:05:42.783 * Node e2d292eade1e654dfcbaf0199c4085fd7be41119 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () is back online.
96354:M 03 May 2025 23:05:42.884 * Node a59eb002dc5e0d938f7c474975db2c8b6a5620b0 () reported node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 () is back online.
96354:M 03 May 2025 23:05:43.590 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96354:M 03 May 2025 23:05:43.618 - Client closed connection id=3 addr=127.0.0.1:50942 laddr=127.0.0.1:22148 fd=14 name= age=22 idle=11 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|info user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=804 tot-net-out=20711 tot-cmds=26
96354:M 03 May 2025 23:05:43.690 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96354:M 03 May 2025 23:05:43.791 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96354:M 03 May 2025 23:05:44.710 - Connection with Node eb36c71c6d2cd16ab0ad1c4e68c62360244596e2 at 127.0.0.1:32149 failed: Connection refused
96354:signal-handler (1746281144) Received SIGTERM scheduling shutdown...
96354:M 03 May 2025 23:05:44.810 * User requested shutdown...
96354:M 03 May 2025 23:05:44.811 * 1 of 1 replicas are in sync when shutting down.
96354:M 03 May 2025 23:05:44.814 * Removing the pid file.
96354:M 03 May 2025 23:05:44.815 * Saving the cluster configuration file before exiting.
96354:M 03 May 2025 23:05:44.857 * Removing the unix socket file.
96354:M 03 May 2025 23:05:44.857 # Valkey is now ready to exit, bye bye...
