### Starting server for test 
91300:M 03 May 2025 23:04:39.739 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
91300:M 03 May 2025 23:04:39.739 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
91300:M 03 May 2025 23:04:39.739 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=91300, just started
91300:M 03 May 2025 23:04:39.739 * Configuration loaded
91300:M 03 May 2025 23:04:39.739 * Increased maximum number of open files to 10032 (it was originally set to 256).
91300:M 03 May 2025 23:04:39.739 * monotonic clock: POSIX clock_gettime
91300:M 03 May 2025 23:04:39.740 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 28635
 |###|   .+###############+.   |###|    PID: 91300                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

91300:M 03 May 2025 23:04:39.740 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
91300:M 03 May 2025 23:04:39.740 * No cluster configuration found, I'm e5cc26705d29085822199dd99ce5a9bc5a6df9aa
91300:M 03 May 2025 23:04:39.751 * Server initialized
91300:M 03 May 2025 23:04:39.751 * Ready to accept connections tcp
91300:M 03 May 2025 23:04:39.751 * Ready to accept connections unix
91300:M 03 May 2025 23:04:39.909 - Accepted 127.0.0.1:63080
91300:M 03 May 2025 23:04:39.909 - Client closed connection id=2 addr=127.0.0.1:63080 laddr=127.0.0.1:28635 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
91300:M 03 May 2025 23:04:39.977 - Accepted 127.0.0.1:63100
91300:M 03 May 2025 23:04:40.174 # Missing implement of connection type tls
91300:M 03 May 2025 23:04:40.250 - Accepting cluster node connection from 127.0.0.1:63192
91300:M 03 May 2025 23:04:40.250 * IP address for this node updated to 127.0.0.1
91300:M 03 May 2025 23:04:40.368 - Accepting cluster node connection from 127.0.0.1:63228
91300:M 03 May 2025 23:04:40.368 - Accepting cluster node connection from 127.0.0.1:63231
91300:M 03 May 2025 23:04:40.421 * Node 30a81d9788723f02563dcd63a914cfdd12f80fb2 () is no longer primary of shard bf571496bad15cb7c4b3579b62f669f58c01c047; removed all 0 slot(s) it used to own
91300:M 03 May 2025 23:04:40.421 * Node 30a81d9788723f02563dcd63a914cfdd12f80fb2 () is now part of shard 4ba9a89b593207dada33f76066bff71d929cf781
91300:M 03 May 2025 23:04:40.421 * Node 30a81d9788723f02563dcd63a914cfdd12f80fb2 () is now a replica of node 53e06f1e0164b09435a1b94f41fe1c877a24a14e () in shard 4ba9a89b593207dada33f76066bff71d929cf781
91300:M 03 May 2025 23:04:40.422 - Accepted 127.0.0.1:63248
91300:M 03 May 2025 23:04:40.422 * Node 6630acb592c8ce198d10cbc4e62290707ccc392a () is no longer primary of shard adf0db3be53d8b3f6a581d47601dba8cdd8c4475; removed all 0 slot(s) it used to own
91300:M 03 May 2025 23:04:40.422 * Node 6630acb592c8ce198d10cbc4e62290707ccc392a () is now part of shard f16707f5d1867673fbbcc31b0a5ed0a2e836860b
91300:M 03 May 2025 23:04:40.422 * Node 6630acb592c8ce198d10cbc4e62290707ccc392a () is now a replica of node e5cc26705d29085822199dd99ce5a9bc5a6df9aa () in shard f16707f5d1867673fbbcc31b0a5ed0a2e836860b
91300:M 03 May 2025 23:04:40.423 # DEBUG LOG: ========== I am primary 1 ==========
91300:M 03 May 2025 23:04:40.423 * Replica 127.0.0.1:28633 asks for synchronization
91300:M 03 May 2025 23:04:40.423 * Full resync requested by replica 127.0.0.1:28633
91300:M 03 May 2025 23:04:40.423 * Replication backlog created, my new replication IDs are '04ebc97fea2823b9cfca2f016a87d7d558cdda8d' and '0000000000000000000000000000000000000000'
91300:M 03 May 2025 23:04:40.423 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
91300:M 03 May 2025 23:04:40.423 * Background RDB transfer started by pid 91386 to pipe through parent process
91386:C 03 May 2025 23:04:40.424 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
91300:M 03 May 2025 23:04:40.424 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
91300:M 03 May 2025 23:04:40.431 * Background RDB transfer terminated with success
91300:M 03 May 2025 23:04:40.431 * Streamed RDB transfer with replica 127.0.0.1:28633 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
91300:M 03 May 2025 23:04:40.431 * Synchronization with replica 127.0.0.1:28633 succeeded
91300:M 03 May 2025 23:04:41.778 * Cluster state changed: ok
### Starting test Test change cluster-announce-port and cluster-announce-tls-port at runtime in tests/unit/cluster/announced-endpoints.tcl
91300:M 03 May 2025 23:04:50.253 * Address updated for node 53e06f1e0164b09435a1b94f41fe1c877a24a14e (), now 127.0.0.1:28637
### Starting test Test change cluster-announce-bus-port at runtime in tests/unit/cluster/announced-endpoints.tcl
91300:M 03 May 2025 23:04:50.455 * Address updated for node 53e06f1e0164b09435a1b94f41fe1c877a24a14e (), now 127.0.0.1:28636
91300:M 03 May 2025 23:04:50.478 - Connection with Node 53e06f1e0164b09435a1b94f41fe1c877a24a14e at 127.0.0.1:28638 failed: Connection refused
### Starting test Check for memory leaks (pid 91318) in tests/unit/cluster/announced-endpoints.tcl
91300:M 03 May 2025 23:04:50.578 - Connection with Node 53e06f1e0164b09435a1b94f41fe1c877a24a14e at 127.0.0.1:28638 failed: Connection refused
91300:M 03 May 2025 23:04:50.656 * Address updated for node 53e06f1e0164b09435a1b94f41fe1c877a24a14e (), now 127.0.0.1:28636
91300:M 03 May 2025 23:04:52.063 - Client closed connection id=3 addr=127.0.0.1:63100 laddr=127.0.0.1:28635 fd=14 name= age=13 idle=2 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=524 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|nodes user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=717 tot-net-out=8095 tot-cmds=23
91300:M 03 May 2025 23:04:52.091 - Connection with Node 53e06f1e0164b09435a1b94f41fe1c877a24a14e at 127.0.0.1:38636 failed: Connection refused
91300:M 03 May 2025 23:04:52.192 - Connection with Node 53e06f1e0164b09435a1b94f41fe1c877a24a14e at 127.0.0.1:38636 failed: Connection refused
91300:M 03 May 2025 23:04:52.293 - Connection with Node 53e06f1e0164b09435a1b94f41fe1c877a24a14e at 127.0.0.1:38636 failed: Connection refused
91300:M 03 May 2025 23:04:52.394 - Connection with Node 53e06f1e0164b09435a1b94f41fe1c877a24a14e at 127.0.0.1:38636 failed: Connection refused
91300:M 03 May 2025 23:04:53.231 - Connection with Node 53e06f1e0164b09435a1b94f41fe1c877a24a14e at 127.0.0.1:38636 failed: Connection refused
91300:signal-handler (1746281093) Received SIGTERM scheduling shutdown...
91300:M 03 May 2025 23:04:53.332 * User requested shutdown...
91300:M 03 May 2025 23:04:53.332 * 1 of 1 replicas are in sync when shutting down.
91300:M 03 May 2025 23:04:53.332 * Removing the pid file.
91300:M 03 May 2025 23:04:53.332 * Saving the cluster configuration file before exiting.
91300:M 03 May 2025 23:04:53.337 * Removing the unix socket file.
91300:M 03 May 2025 23:04:53.337 # Valkey is now ready to exit, bye bye...
