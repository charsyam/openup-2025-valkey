### Starting server for test 
97611:M 03 May 2025 23:05:32.221 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
97611:M 03 May 2025 23:05:32.227 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
97611:M 03 May 2025 23:05:32.233 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=97611, just started
97611:M 03 May 2025 23:05:32.233 * Configuration loaded
97611:M 03 May 2025 23:05:32.236 * Increased maximum number of open files to 10032 (it was originally set to 256).
97611:M 03 May 2025 23:05:32.242 * monotonic clock: POSIX clock_gettime
97611:M 03 May 2025 23:05:32.242 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 26150
 |###|   .+###############+.   |###|    PID: 97611                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

97611:M 03 May 2025 23:05:32.251 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
97611:M 03 May 2025 23:05:32.252 * No cluster configuration found, I'm 61ebad1c32ab0f56bcc169d799fdf5943b390656
97611:M 03 May 2025 23:05:32.263 * Server initialized
97611:M 03 May 2025 23:05:32.263 * Ready to accept connections tcp
97611:M 03 May 2025 23:05:32.263 * Ready to accept connections unix
97611:M 03 May 2025 23:05:32.398 - Accepted 127.0.0.1:56455
97611:M 03 May 2025 23:05:32.403 - Client closed connection id=2 addr=127.0.0.1:56455 laddr=127.0.0.1:26150 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
97611:M 03 May 2025 23:05:32.436 - Accepted 127.0.0.1:56456
97611:M 03 May 2025 23:05:32.437 * Cluster meet 127.0.0.1:26149 (user request from 'id=3 addr=127.0.0.1:56456 laddr=127.0.0.1:26150 fd=14 name= user=default lib-name= lib-ver=').
97611:M 03 May 2025 23:05:32.437 * Cluster meet 127.0.0.1:26148 (user request from 'id=3 addr=127.0.0.1:56456 laddr=127.0.0.1:26150 fd=14 name= user=default lib-name= lib-ver=').
97611:M 03 May 2025 23:05:32.444 * Cluster meet 127.0.0.1:26147 (user request from 'id=3 addr=127.0.0.1:56456 laddr=127.0.0.1:26150 fd=14 name= user=default lib-name= lib-ver=').
97611:M 03 May 2025 23:05:32.446 * Cluster meet 127.0.0.1:26146 (user request from 'id=3 addr=127.0.0.1:56456 laddr=127.0.0.1:26150 fd=14 name= user=default lib-name= lib-ver=').
97611:M 03 May 2025 23:05:32.449 * Cluster meet 127.0.0.1:26145 (user request from 'id=3 addr=127.0.0.1:56456 laddr=127.0.0.1:26150 fd=14 name= user=default lib-name= lib-ver=').
97611:M 03 May 2025 23:05:32.454 # Missing implement of connection type tls
97611:M 03 May 2025 23:05:32.511 - Accepting cluster node connection from 127.0.0.1:56476
97611:M 03 May 2025 23:05:32.517 * IP address for this node updated to 127.0.0.1
97611:M 03 May 2025 23:05:32.520 * Successfully completed handshake with e3bb6d779447ffcb64bad56599b59fb42940ae1a ()
97611:M 03 May 2025 23:05:32.521 * configEpoch collision with node e3bb6d779447ffcb64bad56599b59fb42940ae1a (). configEpoch set to 1
97611:M 03 May 2025 23:05:32.526 - Accepting cluster node connection from 127.0.0.1:56477
97611:M 03 May 2025 23:05:32.526 - Accepting cluster node connection from 127.0.0.1:56478
97611:M 03 May 2025 23:05:32.526 * Successfully completed handshake with 88801eab5a8dae0ad83f955799cfbb8fadb0b7d8 ()
97611:M 03 May 2025 23:05:32.526 * Successfully completed handshake with dadcebac09c4e9e0b69be3fedffd453cbd7401c2 ()
97611:M 03 May 2025 23:05:32.544 - Accepting cluster node connection from 127.0.0.1:56480
97611:M 03 May 2025 23:05:32.544 * Successfully completed handshake with 328af285fe672c4fa4d2656f79e3d35e10e42319 ()
97611:M 03 May 2025 23:05:32.548 - Accepting cluster node connection from 127.0.0.1:56481
97611:M 03 May 2025 23:05:32.550 * Successfully completed handshake with edc8515691adebafcac9acf08326693e209a001f ()
97611:M 03 May 2025 23:05:32.857 - Accepted 127.0.0.1:56522
97611:M 03 May 2025 23:05:32.857 * Node 328af285fe672c4fa4d2656f79e3d35e10e42319 () is no longer primary of shard 19bd6abda69d1f27d344026e8e5505c3add4b8e9; removed all 0 slot(s) it used to own
97611:M 03 May 2025 23:05:32.857 * Node 328af285fe672c4fa4d2656f79e3d35e10e42319 () is now part of shard d17378a959bd9c70141cb7f0223169d9e42f76d1
97611:M 03 May 2025 23:05:32.857 * Node 328af285fe672c4fa4d2656f79e3d35e10e42319 () is now a replica of node 61ebad1c32ab0f56bcc169d799fdf5943b390656 () in shard d17378a959bd9c70141cb7f0223169d9e42f76d1
97611:M 03 May 2025 23:05:32.859 * Replica 127.0.0.1:26147 asks for synchronization
97611:M 03 May 2025 23:05:32.859 * Full resync requested by replica 127.0.0.1:26147
97611:M 03 May 2025 23:05:32.859 * Replication backlog created, my new replication IDs are '70f755a90ddd4d47d65fc813c37714cb6d43950e' and '0000000000000000000000000000000000000000'
97611:M 03 May 2025 23:05:32.859 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
97611:M 03 May 2025 23:05:32.860 * Background RDB transfer started by pid 97677 to pipe through parent process
97611:M 03 May 2025 23:05:32.861 * Node e3bb6d779447ffcb64bad56599b59fb42940ae1a () is no longer primary of shard 4f16abadaec1e9ea3cc65c4221498676b55b4ad1; removed all 0 slot(s) it used to own
97611:M 03 May 2025 23:05:32.861 * Node e3bb6d779447ffcb64bad56599b59fb42940ae1a () is now part of shard 83dc2bf85d4c009879ddaf68d9988e384d2f11e0
97611:M 03 May 2025 23:05:32.861 * Node e3bb6d779447ffcb64bad56599b59fb42940ae1a () is now a replica of node edc8515691adebafcac9acf08326693e209a001f () in shard 83dc2bf85d4c009879ddaf68d9988e384d2f11e0
97677:C 03 May 2025 23:05:32.861 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
97611:M 03 May 2025 23:05:32.861 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
97611:M 03 May 2025 23:05:32.861 * Node dadcebac09c4e9e0b69be3fedffd453cbd7401c2 () is no longer primary of shard 7e6c5d27cd1139519adc2275ad462ead655b469d; removed all 0 slot(s) it used to own
97611:M 03 May 2025 23:05:32.861 * Node dadcebac09c4e9e0b69be3fedffd453cbd7401c2 () is now part of shard 78a459ae2e5d41625b6dad98c71a75bf029ff542
97611:M 03 May 2025 23:05:32.861 * Node dadcebac09c4e9e0b69be3fedffd453cbd7401c2 () is now a replica of node 88801eab5a8dae0ad83f955799cfbb8fadb0b7d8 () in shard 78a459ae2e5d41625b6dad98c71a75bf029ff542
97611:M 03 May 2025 23:05:32.861 # DEBUG LOG: ========== I am primary 0 ==========
97611:M 03 May 2025 23:05:32.865 * Background RDB transfer terminated with success
97611:M 03 May 2025 23:05:32.865 * Streamed RDB transfer with replica 127.0.0.1:26147 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
97611:M 03 May 2025 23:05:32.865 * Synchronization with replica 127.0.0.1:26147 succeeded
97611:M 03 May 2025 23:05:34.296 * Cluster state changed: ok
### Starting test Cluster should start ok in tests/unit/cluster/replica-detach.tcl
### Starting test CLUSTER REPLICATE NO ONE should turn node into empty primary in tests/unit/cluster/replica-detach.tcl
97611:M 03 May 2025 23:05:42.714 - Client closed connection id=8 addr=127.0.0.1:56522 laddr=127.0.0.1:26150 fd=25 name= age=10 idle=0 flags=S capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=1 omem=16920 tot-mem=35352 events=r cmd=replconf user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=668 tot-net-out=129 tot-cmds=17
97611:M 03 May 2025 23:05:42.716 * Connection with replica 127.0.0.1:26147 lost.
97611:M 03 May 2025 23:05:42.739 - Client closed connection id=3 addr=127.0.0.1:56456 laddr=127.0.0.1:26150 fd=14 name= age=10 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=520 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|shards user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=6125 tot-net-out=258699 tot-cmds=204
97611:signal-handler (1746281143) Received SIGTERM scheduling shutdown...
97611:M 03 May 2025 23:05:43.697 * User requested shutdown...
97611:M 03 May 2025 23:05:43.699 * Removing the pid file.
97611:M 03 May 2025 23:05:43.705 * Saving the cluster configuration file before exiting.
97611:M 03 May 2025 23:05:43.745 * Removing the unix socket file.
97611:M 03 May 2025 23:05:43.746 # Valkey is now ready to exit, bye bye...
