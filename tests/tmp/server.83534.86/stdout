### Starting server for test 
97221:M 03 May 2025 23:05:29.176 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
97221:M 03 May 2025 23:05:29.176 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
97221:M 03 May 2025 23:05:29.176 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=97221, just started
97221:M 03 May 2025 23:05:29.176 * Configuration loaded
97221:M 03 May 2025 23:05:29.176 * Increased maximum number of open files to 10032 (it was originally set to 256).
97221:M 03 May 2025 23:05:29.176 * monotonic clock: POSIX clock_gettime
97221:M 03 May 2025 23:05:29.176 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 25651
 |###|   .+###############+.   |###|    PID: 97221                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

97221:M 03 May 2025 23:05:29.176 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
97221:M 03 May 2025 23:05:29.177 * No cluster configuration found, I'm 6d062984222c6b8fea11f573fcb0ebcb21d117bb
97221:M 03 May 2025 23:05:29.210 * Server initialized
97221:M 03 May 2025 23:05:29.224 * Ready to accept connections tcp
97221:M 03 May 2025 23:05:29.224 * Ready to accept connections unix
97221:M 03 May 2025 23:05:29.357 - Accepted 127.0.0.1:56165
97221:M 03 May 2025 23:05:29.362 - Client closed connection id=2 addr=127.0.0.1:56165 laddr=127.0.0.1:25651 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
97221:M 03 May 2025 23:05:29.401 - Accepted 127.0.0.1:56168
97221:M 03 May 2025 23:05:29.734 # Missing implement of connection type tls
97221:M 03 May 2025 23:05:29.746 - Accepting cluster node connection from 127.0.0.1:56236
97221:M 03 May 2025 23:05:29.747 * IP address for this node updated to 127.0.0.1
97221:M 03 May 2025 23:05:29.873 - Accepting cluster node connection from 127.0.0.1:56266
97221:M 03 May 2025 23:05:29.873 - Accepting cluster node connection from 127.0.0.1:56268
97221:M 03 May 2025 23:05:29.934 - Accepting cluster node connection from 127.0.0.1:56271
97221:M 03 May 2025 23:05:29.937 * Successfully completed handshake with 9eb390e8ded52cf641b33887797c00ff53872c26 ()
97221:M 03 May 2025 23:05:29.940 * configEpoch collision with node 9eb390e8ded52cf641b33887797c00ff53872c26 (). configEpoch set to 3
97221:M 03 May 2025 23:05:30.011 - Accepting cluster node connection from 127.0.0.1:56290
97221:M 03 May 2025 23:05:30.014 - Handshake: we already know node 7784938381600c37ae962ee96f2a2eac0a305a61 (), updating the address if needed.
97221:M 03 May 2025 23:05:30.077 - Accepting cluster node connection from 127.0.0.1:56295
97221:M 03 May 2025 23:05:30.155 * Node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () is no longer primary of shard f8b9264d350e1b6f28b56bab3263dddab7527a17; removed all 0 slot(s) it used to own
97221:M 03 May 2025 23:05:30.155 * Node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () is now part of shard 30fd42788a34ad1993a9d803fc85dc59ab50a555
97221:M 03 May 2025 23:05:30.155 * Node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () is now a replica of node 13aa946ae073b283903d0b625ce1c86adb50c18e () in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555
97221:M 03 May 2025 23:05:30.159 - Accepted 127.0.0.1:56307
97221:M 03 May 2025 23:05:30.160 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () is no longer primary of shard ec45c5094d9c5aa67b32f0a89ad6ef1885439f7f; removed all 0 slot(s) it used to own
97221:M 03 May 2025 23:05:30.160 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () is now part of shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853
97221:M 03 May 2025 23:05:30.160 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () is now a replica of node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853
97221:M 03 May 2025 23:05:30.168 * Replica 127.0.0.1:25648 asks for synchronization
97221:M 03 May 2025 23:05:30.169 * Full resync requested by replica 127.0.0.1:25648
97221:M 03 May 2025 23:05:30.169 * Replication backlog created, my new replication IDs are 'aab8bd0a4d5504697c804fe379ec88ad4cadb3ba' and '0000000000000000000000000000000000000000'
97221:M 03 May 2025 23:05:30.169 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
97221:M 03 May 2025 23:05:30.172 * Background RDB transfer started by pid 97276 to pipe through parent process
97276:C 03 May 2025 23:05:30.173 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
97221:M 03 May 2025 23:05:30.174 * Node 3db47b5fc2b7f4cbe1582927946a84d5c923646e () is no longer primary of shard 18d4d063be1d57c64b124b0528cd553b3fed1068; removed all 0 slot(s) it used to own
97221:M 03 May 2025 23:05:30.179 * Node 3db47b5fc2b7f4cbe1582927946a84d5c923646e () is now part of shard 0618c300f6ba0c0f36756b1aa5de671e6ee48e93
97221:M 03 May 2025 23:05:30.188 * Node 3db47b5fc2b7f4cbe1582927946a84d5c923646e () is now a replica of node 9eb390e8ded52cf641b33887797c00ff53872c26 () in shard 0618c300f6ba0c0f36756b1aa5de671e6ee48e93
97221:M 03 May 2025 23:05:30.194 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
97221:M 03 May 2025 23:05:30.209 * Background RDB transfer terminated with success
97221:M 03 May 2025 23:05:30.211 * Streamed RDB transfer with replica 127.0.0.1:25648 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
97221:M 03 May 2025 23:05:30.211 * Synchronization with replica 127.0.0.1:25648 succeeded
97221:M 03 May 2025 23:05:30.211 # DEBUG LOG: ========== I am primary 1 ==========
97221:M 03 May 2025 23:05:31.272 * Cluster state changed: ok
### Starting test Slot migration states are replicated in tests/unit/cluster/slot-migration.tcl
97221:M 03 May 2025 23:05:39.846 * Importing slot 609 from node 13aa946ae073b283903d0b625ce1c86adb50c18e ()
### Starting test Migration target is auto-updated after failover in target shard in tests/unit/cluster/slot-migration.tcl
97221:M 03 May 2025 23:05:42.866 - Accepting cluster node connection from 127.0.0.1:57051
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57052
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57061
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57065
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57073
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57121
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57122
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57126
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57127
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57128
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57173
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57174
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57178
97221:M 03 May 2025 23:05:42.868 - Accepting cluster node connection from 127.0.0.1:57179
97221:M 03 May 2025 23:05:42.868 - Client closed connection id=9 addr=127.0.0.1:56307 laddr=127.0.0.1:25651 fd=25 name= age=12 idle=0 flags=S capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=1 omem=16920 tot-mem=35352 events=r cmd=replconf user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=776 tot-net-out=202 tot-cmds=20
97221:M 03 May 2025 23:05:42.868 * Connection with replica 127.0.0.1:25648 lost.
97221:M 03 May 2025 23:05:42.868 # Failover auth denied to 7784938381600c37ae962ee96f2a2eac0a305a61 () for epoch 6: its primary is up
97221:M 03 May 2025 23:05:42.868 * Configuration change detected. Reconfiguring myself as a replica of node 7784938381600c37ae962ee96f2a2eac0a305a61 () in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853
97221:S 03 May 2025 23:05:42.868 * Before turning into a replica, using my own primary parameters to synthesize a cached primary: I may be able to synchronize with the new primary with just a partial transfer.
97221:S 03 May 2025 23:05:42.868 * Connecting to PRIMARY 127.0.0.1:25648
97221:S 03 May 2025 23:05:42.868 * PRIMARY <-> REPLICA sync started
97221:S 03 May 2025 23:05:42.890 * Non blocking connect for SYNC fired the event.
97221:S 03 May 2025 23:05:42.892 - Accepting cluster node connection from 127.0.0.1:57187
97221:S 03 May 2025 23:05:42.905 * Primary replied to PING, replication can continue...
97221:S 03 May 2025 23:05:42.905 * Trying a partial resynchronization (request aab8bd0a4d5504697c804fe379ec88ad4cadb3ba:176).
97221:S 03 May 2025 23:05:42.905 * Successful partial resynchronization with primary.
97221:S 03 May 2025 23:05:42.905 * Primary replication ID changed to 50cd8db6fc263b02b8b133c6f92f97c13fd213b3
97221:S 03 May 2025 23:05:42.905 * PRIMARY <-> REPLICA sync: Primary accepted a Partial Resynchronization.
97221:S 03 May 2025 23:05:43.003 * Manual failover user request accepted (user request from 'id=3 addr=127.0.0.1:56168 laddr=127.0.0.1:25651 fd=14 name= user=default lib-name= lib-ver=').
97221:S 03 May 2025 23:05:43.012 * Received replication offset for paused primary manual failover: 175
97221:S 03 May 2025 23:05:43.014 * All primary replication stream processed, manual failover can start.
97221:S 03 May 2025 23:05:43.014 * Start of election delayed for 0 milliseconds (rank #0, primary rank #0, offset 175).
97221:S 03 May 2025 23:05:43.014 * Starting a failover election for epoch 7, node config epoch is 6
97221:S 03 May 2025 23:05:43.034 * Failover election won: I'm the new primary.
97221:S 03 May 2025 23:05:43.035 * configEpoch set to 7 after successful failover
97221:S 03 May 2025 23:05:43.035 * Setting myself to primary in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853 after failover; my old primary is 7784938381600c37ae962ee96f2a2eac0a305a61 ()
97221:M 03 May 2025 23:05:43.035 * Connection with primary lost.
97221:M 03 May 2025 23:05:43.035 * Caching the disconnected primary state.
97221:M 03 May 2025 23:05:43.035 * Discarding previously cached primary state.
97221:M 03 May 2025 23:05:43.038 * Setting secondary replication ID to 50cd8db6fc263b02b8b133c6f92f97c13fd213b3, valid up to offset: 176. New replication ID is f765a1c34cb0c4a0c39b87b5215570f84e9b866f
97221:M 03 May 2025 23:05:43.051 - Accepted 127.0.0.1:57193
97221:M 03 May 2025 23:05:43.072 * A failover occurred in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853; node 7784938381600c37ae962ee96f2a2eac0a305a61 () failed over to node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () with a config epoch of 7
97221:M 03 May 2025 23:05:43.072 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () is now a replica of node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853
97221:M 03 May 2025 23:05:43.074 * Replica 127.0.0.1:25648 asks for synchronization
97221:M 03 May 2025 23:05:43.074 * Partial resynchronization request from 127.0.0.1:25648 accepted. Sending 0 bytes of backlog starting from offset 176.
### Starting test Migration source is auto-updated after failover in source shard in tests/unit/cluster/slot-migration.tcl
97221:M 03 May 2025 23:05:44.379 * Node 9eb390e8ded52cf641b33887797c00ff53872c26 () reported node 13aa946ae073b283903d0b625ce1c86adb50c18e () as not reachable.
97221:M 03 May 2025 23:05:44.382 * Marking node 13aa946ae073b283903d0b625ce1c86adb50c18e () as failing (quorum reached).
97221:M 03 May 2025 23:05:44.384 # Cluster state changed: fail
97221:M 03 May 2025 23:05:44.396 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
97221:M 03 May 2025 23:05:45.511 * Failover auth granted to 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () for epoch 8
97221:M 03 May 2025 23:05:45.531 * Failover occurred in migration source. Update importing source for slot 609 to node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555.
97221:M 03 May 2025 23:05:45.533 * Cluster state changed: ok
97221:M 03 May 2025 23:05:45.665 * Node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () reported node 13aa946ae073b283903d0b625ce1c86adb50c18e () as not reachable.
97221:M 03 May 2025 23:05:46.184 - Node 13aa946ae073b283903d0b625ce1c86adb50c18e has old slots configuration, sending an UPDATE message about 940f25bab80d655fae5d2c00f7e5d053f18a0aa3
97221:M 03 May 2025 23:05:46.193 * Clear FAIL state for node 13aa946ae073b283903d0b625ce1c86adb50c18e (): primary without slots is reachable again.
97221:M 03 May 2025 23:05:46.193 * A failover occurred in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555; node 13aa946ae073b283903d0b625ce1c86adb50c18e () failed over to node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () with a config epoch of 8
97221:M 03 May 2025 23:05:46.193 * Node 13aa946ae073b283903d0b625ce1c86adb50c18e () is now a replica of node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555
97221:M 03 May 2025 23:05:46.201 * Node 9eb390e8ded52cf641b33887797c00ff53872c26 () reported node 13aa946ae073b283903d0b625ce1c86adb50c18e () is back online.
97221:M 03 May 2025 23:05:46.314 * Failover auth granted to 13aa946ae073b283903d0b625ce1c86adb50c18e () for epoch 9
97221:M 03 May 2025 23:05:46.344 * Failover occurred in migration source. Update importing source for slot 609 to node 13aa946ae073b283903d0b625ce1c86adb50c18e () in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555.
97221:M 03 May 2025 23:05:46.406 * A failover occurred in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555; node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () failed over to node 13aa946ae073b283903d0b625ce1c86adb50c18e () with a config epoch of 9
97221:M 03 May 2025 23:05:46.406 * Node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () is now a replica of node 13aa946ae073b283903d0b625ce1c86adb50c18e () in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555
97221:M 03 May 2025 23:05:46.406 * Node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () reported node 13aa946ae073b283903d0b625ce1c86adb50c18e () is back online.
### Starting test Replica redirects key access in migrating slots in tests/unit/cluster/slot-migration.tcl
### Starting test Replica of migrating node returns ASK redirect after READONLY in tests/unit/cluster/slot-migration.tcl
### Starting test Replica of migrating node returns TRYAGAIN after READONLY in tests/unit/cluster/slot-migration.tcl
### Starting test Replica of importing node returns TRYAGAIN after READONLY and ASKING in tests/unit/cluster/slot-migration.tcl
### Starting test New replica inherits migrating slot in tests/unit/cluster/slot-migration.tcl
97221:M 03 May 2025 23:05:46.612 - Accepting cluster node connection from 127.0.0.1:58091
97221:M 03 May 2025 23:05:46.783 * A failover occurred in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555; node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () failed over to node 13aa946ae073b283903d0b625ce1c86adb50c18e () with a config epoch of 9
97221:M 03 May 2025 23:05:46.786 * Node 940f25bab80d655fae5d2c00f7e5d053f18a0aa3 () is now a replica of node 13aa946ae073b283903d0b625ce1c86adb50c18e () in shard 30fd42788a34ad1993a9d803fc85dc59ab50a555
### Starting test New replica inherits importing slot in tests/unit/cluster/slot-migration.tcl
97221:M 03 May 2025 23:05:46.961 - Client closed connection id=13 addr=127.0.0.1:57193 laddr=127.0.0.1:25651 fd=15 name= age=3 idle=0 flags=S capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=20 obl=0 oll=1 omem=16920 tot-mem=35352 events=r cmd=replconf user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=478 tot-net-out=27 tot-cmds=10
97221:M 03 May 2025 23:05:46.961 * Connection with replica 127.0.0.1:25648 lost.
97221:M 03 May 2025 23:05:47.037 - Accepting cluster node connection from 127.0.0.1:58234
97221:M 03 May 2025 23:05:47.041 * Freeing outbound link to node 7784938381600c37ae962ee96f2a2eac0a305a61 () after receiving a MEET packet from this known node
97221:M 03 May 2025 23:05:47.193 - Accepted 127.0.0.1:58285
97221:M 03 May 2025 23:05:47.214 * A failover occurred in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853; node 7784938381600c37ae962ee96f2a2eac0a305a61 () failed over to node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () with a config epoch of 7
97221:M 03 May 2025 23:05:47.216 * Node 7784938381600c37ae962ee96f2a2eac0a305a61 () is now a replica of node 6d062984222c6b8fea11f573fcb0ebcb21d117bb () in shard 17aa912c73fdfd2f9d07ca60ab9e8177abdb5853
97221:M 03 May 2025 23:05:47.221 * Replica 127.0.0.1:25648 asks for synchronization
97221:M 03 May 2025 23:05:47.221 * Full resync requested by replica 127.0.0.1:25648
97221:M 03 May 2025 23:05:47.221 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
97221:M 03 May 2025 23:05:47.222 * Background RDB transfer started by pid 98497 to pipe through parent process
98497:C 03 May 2025 23:05:47.225 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
97221:M 03 May 2025 23:05:47.225 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
97221:M 03 May 2025 23:05:47.228 * Background RDB transfer terminated with success
97221:M 03 May 2025 23:05:47.228 * Streamed RDB transfer with replica 127.0.0.1:25648 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
97221:M 03 May 2025 23:05:47.228 * Synchronization with replica 127.0.0.1:25648 succeeded
### Starting test Check for memory leaks (pid 97246) in tests/unit/cluster/slot-migration.tcl
97221:M 03 May 2025 23:05:48.624 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97221:M 03 May 2025 23:05:48.647 - Client closed connection id=3 addr=127.0.0.1:56168 laddr=127.0.0.1:25651 fd=14 name= age=19 idle=1 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=799 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|slots user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=2180 tot-net-out=58251 tot-cmds=76
97221:M 03 May 2025 23:05:48.726 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97221:M 03 May 2025 23:05:48.826 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97221:M 03 May 2025 23:05:49.686 - Accepting cluster node connection from 127.0.0.1:59279
97221:M 03 May 2025 23:05:49.686 - Accepting cluster node connection from 127.0.0.1:59293
97221:M 03 May 2025 23:05:49.686 - Accepting cluster node connection from 127.0.0.1:59301
97221:M 03 May 2025 23:05:49.686 - Accepting cluster node connection from 127.0.0.1:59302
97221:M 03 May 2025 23:05:49.686 - Connection with Node 13aa946ae073b283903d0b625ce1c86adb50c18e at 127.0.0.1:35652 failed: Connection refused
97221:signal-handler (1746281149) Received SIGTERM scheduling shutdown...
97221:M 03 May 2025 23:05:49.787 * User requested shutdown...
97221:M 03 May 2025 23:05:49.791 * 1 of 1 replicas are in sync when shutting down.
97221:M 03 May 2025 23:05:49.792 * Removing the pid file.
97221:M 03 May 2025 23:05:49.797 * Saving the cluster configuration file before exiting.
97221:M 03 May 2025 23:05:49.823 * Removing the unix socket file.
97221:M 03 May 2025 23:05:49.826 # Valkey is now ready to exit, bye bye...
