### Starting server for test 
93753:M 03 May 2025 23:04:55.968 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
93753:M 03 May 2025 23:04:55.968 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
93753:M 03 May 2025 23:04:55.968 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=93753, just started
93753:M 03 May 2025 23:04:55.968 * Configuration loaded
93753:M 03 May 2025 23:04:55.969 * Increased maximum number of open files to 10032 (it was originally set to 256).
93753:M 03 May 2025 23:04:55.969 * monotonic clock: POSIX clock_gettime
93753:M 03 May 2025 23:04:55.969 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 22632
 |###|   .+###############+.   |###|    PID: 93753                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

93753:M 03 May 2025 23:04:55.969 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
93753:M 03 May 2025 23:04:55.969 * No cluster configuration found, I'm ee4ccc5a6d936404247b201b6e32f693b0724a41
93753:M 03 May 2025 23:04:55.976 * Server initialized
93753:M 03 May 2025 23:04:55.976 * Ready to accept connections tcp
93753:M 03 May 2025 23:04:55.976 * Ready to accept connections unix
93753:M 03 May 2025 23:04:56.104 - Accepted 127.0.0.1:52354
93753:M 03 May 2025 23:04:56.105 - Client closed connection id=2 addr=127.0.0.1:52354 laddr=127.0.0.1:22632 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
93753:M 03 May 2025 23:04:56.111 - Accepted 127.0.0.1:52358
93753:M 03 May 2025 23:04:56.111 * Cluster meet 127.0.0.1:22631 (user request from 'id=3 addr=127.0.0.1:52358 laddr=127.0.0.1:22632 fd=14 name= user=default lib-name= lib-ver=').
93753:M 03 May 2025 23:04:56.111 * Cluster meet 127.0.0.1:22630 (user request from 'id=3 addr=127.0.0.1:52358 laddr=127.0.0.1:22632 fd=14 name= user=default lib-name= lib-ver=').
93753:M 03 May 2025 23:04:56.111 * Cluster meet 127.0.0.1:22629 (user request from 'id=3 addr=127.0.0.1:52358 laddr=127.0.0.1:22632 fd=14 name= user=default lib-name= lib-ver=').
93753:M 03 May 2025 23:04:56.111 * Cluster meet 127.0.0.1:22628 (user request from 'id=3 addr=127.0.0.1:52358 laddr=127.0.0.1:22632 fd=14 name= user=default lib-name= lib-ver=').
93753:M 03 May 2025 23:04:56.111 * Cluster meet 127.0.0.1:22627 (user request from 'id=3 addr=127.0.0.1:52358 laddr=127.0.0.1:22632 fd=14 name= user=default lib-name= lib-ver=').
93753:M 03 May 2025 23:04:56.111 * Cluster meet 127.0.0.1:22626 (user request from 'id=3 addr=127.0.0.1:52358 laddr=127.0.0.1:22632 fd=14 name= user=default lib-name= lib-ver=').
93753:M 03 May 2025 23:04:56.111 * Cluster meet 127.0.0.1:22625 (user request from 'id=3 addr=127.0.0.1:52358 laddr=127.0.0.1:22632 fd=14 name= user=default lib-name= lib-ver=').
93753:M 03 May 2025 23:04:56.112 * Cluster meet 127.0.0.1:22624 (user request from 'id=3 addr=127.0.0.1:52358 laddr=127.0.0.1:22632 fd=14 name= user=default lib-name= lib-ver=').
93753:M 03 May 2025 23:04:56.112 * Cluster meet 127.0.0.1:22623 (user request from 'id=3 addr=127.0.0.1:52358 laddr=127.0.0.1:22632 fd=14 name= user=default lib-name= lib-ver=').
93753:M 03 May 2025 23:04:56.115 # Missing implement of connection type tls
93753:M 03 May 2025 23:04:56.216 - Accepting cluster node connection from 127.0.0.1:52390
93753:M 03 May 2025 23:04:56.219 - Accepting cluster node connection from 127.0.0.1:52392
93753:M 03 May 2025 23:04:56.219 - Accepting cluster node connection from 127.0.0.1:52402
93753:M 03 May 2025 23:04:56.219 - Accepting cluster node connection from 127.0.0.1:52410
93753:M 03 May 2025 23:04:56.227 - Accepting cluster node connection from 127.0.0.1:52411
93753:M 03 May 2025 23:04:56.227 * IP address for this node updated to 127.0.0.1
93753:M 03 May 2025 23:04:56.227 * Successfully completed handshake with b7470143c5f83f42722b2d696aafeb0bd4f348e3 ()
93753:M 03 May 2025 23:04:56.228 * Successfully completed handshake with 6295864ec3c9949038d513009b5a7c55872bce92 ()
93753:M 03 May 2025 23:04:56.228 * Successfully completed handshake with 5c5a87336b901d9a4e756e2c03feb8799b7d83a1 ()
93753:M 03 May 2025 23:04:56.230 * Successfully completed handshake with 31cef9dc1eb9c67121a78fd47f78868b79215218 ()
93753:M 03 May 2025 23:04:56.238 - Accepting cluster node connection from 127.0.0.1:52412
93753:M 03 May 2025 23:04:56.238 * Successfully completed handshake with 1577ce30b9c4a409f8eb045b153b411d05d56e42 ()
93753:M 03 May 2025 23:04:56.244 - Accepting cluster node connection from 127.0.0.1:52414
93753:M 03 May 2025 23:04:56.244 * Successfully completed handshake with 28c2c91c3f5ee32b542379c011d4bfed4a6ad3cb ()
93753:M 03 May 2025 23:04:56.249 - Accepting cluster node connection from 127.0.0.1:52416
93753:M 03 May 2025 23:04:56.249 * Successfully completed handshake with 3c13ef7226f612b882c2b069c890d1bbb9ebdfd7 ()
93753:M 03 May 2025 23:04:56.254 * Successfully completed handshake with 4b4fee13ab875650b5390cd60807b5a566ebf1d9 ()
93753:M 03 May 2025 23:04:56.276 - Accepting cluster node connection from 127.0.0.1:52421
93753:M 03 May 2025 23:04:56.276 * Successfully completed handshake with 418a5eac53699187f5e14aab75c43cdfd6198697 ()
93753:M 03 May 2025 23:04:57.486 - Accepted 127.0.0.1:52745
93753:M 03 May 2025 23:04:57.486 * Node 4b4fee13ab875650b5390cd60807b5a566ebf1d9 () is no longer primary of shard 94852696d53e613ed21c345dfadf758bf73be084; removed all 0 slot(s) it used to own
93753:M 03 May 2025 23:04:57.486 * Node 4b4fee13ab875650b5390cd60807b5a566ebf1d9 () is now part of shard 693ce90d8d143da7abb4eba7ef1ac5064ab479b7
93753:M 03 May 2025 23:04:57.486 * Node 4b4fee13ab875650b5390cd60807b5a566ebf1d9 () is now a replica of node ee4ccc5a6d936404247b201b6e32f693b0724a41 () in shard 693ce90d8d143da7abb4eba7ef1ac5064ab479b7
93753:M 03 May 2025 23:04:57.489 * Node b7470143c5f83f42722b2d696aafeb0bd4f348e3 () is no longer primary of shard 4ec94ee2bcf10cfbf2eeeed2d2e4f82abb93c9f0; removed all 0 slot(s) it used to own
93753:M 03 May 2025 23:04:57.489 * Node b7470143c5f83f42722b2d696aafeb0bd4f348e3 () is now part of shard 97dee9df9ba74d9f2c875e795c5906b3dbf0d0ee
93753:M 03 May 2025 23:04:57.489 * Node b7470143c5f83f42722b2d696aafeb0bd4f348e3 () is now a replica of node 1577ce30b9c4a409f8eb045b153b411d05d56e42 () in shard 97dee9df9ba74d9f2c875e795c5906b3dbf0d0ee
93753:M 03 May 2025 23:04:57.489 * Replica 127.0.0.1:22625 asks for synchronization
93753:M 03 May 2025 23:04:57.489 * Full resync requested by replica 127.0.0.1:22625
93753:M 03 May 2025 23:04:57.489 * Replication backlog created, my new replication IDs are '5fa5195ae111e89f40b07402d7e7b68ac01b8003' and '0000000000000000000000000000000000000000'
93753:M 03 May 2025 23:04:57.489 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
93753:M 03 May 2025 23:04:57.492 * Background RDB transfer started by pid 93881 to pipe through parent process
93753:M 03 May 2025 23:04:57.492 * Node 31cef9dc1eb9c67121a78fd47f78868b79215218 () is no longer primary of shard 13d255b78e355c132fed9be710c3f45e285808ff; removed all 0 slot(s) it used to own
93753:M 03 May 2025 23:04:57.492 * Node 31cef9dc1eb9c67121a78fd47f78868b79215218 () is now part of shard fab5abc4871e9d7bac3be8c0d5781119d1f6a898
93753:M 03 May 2025 23:04:57.492 * Node 31cef9dc1eb9c67121a78fd47f78868b79215218 () is now a replica of node 418a5eac53699187f5e14aab75c43cdfd6198697 () in shard fab5abc4871e9d7bac3be8c0d5781119d1f6a898
93881:C 03 May 2025 23:04:57.492 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
93753:M 03 May 2025 23:04:57.493 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
93753:M 03 May 2025 23:04:57.494 # DEBUG LOG: ========== I am primary 0 ==========
93753:M 03 May 2025 23:04:57.500 * Background RDB transfer terminated with success
93753:M 03 May 2025 23:04:57.500 * Streamed RDB transfer with replica 127.0.0.1:22625 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
93753:M 03 May 2025 23:04:57.500 * Synchronization with replica 127.0.0.1:22625 succeeded
93753:M 03 May 2025 23:04:58.040 * Cluster state changed: ok
### Starting test Primaries will not time out then they are elected in the same epoch in tests/unit/cluster/failover2.tcl
93753:M 03 May 2025 23:05:15.383 - Accepting cluster node connection from 127.0.0.1:59592
93753:M 03 May 2025 23:05:15.388 - Accepting cluster node connection from 127.0.0.1:59618
93753:M 03 May 2025 23:05:15.391 - Accepting cluster node connection from 127.0.0.1:59625
93753:M 03 May 2025 23:05:15.391 - Accepting cluster node connection from 127.0.0.1:59657
93753:M 03 May 2025 23:05:15.394 - Accepting cluster node connection from 127.0.0.1:59658
93753:M 03 May 2025 23:05:15.397 - Accepting cluster node connection from 127.0.0.1:59659
93753:M 03 May 2025 23:05:15.397 - Accepting cluster node connection from 127.0.0.1:59693
93753:M 03 May 2025 23:05:15.397 - Client closed connection id=23 addr=127.0.0.1:52745 laddr=127.0.0.1:22632 fd=33 name= age=18 idle=0 flags=S capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=1 omem=16920 tot-mem=35352 events=r cmd=replconf user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=913 tot-net-out=41 tot-cmds=24
93753:M 03 May 2025 23:05:15.397 * Connection with replica 127.0.0.1:22625 lost.
93753:M 03 May 2025 23:05:15.397 # Failover auth denied to 4b4fee13ab875650b5390cd60807b5a566ebf1d9 () for epoch 10: its primary is up
93753:M 03 May 2025 23:05:15.397 * FAIL message received from 4b4fee13ab875650b5390cd60807b5a566ebf1d9 () about 1577ce30b9c4a409f8eb045b153b411d05d56e42 ()
93753:M 03 May 2025 23:05:15.397 * Configuration change detected. Reconfiguring myself as a replica of node 4b4fee13ab875650b5390cd60807b5a566ebf1d9 () in shard 693ce90d8d143da7abb4eba7ef1ac5064ab479b7
93753:S 03 May 2025 23:05:15.397 * Before turning into a replica, using my own primary parameters to synthesize a cached primary: I may be able to synchronize with the new primary with just a partial transfer.
93753:S 03 May 2025 23:05:15.397 * Connecting to PRIMARY 127.0.0.1:22625
93753:S 03 May 2025 23:05:15.397 * PRIMARY <-> REPLICA sync started
93753:S 03 May 2025 23:05:15.397 * Node 4b4fee13ab875650b5390cd60807b5a566ebf1d9 () reported node 1577ce30b9c4a409f8eb045b153b411d05d56e42 () as not reachable.
93753:S 03 May 2025 23:05:15.397 * FAIL message received from b7470143c5f83f42722b2d696aafeb0bd4f348e3 () about 418a5eac53699187f5e14aab75c43cdfd6198697 ()
93753:S 03 May 2025 23:05:15.397 * Node b7470143c5f83f42722b2d696aafeb0bd4f348e3 () reported node 1577ce30b9c4a409f8eb045b153b411d05d56e42 () as not reachable.
93753:S 03 May 2025 23:05:15.397 * Node b7470143c5f83f42722b2d696aafeb0bd4f348e3 () reported node 418a5eac53699187f5e14aab75c43cdfd6198697 () as not reachable.
93753:S 03 May 2025 23:05:15.404 * Non blocking connect for SYNC fired the event.
93753:S 03 May 2025 23:05:15.404 * Node 4b4fee13ab875650b5390cd60807b5a566ebf1d9 () reported node 418a5eac53699187f5e14aab75c43cdfd6198697 () as not reachable.
93753:S 03 May 2025 23:05:15.406 - Node 1577ce30b9c4a409f8eb045b153b411d05d56e42 has old slots configuration, sending an UPDATE message about b7470143c5f83f42722b2d696aafeb0bd4f348e3
93753:S 03 May 2025 23:05:15.406 * Primary replied to PING, replication can continue...
93753:S 03 May 2025 23:05:15.409 * Clear FAIL state for node 1577ce30b9c4a409f8eb045b153b411d05d56e42 (): primary without slots is reachable again.
93753:S 03 May 2025 23:05:15.409 - Node 1577ce30b9c4a409f8eb045b153b411d05d56e42 has old slots configuration, sending an UPDATE message about b7470143c5f83f42722b2d696aafeb0bd4f348e3
93753:S 03 May 2025 23:05:15.412 * A failover occurred in shard 97dee9df9ba74d9f2c875e795c5906b3dbf0d0ee; node 1577ce30b9c4a409f8eb045b153b411d05d56e42 () failed over to node b7470143c5f83f42722b2d696aafeb0bd4f348e3 () with a config epoch of 11
93753:S 03 May 2025 23:05:15.412 * Node 1577ce30b9c4a409f8eb045b153b411d05d56e42 () is now a replica of node b7470143c5f83f42722b2d696aafeb0bd4f348e3 () in shard 97dee9df9ba74d9f2c875e795c5906b3dbf0d0ee
93753:S 03 May 2025 23:05:15.412 * Trying a partial resynchronization (request 5fa5195ae111e89f40b07402d7e7b68ac01b8003:15).
93753:S 03 May 2025 23:05:15.414 * Successful partial resynchronization with primary.
93753:S 03 May 2025 23:05:15.414 * Primary replication ID changed to a991e90565f6fbdb9e7cf84f37cc5b3571f2fcdd
93753:S 03 May 2025 23:05:15.414 * PRIMARY <-> REPLICA sync: Primary accepted a Partial Resynchronization.
93753:S 03 May 2025 23:05:15.420 - Node 418a5eac53699187f5e14aab75c43cdfd6198697 has old slots configuration, sending an UPDATE message about 31cef9dc1eb9c67121a78fd47f78868b79215218
93753:S 03 May 2025 23:05:15.420 * Clear FAIL state for node 418a5eac53699187f5e14aab75c43cdfd6198697 (): primary without slots is reachable again.
93753:S 03 May 2025 23:05:15.420 - Node 418a5eac53699187f5e14aab75c43cdfd6198697 has old slots configuration, sending an UPDATE message about 31cef9dc1eb9c67121a78fd47f78868b79215218
93753:S 03 May 2025 23:05:15.424 - Client closed connection id=3 addr=127.0.0.1:52358 laddr=127.0.0.1:22632 fd=14 name= age=19 idle=8 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|info user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7400 tot-net-out=496548 tot-cmds=247
93753:S 03 May 2025 23:05:15.433 * A failover occurred in shard fab5abc4871e9d7bac3be8c0d5781119d1f6a898; node 418a5eac53699187f5e14aab75c43cdfd6198697 () failed over to node 31cef9dc1eb9c67121a78fd47f78868b79215218 () with a config epoch of 12
93753:S 03 May 2025 23:05:15.433 * Node 418a5eac53699187f5e14aab75c43cdfd6198697 () is now a replica of node 31cef9dc1eb9c67121a78fd47f78868b79215218 () in shard fab5abc4871e9d7bac3be8c0d5781119d1f6a898
93753:S 03 May 2025 23:05:17.464 * Node b7470143c5f83f42722b2d696aafeb0bd4f348e3 () reported node 418a5eac53699187f5e14aab75c43cdfd6198697 () is back online.
93753:signal-handler (1746281117) Received SIGTERM scheduling shutdown...
93753:S 03 May 2025 23:05:17.565 * User requested shutdown...
93753:S 03 May 2025 23:05:17.566 * Removing the pid file.
93753:S 03 May 2025 23:05:17.566 * Saving the cluster configuration file before exiting.
93753:S 03 May 2025 23:05:17.575 * Removing the unix socket file.
93753:S 03 May 2025 23:05:17.575 # Valkey is now ready to exit, bye bye...
