### Starting server for test 
93006:M 03 May 2025 23:04:51.970 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
93006:M 03 May 2025 23:04:51.970 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
93006:M 03 May 2025 23:04:51.970 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=93006, just started
93006:M 03 May 2025 23:04:51.970 * Configuration loaded
93006:M 03 May 2025 23:04:51.970 * Increased maximum number of open files to 10032 (it was originally set to 256).
93006:M 03 May 2025 23:04:51.970 * monotonic clock: POSIX clock_gettime
93006:M 03 May 2025 23:04:51.970 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 22137
 |###|   .+###############+.   |###|    PID: 93006                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

93006:M 03 May 2025 23:04:51.970 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
93006:M 03 May 2025 23:04:51.971 * No cluster configuration found, I'm 5fddd6dd16d05f5149c7627c89ab22057d4fdf10
93006:M 03 May 2025 23:04:51.977 * Server initialized
93006:M 03 May 2025 23:04:51.977 * Ready to accept connections tcp
93006:M 03 May 2025 23:04:51.977 * Ready to accept connections unix
93006:M 03 May 2025 23:04:52.110 - Accepted 127.0.0.1:51113
93006:M 03 May 2025 23:04:52.110 - Client closed connection id=2 addr=127.0.0.1:51113 laddr=127.0.0.1:22137 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
93006:M 03 May 2025 23:04:52.125 - Accepted 127.0.0.1:51124
93006:M 03 May 2025 23:04:52.544 - Accepting cluster node connection from 127.0.0.1:51281
93006:M 03 May 2025 23:04:52.544 * IP address for this node updated to 127.0.0.1
93006:M 03 May 2025 23:04:52.691 - Accepting cluster node connection from 127.0.0.1:51366
93006:M 03 May 2025 23:04:52.692 - Accepting cluster node connection from 127.0.0.1:51372
93006:M 03 May 2025 23:04:52.697 * Successfully completed handshake with 5cd2dce60033fcc4ef63956b3ed3b6b352d7a502 ()
93006:M 03 May 2025 23:04:52.720 * Successfully completed handshake with 35e3684d330845aab3b3b8c8222bd0cf0426307c ()
93006:M 03 May 2025 23:04:52.720 * configEpoch collision with node ef1e567d8f1512b87be09ea15d7c35e6bf67fb7e (). configEpoch set to 2
93006:M 03 May 2025 23:04:52.720 * configEpoch collision with node 6cc182f5fd9d241f33f71e47c38b512e9b5263ad (). configEpoch set to 3
93006:M 03 May 2025 23:04:52.720 - Accepting cluster node connection from 127.0.0.1:51377
93006:M 03 May 2025 23:04:52.742 - Accepting cluster node connection from 127.0.0.1:51390
93006:M 03 May 2025 23:04:52.748 - Accepting cluster node connection from 127.0.0.1:51401
93006:M 03 May 2025 23:04:52.763 * configEpoch collision with node 6cc182f5fd9d241f33f71e47c38b512e9b5263ad (). configEpoch set to 4
93006:M 03 May 2025 23:04:52.766 * configEpoch collision with node 6cc182f5fd9d241f33f71e47c38b512e9b5263ad (). configEpoch set to 5
93006:M 03 May 2025 23:04:52.771 - Accepting cluster node connection from 127.0.0.1:51417
93006:M 03 May 2025 23:04:52.771 - Accepting cluster node connection from 127.0.0.1:51422
93006:M 03 May 2025 23:04:52.808 - Accepting cluster node connection from 127.0.0.1:51425
93006:M 03 May 2025 23:04:52.809 - Accepting cluster node connection from 127.0.0.1:51431
93006:M 03 May 2025 23:04:52.882 - Accepting cluster node connection from 127.0.0.1:51470
93006:M 03 May 2025 23:04:53.007 # Missing implement of connection type tls
93006:M 03 May 2025 23:04:53.128 * Node aa25892320b9f05c95ecf5b36e0311ba1c846583 () is no longer primary of shard 54ee3fe575ecb15f700bbbb591bb77ea969cb8ef; removed all 0 slot(s) it used to own
93006:M 03 May 2025 23:04:53.128 * Node aa25892320b9f05c95ecf5b36e0311ba1c846583 () is now part of shard e336a9a27041d0cee4788e5e75eb1a47b8b18d0d
93006:M 03 May 2025 23:04:53.128 * Node aa25892320b9f05c95ecf5b36e0311ba1c846583 () is now a replica of node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 () in shard e336a9a27041d0cee4788e5e75eb1a47b8b18d0d
93006:M 03 May 2025 23:04:53.129 * Node ef1e567d8f1512b87be09ea15d7c35e6bf67fb7e () is no longer primary of shard 7cf2bdde6a39a0795e54c8aa3a6bee33710bb1b3; removed all 0 slot(s) it used to own
93006:M 03 May 2025 23:04:53.129 * Node ef1e567d8f1512b87be09ea15d7c35e6bf67fb7e () is now part of shard 7ec9c76be688682321f9cc6432d8fe3e310ee512
93006:M 03 May 2025 23:04:53.129 * Node ef1e567d8f1512b87be09ea15d7c35e6bf67fb7e () is now a replica of node cfd7b2eac3006d20de4d8819d890a0def1578f55 () in shard 7ec9c76be688682321f9cc6432d8fe3e310ee512
93006:M 03 May 2025 23:04:53.130 - Accepted 127.0.0.1:51569
93006:M 03 May 2025 23:04:53.130 * Node 35e3684d330845aab3b3b8c8222bd0cf0426307c () is no longer primary of shard 8873cbe0689874410bf3bba4b9238e4254967575; removed all 0 slot(s) it used to own
93006:M 03 May 2025 23:04:53.130 * Node 35e3684d330845aab3b3b8c8222bd0cf0426307c () is now part of shard 51e5d3f7a3a912a417bfe216c1d6e8258e66a760
93006:M 03 May 2025 23:04:53.130 * Node 35e3684d330845aab3b3b8c8222bd0cf0426307c () is now a replica of node 5fddd6dd16d05f5149c7627c89ab22057d4fdf10 () in shard 51e5d3f7a3a912a417bfe216c1d6e8258e66a760
93006:M 03 May 2025 23:04:53.130 * Replica 127.0.0.1:22132 asks for synchronization
93006:M 03 May 2025 23:04:53.131 * Full resync requested by replica 127.0.0.1:22132
93006:M 03 May 2025 23:04:53.131 * Replication backlog created, my new replication IDs are '6752fd062272be21578cff6a2c8648a64c80939f' and '0000000000000000000000000000000000000000'
93006:M 03 May 2025 23:04:53.131 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
93006:M 03 May 2025 23:04:53.132 * Background RDB transfer started by pid 93207 to pipe through parent process
93207:C 03 May 2025 23:04:53.132 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
93006:M 03 May 2025 23:04:53.135 * Node 5cd2dce60033fcc4ef63956b3ed3b6b352d7a502 () is no longer primary of shard 3d01b816cd114fb41f7fe30be6be458e04b28c99; removed all 0 slot(s) it used to own
93006:M 03 May 2025 23:04:53.135 * Node 5cd2dce60033fcc4ef63956b3ed3b6b352d7a502 () is now part of shard eddbf15e265e3341bb8bb5f23e63c9c9acae6ad3
93006:M 03 May 2025 23:04:53.135 * Node 5cd2dce60033fcc4ef63956b3ed3b6b352d7a502 () is now a replica of node 7d3399d6d71b9f1addc72ea3a10085ef56a0dade () in shard eddbf15e265e3341bb8bb5f23e63c9c9acae6ad3
93006:M 03 May 2025 23:04:53.135 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
93006:M 03 May 2025 23:04:53.139 * Node 00c5c3544a9cb7e11c28446fb70f8c5370ba2215 () is no longer primary of shard 7c3cb3ee4781c865ef9e69ed9ac97a5dfa83b007; removed all 0 slot(s) it used to own
93006:M 03 May 2025 23:04:53.139 * Node 00c5c3544a9cb7e11c28446fb70f8c5370ba2215 () is now part of shard 8887c6c8a455d9b1b8e2ffdede6989e883efac52
93006:M 03 May 2025 23:04:53.139 * Node 00c5c3544a9cb7e11c28446fb70f8c5370ba2215 () is now a replica of node 6cc182f5fd9d241f33f71e47c38b512e9b5263ad () in shard 8887c6c8a455d9b1b8e2ffdede6989e883efac52
93006:M 03 May 2025 23:04:53.144 * Background RDB transfer terminated with success
93006:M 03 May 2025 23:04:53.144 * Streamed RDB transfer with replica 127.0.0.1:22132 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
93006:M 03 May 2025 23:04:53.144 * Synchronization with replica 127.0.0.1:22132 succeeded
93006:M 03 May 2025 23:04:53.145 # DEBUG LOG: ========== I am primary 2 ==========
93006:M 03 May 2025 23:04:54.065 * Cluster state changed: ok
### Starting test Cluster is up in tests/unit/cluster/manual-failover.tcl
### Starting test Cluster is writable in tests/unit/cluster/manual-failover.tcl
93006:M 03 May 2025 23:05:02.934 - Accepted 127.0.0.1:53912
93006:M 03 May 2025 23:05:02.959 - Client closed connection id=7 addr=127.0.0.1:53912 laddr=127.0.0.1:22137 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=30 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=1914 tot-net-out=838 tot-cmds=48
### Starting test Instance #5 is a slave in tests/unit/cluster/manual-failover.tcl
### Starting test Instance #5 synced with the master in tests/unit/cluster/manual-failover.tcl
93006:M 03 May 2025 23:05:02.988 - Accepted 127.0.0.1:53964
### Starting test Send CLUSTER FAILOVER to #5, during load in tests/unit/cluster/manual-failover.tcl
93006:M 03 May 2025 23:05:03.483 * Failover auth granted to aa25892320b9f05c95ecf5b36e0311ba1c846583 () for epoch 10
93006:M 03 May 2025 23:05:03.560 * A failover occurred in shard e336a9a27041d0cee4788e5e75eb1a47b8b18d0d; node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 () failed over to node aa25892320b9f05c95ecf5b36e0311ba1c846583 () with a config epoch of 10
93006:M 03 May 2025 23:05:03.560 * Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 () is now a replica of node aa25892320b9f05c95ecf5b36e0311ba1c846583 () in shard e336a9a27041d0cee4788e5e75eb1a47b8b18d0d
93006:M 03 May 2025 23:05:03.562 - Accepted 127.0.0.1:54238
93006:M 03 May 2025 23:05:03.562 - Client closed connection id=8 addr=127.0.0.1:53964 laddr=127.0.0.1:22137 fd=34 name= age=1 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=5 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=eval user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=103859 tot-net-out=4703 tot-cmds=1547
### Starting test Wait for failover in tests/unit/cluster/manual-failover.tcl
### Starting test Cluster should eventually be up again in tests/unit/cluster/manual-failover.tcl
### Starting test Cluster is writable in tests/unit/cluster/manual-failover.tcl
93006:M 03 May 2025 23:05:04.118 - Accepted 127.0.0.1:54519
93006:M 03 May 2025 23:05:04.140 - Client closed connection id=11 addr=127.0.0.1:54519 laddr=127.0.0.1:22137 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=1914 tot-net-out=838 tot-cmds=48
### Starting test Instance #5 is now a master in tests/unit/cluster/manual-failover.tcl
### Starting test Verify 50000 keys for consistency with logical content in tests/unit/cluster/manual-failover.tcl
### Starting test Instance #0 gets converted into a slave in tests/unit/cluster/manual-failover.tcl
### Starting test Check for memory leaks (pid 93113) in tests/unit/cluster/manual-failover.tcl
93006:M 03 May 2025 23:05:05.760 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
### Starting test Check for memory leaks (pid 93060) in tests/unit/cluster/manual-failover.tcl
93006:M 03 May 2025 23:05:05.861 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:05.962 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:06.063 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:06.164 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:06.265 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:06.366 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:06.468 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:06.568 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:06.669 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:06.770 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:06.871 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:06.972 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:07.073 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:07.074 - Connection with Node cfd7b2eac3006d20de4d8819d890a0def1578f55 at 127.0.0.1:32138 failed: Connection refused
93006:M 03 May 2025 23:05:07.115 - Client closed connection id=3 addr=127.0.0.1:51124 laddr=127.0.0.1:22137 fd=14 name= age=15 idle=3 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=874 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|slots user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=460 tot-net-out=14169 tot-cmds=14
93006:M 03 May 2025 23:05:07.174 - DB 0: 1874 keys (0 volatile) in 9772 slots HT.
93006:M 03 May 2025 23:05:07.175 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:07.175 - Connection with Node cfd7b2eac3006d20de4d8819d890a0def1578f55 at 127.0.0.1:32138 failed: Connection refused
93006:M 03 May 2025 23:05:07.275 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:07.279 - Connection with Node cfd7b2eac3006d20de4d8819d890a0def1578f55 at 127.0.0.1:32138 failed: Connection refused
93006:M 03 May 2025 23:05:07.997 - Connection with Node e9ab92522ac59e38f8ef7ecddcb23ed30aabf680 at 127.0.0.1:32139 failed: Connection refused
93006:M 03 May 2025 23:05:07.997 - Connection with Node cfd7b2eac3006d20de4d8819d890a0def1578f55 at 127.0.0.1:32138 failed: Connection refused
93006:signal-handler (1746281108) Received SIGTERM scheduling shutdown...
93006:M 03 May 2025 23:05:08.097 * User requested shutdown...
93006:M 03 May 2025 23:05:08.097 * 1 of 1 replicas are in sync when shutting down.
93006:M 03 May 2025 23:05:08.097 * Removing the pid file.
93006:M 03 May 2025 23:05:08.097 * Saving the cluster configuration file before exiting.
93006:M 03 May 2025 23:05:08.104 * Removing the unix socket file.
93006:M 03 May 2025 23:05:08.104 # Valkey is now ready to exit, bye bye...
