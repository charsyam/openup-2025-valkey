### Starting server for test 
96034:M 03 May 2025 23:05:19.703 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
96034:M 03 May 2025 23:05:19.703 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
96034:M 03 May 2025 23:05:19.703 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=96034, just started
96034:M 03 May 2025 23:05:19.703 * Configuration loaded
96034:M 03 May 2025 23:05:19.703 * Increased maximum number of open files to 10032 (it was originally set to 256).
96034:M 03 May 2025 23:05:19.703 * monotonic clock: POSIX clock_gettime
96034:M 03 May 2025 23:05:19.704 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 21166
 |###|   .+###############+.   |###|    PID: 96034                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

96034:M 03 May 2025 23:05:19.704 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
96034:M 03 May 2025 23:05:19.704 * No cluster configuration found, I'm 10912261bdb2e577ede9ef64ac1558fc40b1a164
96034:M 03 May 2025 23:05:19.713 * Server initialized
96034:M 03 May 2025 23:05:19.713 * Ready to accept connections tcp
96034:M 03 May 2025 23:05:19.713 * Ready to accept connections unix
96034:M 03 May 2025 23:05:19.836 - Accepted 127.0.0.1:49795
96034:M 03 May 2025 23:05:19.838 - Client closed connection id=2 addr=127.0.0.1:49795 laddr=127.0.0.1:21166 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
96034:M 03 May 2025 23:05:19.855 - Accepted 127.0.0.1:49800
96034:M 03 May 2025 23:05:19.859 * Cluster meet 127.0.0.1:21165 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.862 * Cluster meet 127.0.0.1:21164 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.869 * Cluster meet 127.0.0.1:21163 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.874 * Cluster meet 127.0.0.1:21162 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.874 * Cluster meet 127.0.0.1:21161 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.877 * Cluster meet 127.0.0.1:21160 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.877 * Cluster meet 127.0.0.1:21159 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.878 * Cluster meet 127.0.0.1:21158 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.880 * Cluster meet 127.0.0.1:21157 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.883 * Cluster meet 127.0.0.1:21156 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.886 * Cluster meet 127.0.0.1:21155 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.886 * Cluster meet 127.0.0.1:21154 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.887 * Cluster meet 127.0.0.1:21153 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.887 * Cluster meet 127.0.0.1:21152 (user request from 'id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= user=default lib-name= lib-ver=').
96034:M 03 May 2025 23:05:19.940 - Accepting cluster node connection from 127.0.0.1:49871
96034:M 03 May 2025 23:05:19.947 - Accepting cluster node connection from 127.0.0.1:49872
96034:M 03 May 2025 23:05:19.947 * IP address for this node updated to 127.0.0.1
96034:M 03 May 2025 23:05:19.947 * Successfully completed handshake with ddcb12db51beec1ee6e5877caa40228fab26c7aa ()
96034:M 03 May 2025 23:05:19.947 * configEpoch collision with node ddcb12db51beec1ee6e5877caa40228fab26c7aa (). configEpoch set to 1
96034:M 03 May 2025 23:05:19.958 - Accepting cluster node connection from 127.0.0.1:49884
96034:M 03 May 2025 23:05:19.958 - Accepting cluster node connection from 127.0.0.1:49885
96034:M 03 May 2025 23:05:19.958 * Successfully completed handshake with 283c293e0f27e3efad0224e969368ec1b14adffa ()
96034:M 03 May 2025 23:05:19.959 * Successfully completed handshake with fc4b0764db49c2df6d9f434cac8b413a1007e523 ()
96034:M 03 May 2025 23:05:19.959 * Successfully completed handshake with 6a7665f2841f99b5daa32d3e49ab35c8355be10b ()
96034:M 03 May 2025 23:05:19.973 - Accepting cluster node connection from 127.0.0.1:49892
96034:M 03 May 2025 23:05:19.973 * Successfully completed handshake with f3412e953d77343a09ad6afd7dcb84c8f237cc71 ()
96034:M 03 May 2025 23:05:19.983 - Accepting cluster node connection from 127.0.0.1:49893
96034:M 03 May 2025 23:05:19.983 - Accepting cluster node connection from 127.0.0.1:49894
96034:M 03 May 2025 23:05:19.983 * Successfully completed handshake with 210dee5ab17b0fd27f0688bb1160d17743ea9f5e ()
96034:M 03 May 2025 23:05:19.984 * Successfully completed handshake with 2f778a0a40c6fbfc0f691ae32c9e0f919dcc6393 ()
96034:M 03 May 2025 23:05:20.009 - Accepting cluster node connection from 127.0.0.1:49904
96034:M 03 May 2025 23:05:20.009 - Accepting cluster node connection from 127.0.0.1:49908
96034:M 03 May 2025 23:05:20.009 - Accepting cluster node connection from 127.0.0.1:49919
96034:M 03 May 2025 23:05:20.009 - Accepting cluster node connection from 127.0.0.1:49920
96034:M 03 May 2025 23:05:20.009 - Accepting cluster node connection from 127.0.0.1:49931
96034:M 03 May 2025 23:05:20.009 * Successfully completed handshake with da5d8ada8b73e0d68914ae0217bd1129f4a1b6ff ()
96034:M 03 May 2025 23:05:20.009 * Successfully completed handshake with 44414c6c981e512f233afe7f1f98d6ea9503189c ()
96034:M 03 May 2025 23:05:20.009 * Successfully completed handshake with d58af409c560f69f44f0ee5961ef14002ceaec1b ()
96034:M 03 May 2025 23:05:20.009 * Successfully completed handshake with 1f7d44617366e3e8294786762948df57791b5965 ()
96034:M 03 May 2025 23:05:20.009 * Successfully completed handshake with d651cfbc055f5007ef5a0932a13ce1c8359dad9f ()
96034:M 03 May 2025 23:05:20.012 - Accepting cluster node connection from 127.0.0.1:49936
96034:M 03 May 2025 23:05:20.012 * Successfully completed handshake with 5c9d29409d13e59dc3be6cd416210ea5670c4374 ()
96034:M 03 May 2025 23:05:20.025 - Accepting cluster node connection from 127.0.0.1:49937
96034:M 03 May 2025 23:05:20.025 * Successfully completed handshake with e56a07ef8c27e0c318aed44f12bacda27ba6a7b7 ()
96034:M 03 May 2025 23:05:20.131 * configEpoch collision with node da5d8ada8b73e0d68914ae0217bd1129f4a1b6ff (). configEpoch set to 3
96034:M 03 May 2025 23:05:20.199 # Missing implement of connection type tls
96034:M 03 May 2025 23:05:21.782 * Cluster state changed: ok
96034:M 03 May 2025 23:05:39.323 - Accepted 127.0.0.1:56905
96034:M 03 May 2025 23:05:39.342 * Node e56a07ef8c27e0c318aed44f12bacda27ba6a7b7 () is no longer primary of shard 657400279748defbab60a93b8b0a3861bcff593d; removed all 0 slot(s) it used to own
96034:M 03 May 2025 23:05:39.342 * Node e56a07ef8c27e0c318aed44f12bacda27ba6a7b7 () is now part of shard fc6db5caaa76d4dc39f6cf8c01433e530eadcaa4
96034:M 03 May 2025 23:05:39.342 * Node e56a07ef8c27e0c318aed44f12bacda27ba6a7b7 () is now a replica of node 10912261bdb2e577ede9ef64ac1558fc40b1a164 () in shard fc6db5caaa76d4dc39f6cf8c01433e530eadcaa4
96034:M 03 May 2025 23:05:39.344 * Replica 127.0.0.1:21161 asks for synchronization
96034:M 03 May 2025 23:05:39.344 * Full resync requested by replica 127.0.0.1:21161
96034:M 03 May 2025 23:05:39.344 * Replication backlog created, my new replication IDs are '863e28cdf9c78fae4850c549c3c8cbcc93f6e48c' and '0000000000000000000000000000000000000000'
96034:M 03 May 2025 23:05:39.344 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
96034:M 03 May 2025 23:05:39.345 * Background RDB transfer started by pid 97888 to pipe through parent process
97888:C 03 May 2025 23:05:39.345 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
96034:M 03 May 2025 23:05:39.345 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
96034:M 03 May 2025 23:05:39.350 * Background RDB transfer terminated with success
96034:M 03 May 2025 23:05:39.350 * Streamed RDB transfer with replica 127.0.0.1:21161 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
96034:M 03 May 2025 23:05:39.350 * Synchronization with replica 127.0.0.1:21161 succeeded
96034:M 03 May 2025 23:05:39.351 * Node 283c293e0f27e3efad0224e969368ec1b14adffa () is no longer primary of shard 601f556b2926ee498f52df8847de445d759de834; removed all 0 slot(s) it used to own
96034:M 03 May 2025 23:05:39.352 * Node 283c293e0f27e3efad0224e969368ec1b14adffa () is now part of shard a6768d60269308d289270cdef20443f555ffa64d
96034:M 03 May 2025 23:05:39.354 * Node 283c293e0f27e3efad0224e969368ec1b14adffa () is now a replica of node 210dee5ab17b0fd27f0688bb1160d17743ea9f5e () in shard a6768d60269308d289270cdef20443f555ffa64d
96034:M 03 May 2025 23:05:39.425 * Node da5d8ada8b73e0d68914ae0217bd1129f4a1b6ff () is no longer primary of shard fe47f90acbe1fec374dcd2aec60ffa71716eba12; removed all 0 slot(s) it used to own
96034:M 03 May 2025 23:05:39.427 * Node da5d8ada8b73e0d68914ae0217bd1129f4a1b6ff () is now part of shard 4c8c3cadd25d3224a200dae2a02d9c99fc7fc359
96034:M 03 May 2025 23:05:39.430 * Node da5d8ada8b73e0d68914ae0217bd1129f4a1b6ff () is now a replica of node fc4b0764db49c2df6d9f434cac8b413a1007e523 () in shard 4c8c3cadd25d3224a200dae2a02d9c99fc7fc359
96034:M 03 May 2025 23:05:39.466 * Node d58af409c560f69f44f0ee5961ef14002ceaec1b () is no longer primary of shard c49a31e910aa40c6a75a62f4b0ff7e0ea2ff1b2f; removed all 0 slot(s) it used to own
96034:M 03 May 2025 23:05:39.466 * Node d58af409c560f69f44f0ee5961ef14002ceaec1b () is now part of shard 07017f9d869a67e1be8c99fe229c46fcd2157b0f
96034:M 03 May 2025 23:05:39.466 * Node d58af409c560f69f44f0ee5961ef14002ceaec1b () is now a replica of node 5c9d29409d13e59dc3be6cd416210ea5670c4374 () in shard 07017f9d869a67e1be8c99fe229c46fcd2157b0f
96034:M 03 May 2025 23:05:39.512 * Node d651cfbc055f5007ef5a0932a13ce1c8359dad9f () is no longer primary of shard 7fd5eb3638068e44200fb88c813e83da1c704ba5; removed all 0 slot(s) it used to own
96034:M 03 May 2025 23:05:39.513 * Node d651cfbc055f5007ef5a0932a13ce1c8359dad9f () is now part of shard 4564397d564906afa3f63a8cf50c8b9d20b17c65
96034:M 03 May 2025 23:05:39.513 * Node d651cfbc055f5007ef5a0932a13ce1c8359dad9f () is now a replica of node f3412e953d77343a09ad6afd7dcb84c8f237cc71 () in shard 4564397d564906afa3f63a8cf50c8b9d20b17c65
96034:M 03 May 2025 23:05:39.529 - Accepted 127.0.0.1:56939
96034:M 03 May 2025 23:05:39.567 * Node 6a7665f2841f99b5daa32d3e49ab35c8355be10b () is no longer primary of shard 24c64cbc2c11711a11f97af81796398ae55d0cf3; removed all 0 slot(s) it used to own
96034:M 03 May 2025 23:05:39.569 * Node 6a7665f2841f99b5daa32d3e49ab35c8355be10b () is now part of shard fc6db5caaa76d4dc39f6cf8c01433e530eadcaa4
96034:M 03 May 2025 23:05:39.572 * Node 6a7665f2841f99b5daa32d3e49ab35c8355be10b () is now a replica of node 10912261bdb2e577ede9ef64ac1558fc40b1a164 () in shard fc6db5caaa76d4dc39f6cf8c01433e530eadcaa4
96034:M 03 May 2025 23:05:39.575 * Replica 127.0.0.1:21156 asks for synchronization
96034:M 03 May 2025 23:05:39.575 * Full resync requested by replica 127.0.0.1:21156
96034:M 03 May 2025 23:05:39.575 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
96034:M 03 May 2025 23:05:39.577 * Background RDB transfer started by pid 97908 to pipe through parent process
97908:C 03 May 2025 23:05:39.577 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
96034:M 03 May 2025 23:05:39.577 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
96034:M 03 May 2025 23:05:39.580 * Background RDB transfer terminated with success
96034:M 03 May 2025 23:05:39.581 * Streamed RDB transfer with replica 127.0.0.1:21156 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
96034:M 03 May 2025 23:05:39.581 * Synchronization with replica 127.0.0.1:21156 succeeded
96034:M 03 May 2025 23:05:39.610 * Node 2f778a0a40c6fbfc0f691ae32c9e0f919dcc6393 () is no longer primary of shard bf28ce133de2f424bf9cedf97ba43b547fd7fbf6; removed all 0 slot(s) it used to own
96034:M 03 May 2025 23:05:39.612 * Node 2f778a0a40c6fbfc0f691ae32c9e0f919dcc6393 () is now part of shard a6768d60269308d289270cdef20443f555ffa64d
96034:M 03 May 2025 23:05:39.612 * Node 2f778a0a40c6fbfc0f691ae32c9e0f919dcc6393 () is now a replica of node 210dee5ab17b0fd27f0688bb1160d17743ea9f5e () in shard a6768d60269308d289270cdef20443f555ffa64d
96034:M 03 May 2025 23:05:39.681 * Node 44414c6c981e512f233afe7f1f98d6ea9503189c () is no longer primary of shard b7fa572e15a1fd3cc2f9fcb9bfa84f4bb2aecab6; removed all 0 slot(s) it used to own
96034:M 03 May 2025 23:05:39.681 * Node 44414c6c981e512f233afe7f1f98d6ea9503189c () is now part of shard 4c8c3cadd25d3224a200dae2a02d9c99fc7fc359
96034:M 03 May 2025 23:05:39.681 * Node 44414c6c981e512f233afe7f1f98d6ea9503189c () is now a replica of node fc4b0764db49c2df6d9f434cac8b413a1007e523 () in shard 4c8c3cadd25d3224a200dae2a02d9c99fc7fc359
96034:M 03 May 2025 23:05:39.735 * Node ddcb12db51beec1ee6e5877caa40228fab26c7aa () is no longer primary of shard 53ea531d8a056ee12606c05ecce8d87105f9b0be; removed all 0 slot(s) it used to own
96034:M 03 May 2025 23:05:39.737 * Node ddcb12db51beec1ee6e5877caa40228fab26c7aa () is now part of shard 07017f9d869a67e1be8c99fe229c46fcd2157b0f
96034:M 03 May 2025 23:05:39.739 * Node ddcb12db51beec1ee6e5877caa40228fab26c7aa () is now a replica of node 5c9d29409d13e59dc3be6cd416210ea5670c4374 () in shard 07017f9d869a67e1be8c99fe229c46fcd2157b0f
96034:M 03 May 2025 23:05:39.795 * Node 1f7d44617366e3e8294786762948df57791b5965 () is no longer primary of shard 9f07d19cd59055a25b69ddc91f194def963dbea5; removed all 0 slot(s) it used to own
96034:M 03 May 2025 23:05:39.795 * Node 1f7d44617366e3e8294786762948df57791b5965 () is now part of shard 4564397d564906afa3f63a8cf50c8b9d20b17c65
96034:M 03 May 2025 23:05:39.797 * Node 1f7d44617366e3e8294786762948df57791b5965 () is now a replica of node f3412e953d77343a09ad6afd7dcb84c8f237cc71 () in shard 4564397d564906afa3f63a8cf50c8b9d20b17c65
96034:M 03 May 2025 23:05:39.799 # DEBUG LOG: ========== I am primary 0 ==========
### Starting test Cluster is up in tests/unit/cluster/cluster-slots.tcl
### Starting test Cluster is writable in tests/unit/cluster/cluster-slots.tcl
96034:M 03 May 2025 23:06:25.533 - Accepted 127.0.0.1:53311
96034:M 03 May 2025 23:06:25.534 - Client closed connection id=8 addr=127.0.0.1:53311 laddr=127.0.0.1:21166 fd=45 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=cluster|nodes user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=28 tot-net-out=89082 tot-cmds=1
96034:M 03 May 2025 23:06:25.537 - Accepted 127.0.0.1:53327
96034:M 03 May 2025 23:06:25.598 - Client closed connection id=9 addr=127.0.0.1:53327 laddr=127.0.0.1:21166 fd=45 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=1431 tot-net-out=627 tot-cmds=36
### Starting test Instance #5 is a slave in tests/unit/cluster/cluster-slots.tcl
### Starting test client do not break when cluster slot in tests/unit/cluster/cluster-slots.tcl
96034:M 03 May 2025 23:06:25.609 - DB 0: 18 keys (0 volatile) in 126 slots HT.
### Starting test client can handle keys with hash tag in tests/unit/cluster/cluster-slots.tcl
96034:M 03 May 2025 23:06:27.572 - Accepted 127.0.0.1:54745
96034:M 03 May 2025 23:06:27.575 - Client closed connection id=11 addr=127.0.0.1:54745 laddr=127.0.0.1:21166 fd=45 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=cluster|nodes user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=28 tot-net-out=89082 tot-cmds=1
96034:M 03 May 2025 23:06:27.582 - Accepted 127.0.0.1:54764
96034:M 03 May 2025 23:06:27.613 - Client closed connection id=12 addr=127.0.0.1:54764 laddr=127.0.0.1:21166 fd=45 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=NULL user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=0 tot-net-out=0 tot-cmds=0
### Starting test slot migration is valid from primary to another primary in tests/unit/cluster/cluster-slots.tcl
96034:M 03 May 2025 23:06:27.615 - Accepted 127.0.0.1:54776
96034:M 03 May 2025 23:06:27.618 - Client closed connection id=13 addr=127.0.0.1:54776 laddr=127.0.0.1:21166 fd=45 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=cluster|nodes user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=28 tot-net-out=89082 tot-cmds=1
96034:M 03 May 2025 23:06:27.622 - Accepted 127.0.0.1:54790
### Starting test slot migration is invalid from primary to replica in tests/unit/cluster/cluster-slots.tcl
96034:M 03 May 2025 23:06:27.657 - Accepted 127.0.0.1:54799
96034:M 03 May 2025 23:06:27.658 - Client closed connection id=15 addr=127.0.0.1:54799 laddr=127.0.0.1:21166 fd=46 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=cluster|nodes user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=28 tot-net-out=89082 tot-cmds=1
96034:M 03 May 2025 23:06:27.660 - Accepted 127.0.0.1:54813
### Starting test slot must be unbound on the owner when it is deleted in tests/unit/cluster/cluster-slots.tcl
96034:M 03 May 2025 23:06:28.129 * Slot 10479 is migrated from node f3412e953d77343a09ad6afd7dcb84c8f237cc71 () in shard 4564397d564906afa3f63a8cf50c8b9d20b17c65 to node 5c9d29409d13e59dc3be6cd416210ea5670c4374 () in shard 07017f9d869a67e1be8c99fe229c46fcd2157b0f.
96034:M 03 May 2025 23:06:30.656 - DB 0: 18 keys (0 volatile) in 126 slots HT.
96034:M 03 May 2025 23:06:32.924 # Cluster state changed: fail
96034:M 03 May 2025 23:06:32.924 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
96034:M 03 May 2025 23:06:35.701 - DB 0: 18 keys (0 volatile) in 126 slots HT.
96034:M 03 May 2025 23:06:37.226 - Client closed connection id=3 addr=127.0.0.1:49800 laddr=127.0.0.1:21166 fd=14 name= age=78 idle=4 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|slots user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=35802 tot-net-out=24498799 tot-cmds=53
96034:signal-handler (1746281200) Received SIGTERM scheduling shutdown...
96034:M 03 May 2025 23:06:40.736 * User requested shutdown...
96034:M 03 May 2025 23:06:40.736 * 2 of 2 replicas are in sync when shutting down.
96034:M 03 May 2025 23:06:40.736 * Removing the pid file.
96034:M 03 May 2025 23:06:40.736 * Saving the cluster configuration file before exiting.
96034:M 03 May 2025 23:06:40.746 * Removing the unix socket file.
96034:M 03 May 2025 23:06:40.746 # Valkey is now ready to exit, bye bye...
