### Starting server for test 
92372:M 03 May 2025 23:04:47.032 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
92372:M 03 May 2025 23:04:47.032 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
92372:M 03 May 2025 23:04:47.032 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=92372, just started
92372:M 03 May 2025 23:04:47.032 * Configuration loaded
92372:M 03 May 2025 23:04:47.033 * Increased maximum number of open files to 10032 (it was originally set to 256).
92372:M 03 May 2025 23:04:47.033 * monotonic clock: POSIX clock_gettime
92372:M 03 May 2025 23:04:47.033 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 27626
 |###|   .+###############+.   |###|    PID: 92372                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

92372:M 03 May 2025 23:04:47.033 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
92372:M 03 May 2025 23:04:47.033 * No cluster configuration found, I'm 7a7bfe9723d2b86da66e7bb1d1031fc2af15f866
92372:M 03 May 2025 23:04:47.040 * Server initialized
92372:M 03 May 2025 23:04:47.040 * Ready to accept connections tcp
92372:M 03 May 2025 23:04:47.040 * Ready to accept connections unix
92372:M 03 May 2025 23:04:47.159 - Accepted 127.0.0.1:65433
92372:M 03 May 2025 23:04:47.159 - Client closed connection id=2 addr=127.0.0.1:65433 laddr=127.0.0.1:27626 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
92372:M 03 May 2025 23:04:47.195 - Accepted 127.0.0.1:65443
92372:M 03 May 2025 23:04:47.956 - Accepting cluster node connection from 127.0.0.1:49423
92372:M 03 May 2025 23:04:47.956 * IP address for this node updated to 127.0.0.1
92372:M 03 May 2025 23:04:48.090 - Accepting cluster node connection from 127.0.0.1:49504
92372:M 03 May 2025 23:04:48.093 * configEpoch collision with node e64560ebd7e867d98113ad1a0e7c234a9fe2141e (). configEpoch set to 2
92372:M 03 May 2025 23:04:48.185 - Accepting cluster node connection from 127.0.0.1:49579
92372:M 03 May 2025 23:04:48.230 - Accepting cluster node connection from 127.0.0.1:49585
92372:M 03 May 2025 23:04:48.233 * Successfully completed handshake with 404bd69e41e44632e3b620906ef886ba77b2836e ()
92372:M 03 May 2025 23:04:48.275 - Accepting cluster node connection from 127.0.0.1:49609
92372:M 03 May 2025 23:04:48.278 - Accepting cluster node connection from 127.0.0.1:49615
92372:M 03 May 2025 23:04:48.282 - Accepting cluster node connection from 127.0.0.1:49626
92372:M 03 May 2025 23:04:48.385 - Accepting cluster node connection from 127.0.0.1:49669
92372:M 03 May 2025 23:04:48.391 - Accepting cluster node connection from 127.0.0.1:49676
92372:M 03 May 2025 23:04:48.749 # Missing implement of connection type tls
92372:M 03 May 2025 23:04:48.778 * Node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () is no longer primary of shard e87633a400958de22fb48ffe6aa6fc13b7021553; removed all 0 slot(s) it used to own
92372:M 03 May 2025 23:04:48.778 * Node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () is now part of shard 31b9baefa0362697e4993fa870109bf43b82374d
92372:M 03 May 2025 23:04:48.778 * Node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () is now a replica of node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () in shard 31b9baefa0362697e4993fa870109bf43b82374d
92372:M 03 May 2025 23:04:48.780 * Node 7f151f30e859942cb03baab48a22f5590b6b9238 () is no longer primary of shard 14be6ef61927f1e1cacb4acf0f93f688f9bba9f5; removed all 0 slot(s) it used to own
92372:M 03 May 2025 23:04:48.780 * Node 7f151f30e859942cb03baab48a22f5590b6b9238 () is now part of shard 610f63b8acb499ebc4ca66a58bd30942e9120f07
92372:M 03 May 2025 23:04:48.780 * Node 7f151f30e859942cb03baab48a22f5590b6b9238 () is now a replica of node 404bd69e41e44632e3b620906ef886ba77b2836e () in shard 610f63b8acb499ebc4ca66a58bd30942e9120f07
92372:M 03 May 2025 23:04:48.782 * Node 756739044a8680749bbe0fed1106f2fca107a392 () is no longer primary of shard 6ff5adbc415aa4b0ef37ff3e3bb39bf085a50cbe; removed all 0 slot(s) it used to own
92372:M 03 May 2025 23:04:48.782 * Node 756739044a8680749bbe0fed1106f2fca107a392 () is now part of shard 2f21ba220d09a9db278f5ea2f4e678cdd2a8ed6a
92372:M 03 May 2025 23:04:48.782 * Node 756739044a8680749bbe0fed1106f2fca107a392 () is now a replica of node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () in shard 2f21ba220d09a9db278f5ea2f4e678cdd2a8ed6a
92372:M 03 May 2025 23:04:48.786 * Node 7f82760c06d2d327a4cf25f67016fd68606e3565 () is no longer primary of shard 5b277857f202e31583052e158b5a8a3b4c522ae6; removed all 0 slot(s) it used to own
92372:M 03 May 2025 23:04:48.786 * Node 7f82760c06d2d327a4cf25f67016fd68606e3565 () is now part of shard bd68865ccc13a9fd4e95b9878458451f374fdc91
92372:M 03 May 2025 23:04:48.786 * Node 7f82760c06d2d327a4cf25f67016fd68606e3565 () is now a replica of node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd () in shard bd68865ccc13a9fd4e95b9878458451f374fdc91
92372:M 03 May 2025 23:04:48.793 - Accepted 127.0.0.1:49869
92372:M 03 May 2025 23:04:48.797 * Node 6f19f49db792785fb97761b94fb6776b225a3b66 () is no longer primary of shard fd3d5778858de380b49aaf2943b6b8ffbb321e18; removed all 0 slot(s) it used to own
92372:M 03 May 2025 23:04:48.797 * Node 6f19f49db792785fb97761b94fb6776b225a3b66 () is now part of shard 7ddc849dc0b94044ddb47800e229c14282783835
92372:M 03 May 2025 23:04:48.797 * Node 6f19f49db792785fb97761b94fb6776b225a3b66 () is now a replica of node 7a7bfe9723d2b86da66e7bb1d1031fc2af15f866 () in shard 7ddc849dc0b94044ddb47800e229c14282783835
92372:M 03 May 2025 23:04:48.798 * Replica 127.0.0.1:27621 asks for synchronization
92372:M 03 May 2025 23:04:48.798 * Full resync requested by replica 127.0.0.1:27621
92372:M 03 May 2025 23:04:48.798 * Replication backlog created, my new replication IDs are 'e29435d7205fb5cbc5fee65ae34f1e921e609b53' and '0000000000000000000000000000000000000000'
92372:M 03 May 2025 23:04:48.798 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
92372:M 03 May 2025 23:04:48.800 * Background RDB transfer started by pid 92533 to pipe through parent process
92372:M 03 May 2025 23:04:48.802 # DEBUG LOG: ========== I am primary 4 ==========
92533:C 03 May 2025 23:04:48.800 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
92372:M 03 May 2025 23:04:48.802 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
92372:M 03 May 2025 23:04:48.805 * Background RDB transfer terminated with success
92372:M 03 May 2025 23:04:48.805 * Streamed RDB transfer with replica 127.0.0.1:27621 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
92372:M 03 May 2025 23:04:48.805 * Synchronization with replica 127.0.0.1:27621 succeeded
92372:M 03 May 2025 23:04:49.086 * Cluster state changed: ok
### Starting test Cluster is up in tests/unit/cluster/manual-takeover.tcl
### Starting test Cluster is writable in tests/unit/cluster/manual-takeover.tcl
92372:M 03 May 2025 23:04:58.296 - Accepted 127.0.0.1:52864
92372:M 03 May 2025 23:04:58.332 - Client closed connection id=7 addr=127.0.0.1:52864 laddr=127.0.0.1:27626 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=1434 tot-net-out=628 tot-cmds=36
### Starting test Killing majority of master nodes in tests/unit/cluster/manual-takeover.tcl
### Starting test Cluster should eventually be down in tests/unit/cluster/manual-takeover.tcl
92372:M 03 May 2025 23:05:01.646 * Node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd () reported node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () as not reachable.
92372:M 03 May 2025 23:05:01.646 * Node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd () reported node 404bd69e41e44632e3b620906ef886ba77b2836e () as not reachable.
92372:M 03 May 2025 23:05:01.685 # Cluster state changed: fail
92372:M 03 May 2025 23:05:01.690 # Cluster is currently down: I am part of a minority partition.
### Starting test Use takeover to bring slaves back in tests/unit/cluster/manual-takeover.tcl
92372:M 03 May 2025 23:05:01.762 * Node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () reported node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () as not reachable.
92372:M 03 May 2025 23:05:01.765 * Marking node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () as failing (quorum reached).
92372:M 03 May 2025 23:05:01.765 * Node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () reported node 404bd69e41e44632e3b620906ef886ba77b2836e () as not reachable.
92372:M 03 May 2025 23:05:01.765 * Marking node 404bd69e41e44632e3b620906ef886ba77b2836e () as failing (quorum reached).
92372:M 03 May 2025 23:05:01.765 * Node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () reported node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () as not reachable.
92372:M 03 May 2025 23:05:01.768 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
92372:M 03 May 2025 23:05:01.786 * FAIL message received from 1755171edd36166e7d11e63cc90d5dde2a6fd5bd () about 0bd858936210ce20e9170f70a1116f67ec5d0c39 ()
92372:M 03 May 2025 23:05:01.797 * Node 7f151f30e859942cb03baab48a22f5590b6b9238 () reported node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () as not reachable.
92372:M 03 May 2025 23:05:01.799 * Node 7f151f30e859942cb03baab48a22f5590b6b9238 () reported node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () as not reachable.
92372:M 03 May 2025 23:05:01.861 * Node 7f151f30e859942cb03baab48a22f5590b6b9238 () reported node 404bd69e41e44632e3b620906ef886ba77b2836e () as not reachable.
92372:M 03 May 2025 23:05:01.866 * Node 756739044a8680749bbe0fed1106f2fca107a392 () reported node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () as not reachable.
92372:M 03 May 2025 23:05:01.866 * Node 756739044a8680749bbe0fed1106f2fca107a392 () reported node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () as not reachable.
### Starting test Cluster should eventually be up again in tests/unit/cluster/manual-takeover.tcl
92372:M 03 May 2025 23:05:01.894 * Node 756739044a8680749bbe0fed1106f2fca107a392 () reported node 404bd69e41e44632e3b620906ef886ba77b2836e () as not reachable.
92372:M 03 May 2025 23:05:01.994 * Node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd () reported node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () as not reachable.
92372:M 03 May 2025 23:05:02.296 - DB 0: 18 keys (0 volatile) in 126 slots HT.
92372:M 03 May 2025 23:05:04.709 * Cluster state changed: ok
### Starting test Cluster is writable in tests/unit/cluster/manual-takeover.tcl
92372:M 03 May 2025 23:05:04.879 - Accepted 127.0.0.1:54884
92372:M 03 May 2025 23:05:04.880 - Client closed connection id=8 addr=127.0.0.1:54884 laddr=127.0.0.1:27626 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=cluster|nodes user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=28 tot-net-out=1184 tot-cmds=1
92372:M 03 May 2025 23:05:04.880 - Accepted 127.0.0.1:54889
92372:M 03 May 2025 23:05:04.912 - Client closed connection id=9 addr=127.0.0.1:54889 laddr=127.0.0.1:27626 fd=34 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=30 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=1434 tot-net-out=628 tot-cmds=36
### Starting test Instance #5, #6, #7 are now masters in tests/unit/cluster/manual-takeover.tcl
### Starting test Restarting the previously killed master nodes in tests/unit/cluster/manual-takeover.tcl
92372:M 03 May 2025 23:05:04.939 - Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 has old slots configuration, sending an UPDATE message about e64560ebd7e867d98113ad1a0e7c234a9fe2141e
92372:M 03 May 2025 23:05:04.979 - Node 404bd69e41e44632e3b620906ef886ba77b2836e has old slots configuration, sending an UPDATE message about 7f151f30e859942cb03baab48a22f5590b6b9238
92372:M 03 May 2025 23:05:04.981 * A failover occurred in shard 31b9baefa0362697e4993fa870109bf43b82374d; node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () failed over to node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () with a config epoch of 10
92372:M 03 May 2025 23:05:04.981 * Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () is now a replica of node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () in shard 31b9baefa0362697e4993fa870109bf43b82374d
92372:M 03 May 2025 23:05:04.981 * Clear FAIL state for node 0bd858936210ce20e9170f70a1116f67ec5d0c39 (): replica is reachable again.
92372:M 03 May 2025 23:05:04.989 * A failover occurred in shard 610f63b8acb499ebc4ca66a58bd30942e9120f07; node 404bd69e41e44632e3b620906ef886ba77b2836e () failed over to node 7f151f30e859942cb03baab48a22f5590b6b9238 () with a config epoch of 11
92372:M 03 May 2025 23:05:04.989 * Node 404bd69e41e44632e3b620906ef886ba77b2836e () is now a replica of node 7f151f30e859942cb03baab48a22f5590b6b9238 () in shard 610f63b8acb499ebc4ca66a58bd30942e9120f07
92372:M 03 May 2025 23:05:04.989 * Clear FAIL state for node 404bd69e41e44632e3b620906ef886ba77b2836e (): replica is reachable again.
92372:M 03 May 2025 23:05:05.020 * Node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd () reported node 404bd69e41e44632e3b620906ef886ba77b2836e () is back online.
92372:M 03 May 2025 23:05:05.022 * Node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () reported node 404bd69e41e44632e3b620906ef886ba77b2836e () is back online.
92372:M 03 May 2025 23:05:05.031 * Node 7f151f30e859942cb03baab48a22f5590b6b9238 () reported node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () is back online.
92372:M 03 May 2025 23:05:05.032 * Node 7f151f30e859942cb03baab48a22f5590b6b9238 () reported node 404bd69e41e44632e3b620906ef886ba77b2836e () is back online.
### Starting test Instance #0, #1, #2 gets converted into a slaves in tests/unit/cluster/manual-takeover.tcl
92372:M 03 May 2025 23:05:05.041 - Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe has old slots configuration, sending an UPDATE message about 756739044a8680749bbe0fed1106f2fca107a392
92372:M 03 May 2025 23:05:05.050 * A failover occurred in shard 2f21ba220d09a9db278f5ea2f4e678cdd2a8ed6a; node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () failed over to node 756739044a8680749bbe0fed1106f2fca107a392 () with a config epoch of 12
92372:M 03 May 2025 23:05:05.050 * Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () is now a replica of node 756739044a8680749bbe0fed1106f2fca107a392 () in shard 2f21ba220d09a9db278f5ea2f4e678cdd2a8ed6a
92372:M 03 May 2025 23:05:05.050 * Clear FAIL state for node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe (): replica is reachable again.
### Starting test Check for memory leaks (pid 92450) in tests/unit/cluster/manual-takeover.tcl
92372:M 03 May 2025 23:05:05.083 * Node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd () reported node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () is back online.
92372:M 03 May 2025 23:05:05.087 * Node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd () reported node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () is back online.
92372:M 03 May 2025 23:05:05.118 * Node 756739044a8680749bbe0fed1106f2fca107a392 () reported node 404bd69e41e44632e3b620906ef886ba77b2836e () is back online.
92372:M 03 May 2025 23:05:05.137 * Node 7f151f30e859942cb03baab48a22f5590b6b9238 () reported node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () is back online.
92372:M 03 May 2025 23:05:05.212 * Node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () reported node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () is back online.
92372:M 03 May 2025 23:05:05.214 * Node 756739044a8680749bbe0fed1106f2fca107a392 () reported node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe () is back online.
92372:M 03 May 2025 23:05:05.315 * Node 756739044a8680749bbe0fed1106f2fca107a392 () reported node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () is back online.
92372:M 03 May 2025 23:05:05.716 * Node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () reported node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () is back online.
92372:M 03 May 2025 23:05:06.123 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
### Starting test Check for memory leaks (pid 92437) in tests/unit/cluster/manual-takeover.tcl
92372:M 03 May 2025 23:05:06.224 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:06.324 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:06.425 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:06.526 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:06.626 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:06.726 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:06.827 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:06.928 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:07.029 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:07.131 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:07.232 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:07.332 - DB 0: 18 keys (0 volatile) in 126 slots HT.
92372:M 03 May 2025 23:05:07.334 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:07.337 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:07.434 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:07.444 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
### Starting test Check for memory leaks (pid 92404) in tests/unit/cluster/manual-takeover.tcl
92372:M 03 May 2025 23:05:07.535 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:07.535 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:07.635 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:07.638 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:07.736 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:07.740 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:07.836 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:07.842 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:07.936 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:07.936 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:08.037 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:08.037 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:08.138 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:08.140 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:08.238 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:08.243 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:08.338 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:08.340 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:08.440 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:08.441 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:08.540 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:08.542 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:08.543 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
### Starting test Check for memory leaks (pid 92386) in tests/unit/cluster/manual-takeover.tcl
92372:M 03 May 2025 23:05:08.641 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:08.641 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:08.644 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:08.742 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:08.742 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:08.742 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:08.843 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:08.846 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:08.846 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:08.944 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:08.944 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:08.944 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:09.044 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:09.046 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:09.050 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:09.145 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:09.151 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:09.153 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:09.246 * Node 756739044a8680749bbe0fed1106f2fca107a392 () reported node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () as not reachable.
92372:M 03 May 2025 23:05:09.249 * Node e64560ebd7e867d98113ad1a0e7c234a9fe2141e () reported node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () as not reachable.
92372:M 03 May 2025 23:05:09.250 * Marking node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () as failing (quorum reached).
92372:M 03 May 2025 23:05:09.250 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:09.250 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:09.250 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:09.351 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:09.358 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:09.358 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:09.453 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:09.455 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:09.455 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:09.555 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:09.560 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:09.563 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:09.569 - Connection with Node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd at 127.0.0.1:37627 failed: Connection refused
92372:M 03 May 2025 23:05:09.590 * Node 7f151f30e859942cb03baab48a22f5590b6b9238 () reported node 0bd858936210ce20e9170f70a1116f67ec5d0c39 () as not reachable.
92372:M 03 May 2025 23:05:09.642 - Client closed connection id=3 addr=127.0.0.1:65443 laddr=127.0.0.1:27626 fd=14 name= age=22 idle=5 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|info user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=375 tot-net-out=8524 tot-cmds=11
92372:M 03 May 2025 23:05:09.656 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:09.656 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:09.656 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:09.656 - Connection with Node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd at 127.0.0.1:37627 failed: Connection refused
92372:M 03 May 2025 23:05:09.756 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:09.756 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:09.756 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:09.756 - Connection with Node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd at 127.0.0.1:37627 failed: Connection refused
92372:M 03 May 2025 23:05:09.857 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:09.863 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:09.870 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:09.871 - Connection with Node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd at 127.0.0.1:37627 failed: Connection refused
92372:M 03 May 2025 23:05:10.686 * FAIL message received from e64560ebd7e867d98113ad1a0e7c234a9fe2141e () about 404bd69e41e44632e3b620906ef886ba77b2836e ()
92372:M 03 May 2025 23:05:10.686 - Connection with Node 0bd858936210ce20e9170f70a1116f67ec5d0c39 at 127.0.0.1:37630 failed: Connection refused
92372:M 03 May 2025 23:05:10.686 - Connection with Node a2b7b5c17fdae30119e4c551b5a1831b1fc1a6fe at 127.0.0.1:37628 failed: Connection refused
92372:M 03 May 2025 23:05:10.686 - Connection with Node 404bd69e41e44632e3b620906ef886ba77b2836e at 127.0.0.1:37629 failed: Connection refused
92372:M 03 May 2025 23:05:10.686 - Connection with Node 1755171edd36166e7d11e63cc90d5dde2a6fd5bd at 127.0.0.1:37627 failed: Connection refused
92372:signal-handler (1746281110) Received SIGTERM scheduling shutdown...
92372:M 03 May 2025 23:05:10.787 * User requested shutdown...
92372:M 03 May 2025 23:05:10.787 * 1 of 1 replicas are in sync when shutting down.
92372:M 03 May 2025 23:05:10.787 * Removing the pid file.
92372:M 03 May 2025 23:05:10.787 * Saving the cluster configuration file before exiting.
92372:M 03 May 2025 23:05:10.794 * Removing the unix socket file.
92372:M 03 May 2025 23:05:10.794 # Valkey is now ready to exit, bye bye...
