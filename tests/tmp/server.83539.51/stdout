### Starting server for test 
96875:M 03 May 2025 23:05:25.515 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
96875:M 03 May 2025 23:05:25.516 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
96875:M 03 May 2025 23:05:25.516 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=96875, just started
96875:M 03 May 2025 23:05:25.519 * Configuration loaded
96875:M 03 May 2025 23:05:25.519 * Increased maximum number of open files to 10032 (it was originally set to 256).
96875:M 03 May 2025 23:05:25.519 * monotonic clock: POSIX clock_gettime
96875:M 03 May 2025 23:05:25.521 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 28136
 |###|   .+###############+.   |###|    PID: 96875                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

96875:M 03 May 2025 23:05:25.521 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
96875:M 03 May 2025 23:05:25.522 * No cluster configuration found, I'm de13e24339d4ff7acc1955a3ee606a3d19d76a45
96875:M 03 May 2025 23:05:25.562 * Server initialized
96875:M 03 May 2025 23:05:25.562 * Ready to accept connections tcp
96875:M 03 May 2025 23:05:25.565 * Ready to accept connections unix
96875:M 03 May 2025 23:05:25.680 - Accepted 127.0.0.1:54778
96875:M 03 May 2025 23:05:25.683 - Client closed connection id=2 addr=127.0.0.1:54778 laddr=127.0.0.1:28136 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
96875:M 03 May 2025 23:05:25.702 - Accepted 127.0.0.1:54792
96875:M 03 May 2025 23:05:25.707 * Cluster meet 127.0.0.1:28135 (user request from 'id=3 addr=127.0.0.1:54792 laddr=127.0.0.1:28136 fd=14 name= user=default lib-name= lib-ver=').
96875:M 03 May 2025 23:05:25.710 * Cluster meet 127.0.0.1:28134 (user request from 'id=3 addr=127.0.0.1:54792 laddr=127.0.0.1:28136 fd=14 name= user=default lib-name= lib-ver=').
96875:M 03 May 2025 23:05:25.714 * Cluster meet 127.0.0.1:28133 (user request from 'id=3 addr=127.0.0.1:54792 laddr=127.0.0.1:28136 fd=14 name= user=default lib-name= lib-ver=').
96875:M 03 May 2025 23:05:25.717 * Cluster meet 127.0.0.1:28132 (user request from 'id=3 addr=127.0.0.1:54792 laddr=127.0.0.1:28136 fd=14 name= user=default lib-name= lib-ver=').
96875:M 03 May 2025 23:05:25.720 * Cluster meet 127.0.0.1:28131 (user request from 'id=3 addr=127.0.0.1:54792 laddr=127.0.0.1:28136 fd=14 name= user=default lib-name= lib-ver=').
96875:M 03 May 2025 23:05:25.729 * Cluster meet 127.0.0.1:28130 (user request from 'id=3 addr=127.0.0.1:54792 laddr=127.0.0.1:28136 fd=14 name= user=default lib-name= lib-ver=').
96875:M 03 May 2025 23:05:25.820 # Missing implement of connection type tls
96875:M 03 May 2025 23:05:25.826 - Accepting cluster node connection from 127.0.0.1:54875
96875:M 03 May 2025 23:05:25.862 * IP address for this node updated to 127.0.0.1
96875:M 03 May 2025 23:05:25.867 * Successfully completed handshake with 82218a66383f364fb8b5ad2e45a1926d58d091e5 ()
96875:M 03 May 2025 23:05:25.867 - Accepting cluster node connection from 127.0.0.1:54906
96875:M 03 May 2025 23:05:25.867 - Accepting cluster node connection from 127.0.0.1:54909
96875:M 03 May 2025 23:05:25.869 * Successfully completed handshake with 2c8e9b9ace519470139431052e08a1eb6fdae92b ()
96875:M 03 May 2025 23:05:25.869 * Successfully completed handshake with 3d3a9aaa923ca77543710ff8b4a617c35c610fe1 ()
96875:M 03 May 2025 23:05:25.901 - Accepting cluster node connection from 127.0.0.1:54912
96875:M 03 May 2025 23:05:25.901 * Successfully completed handshake with 4c8f7204763471d1b43a2021a9e3b0e972c77b93 ()
96875:M 03 May 2025 23:05:25.919 - Accepting cluster node connection from 127.0.0.1:54940
96875:M 03 May 2025 23:05:25.920 * Successfully completed handshake with a457adc1f12967e01636eebc7be42e1f1c6a5161 ()
96875:M 03 May 2025 23:05:25.924 - Accepting cluster node connection from 127.0.0.1:54942
96875:M 03 May 2025 23:05:25.924 * Successfully completed handshake with c2c6ca43fa4c24228277739956fea1b7c183d841 ()
96875:M 03 May 2025 23:05:26.337 - Accepted 127.0.0.1:55169
96875:M 03 May 2025 23:05:26.338 * Node 3d3a9aaa923ca77543710ff8b4a617c35c610fe1 () is no longer primary of shard 7c00b3d168f90a4a199626d3f7a1772268c8c996; removed all 0 slot(s) it used to own
96875:M 03 May 2025 23:05:26.338 * Node 3d3a9aaa923ca77543710ff8b4a617c35c610fe1 () is now part of shard 84c62b06411891110d35dee733ca3e288cdbd695
96875:M 03 May 2025 23:05:26.338 * Node 3d3a9aaa923ca77543710ff8b4a617c35c610fe1 () is now a replica of node de13e24339d4ff7acc1955a3ee606a3d19d76a45 () in shard 84c62b06411891110d35dee733ca3e288cdbd695
96875:M 03 May 2025 23:05:26.338 - Accepted 127.0.0.1:55170
96875:M 03 May 2025 23:05:26.338 * Replica 127.0.0.1:28133 asks for synchronization
96875:M 03 May 2025 23:05:26.338 * Full resync requested by replica 127.0.0.1:28133
96875:M 03 May 2025 23:05:26.338 * Replication backlog created, my new replication IDs are '74318b6738e501583741e2a5bb69584c371173b2' and '0000000000000000000000000000000000000000'
96875:M 03 May 2025 23:05:26.338 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
96875:M 03 May 2025 23:05:26.339 * Background RDB transfer started by pid 96959 to pipe through parent process
96875:M 03 May 2025 23:05:26.339 * Node 2c8e9b9ace519470139431052e08a1eb6fdae92b () is no longer primary of shard 8ad5aa8ae62d12018c3725e4796d80dc2f479380; removed all 0 slot(s) it used to own
96875:M 03 May 2025 23:05:26.339 * Node 2c8e9b9ace519470139431052e08a1eb6fdae92b () is now part of shard 84c62b06411891110d35dee733ca3e288cdbd695
96875:M 03 May 2025 23:05:26.339 * Node 2c8e9b9ace519470139431052e08a1eb6fdae92b () is now a replica of node de13e24339d4ff7acc1955a3ee606a3d19d76a45 () in shard 84c62b06411891110d35dee733ca3e288cdbd695
96959:C 03 May 2025 23:05:26.339 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
96875:M 03 May 2025 23:05:26.342 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
96875:M 03 May 2025 23:05:26.345 * Node a457adc1f12967e01636eebc7be42e1f1c6a5161 () is no longer primary of shard 8d2f10fdbeec748f5cd732cb467c198b35d51499; removed all 0 slot(s) it used to own
96875:M 03 May 2025 23:05:26.348 * Node a457adc1f12967e01636eebc7be42e1f1c6a5161 () is now part of shard 0f8c2ef8a8a4c6a45a4898c66dcc1edee626bdfd
96875:M 03 May 2025 23:05:26.362 * Node a457adc1f12967e01636eebc7be42e1f1c6a5161 () is now a replica of node 4c8f7204763471d1b43a2021a9e3b0e972c77b93 () in shard 0f8c2ef8a8a4c6a45a4898c66dcc1edee626bdfd
96875:M 03 May 2025 23:05:26.371 * Background RDB transfer terminated with success
96875:M 03 May 2025 23:05:26.377 * Streamed RDB transfer with replica 127.0.0.1:28133 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
96875:M 03 May 2025 23:05:26.377 * Synchronization with replica 127.0.0.1:28133 succeeded
96875:M 03 May 2025 23:05:26.390 * Replica 127.0.0.1:28130 asks for synchronization
96875:M 03 May 2025 23:05:26.393 * Full resync requested by replica 127.0.0.1:28130
96875:M 03 May 2025 23:05:26.393 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
96875:M 03 May 2025 23:05:26.394 * Background RDB transfer started by pid 96963 to pipe through parent process
96875:M 03 May 2025 23:05:26.394 * Node 82218a66383f364fb8b5ad2e45a1926d58d091e5 () is no longer primary of shard 4997817dc7ccddab078b67f876d51a145ed86931; removed all 0 slot(s) it used to own
96875:M 03 May 2025 23:05:26.394 * Node 82218a66383f364fb8b5ad2e45a1926d58d091e5 () is now part of shard 12ecf07cb98495b494daaec988f483de09ffbff0
96875:M 03 May 2025 23:05:26.394 * Node 82218a66383f364fb8b5ad2e45a1926d58d091e5 () is now a replica of node c2c6ca43fa4c24228277739956fea1b7c183d841 () in shard 12ecf07cb98495b494daaec988f483de09ffbff0
96963:C 03 May 2025 23:05:26.394 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
96875:M 03 May 2025 23:05:26.395 # DEBUG LOG: ========== I am primary 0 ==========
96875:M 03 May 2025 23:05:26.395 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
96875:M 03 May 2025 23:05:26.403 * Background RDB transfer terminated with success
96875:M 03 May 2025 23:05:26.403 * Streamed RDB transfer with replica 127.0.0.1:28130 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
96875:M 03 May 2025 23:05:26.403 * Synchronization with replica 127.0.0.1:28130 succeeded
96875:M 03 May 2025 23:05:27.596 * Cluster state changed: ok
### Starting test auto-failover-on-shutdown hands over primaryship to a fully sync'd replica - shutdown - shutdown-timeout: 0 in tests/unit/cluster/auto-failover-on-shutdown.tcl
96875:M 03 May 2025 23:05:37.004 * User requested shutdown... (user request from 'id=3 addr=127.0.0.1:54792 laddr=127.0.0.1:28136 fd=14 name= user=default lib-name= lib-ver=')
96875:M 03 May 2025 23:05:37.012 * Lagging replica 127.0.0.1:28133 reported offset 333 behind master, lag=2, state=online.
96875:M 03 May 2025 23:05:37.013 * 1 of 2 replicas are in sync when shutting down.
96875:M 03 May 2025 23:05:37.015 * Removing the pid file.
96875:M 03 May 2025 23:05:37.015 * Perform auto failover to replica 2c8e9b9ace519470139431052e08a1eb6fdae92b on shutdown.
96875:M 03 May 2025 23:05:37.015 * Saving the cluster configuration file before exiting.
96875:M 03 May 2025 23:05:37.021 * Removing the unix socket file.
96875:M 03 May 2025 23:05:37.022 # Valkey is now ready to exit, bye bye...
### Starting test Unable to find a replica to perform an auto failover - shutdown in tests/unit/cluster/auto-failover-on-shutdown.tcl
