### Starting server for test 
88227:M 03 May 2025 23:04:18.664 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
88227:M 03 May 2025 23:04:18.664 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
88227:M 03 May 2025 23:04:18.664 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=88227, just started
88227:M 03 May 2025 23:04:18.664 * Configuration loaded
88227:M 03 May 2025 23:04:18.664 * Increased maximum number of open files to 10032 (it was originally set to 256).
88227:M 03 May 2025 23:04:18.664 * monotonic clock: POSIX clock_gettime
88227:M 03 May 2025 23:04:18.664 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 22620
 |###|   .+###############+.   |###|    PID: 88227                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

88227:M 03 May 2025 23:04:18.664 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
88227:M 03 May 2025 23:04:18.664 * No cluster configuration found, I'm 33dca58967ea807f71054db92c9bae8edb838d1a
88227:M 03 May 2025 23:04:18.669 * Server initialized
88227:M 03 May 2025 23:04:18.669 * Ready to accept connections tcp
88227:M 03 May 2025 23:04:18.669 * Ready to accept connections unix
88227:M 03 May 2025 23:04:18.790 - Accepted 127.0.0.1:59771
88227:M 03 May 2025 23:04:18.790 - Client closed connection id=2 addr=127.0.0.1:59771 laddr=127.0.0.1:22620 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
88227:M 03 May 2025 23:04:18.800 - Accepted 127.0.0.1:59772
88227:M 03 May 2025 23:04:19.171 - Accepting cluster node connection from 127.0.0.1:59790
88227:M 03 May 2025 23:04:19.171 * IP address for this node updated to 127.0.0.1
88227:M 03 May 2025 23:04:19.275 * Successfully completed handshake with 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 ()
88227:M 03 May 2025 23:04:19.280 * Successfully completed handshake with f848f8f2426110f2aa02d85bc35109efb050ee1c ()
88227:M 03 May 2025 23:04:19.280 * configEpoch collision with node f848f8f2426110f2aa02d85bc35109efb050ee1c (). configEpoch set to 2
88227:M 03 May 2025 23:04:19.280 * Successfully completed handshake with 829dc125be5e6bed85216fa78b484311a004c590 ()
88227:M 03 May 2025 23:04:19.292 - Accepting cluster node connection from 127.0.0.1:59814
88227:M 03 May 2025 23:04:19.349 - Accepting cluster node connection from 127.0.0.1:59819
88227:M 03 May 2025 23:04:19.352 - Accepting cluster node connection from 127.0.0.1:59821
88227:M 03 May 2025 23:04:19.377 - Accepting cluster node connection from 127.0.0.1:59826
88227:M 03 May 2025 23:04:19.377 - Accepting cluster node connection from 127.0.0.1:59827
88227:M 03 May 2025 23:04:19.380 - Accepting cluster node connection from 127.0.0.1:59833
88227:M 03 May 2025 23:04:19.467 - Accepting cluster node connection from 127.0.0.1:59838
88227:M 03 May 2025 23:04:19.469 - Accepting cluster node connection from 127.0.0.1:59839
88227:M 03 May 2025 23:04:19.473 - Accepting cluster node connection from 127.0.0.1:59843
88227:M 03 May 2025 23:04:19.489 # Missing implement of connection type tls
88227:M 03 May 2025 23:04:19.544 - Accepting cluster node connection from 127.0.0.1:59849
88227:M 03 May 2025 23:04:19.568 - Accepting cluster node connection from 127.0.0.1:59850
88227:M 03 May 2025 23:04:20.356 * Node 9bef15b514b96cb4317017ff68ef58f60226bd1e () is no longer primary of shard 5d248352c80d71d4de724058d94e52d31c560130; removed all 0 slot(s) it used to own
88227:M 03 May 2025 23:04:20.356 * Node 9bef15b514b96cb4317017ff68ef58f60226bd1e () is now part of shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
88227:M 03 May 2025 23:04:20.356 * Node 9bef15b514b96cb4317017ff68ef58f60226bd1e () is now a replica of node 3343572579e378b54df1fb6850be8be76dd46e6a () in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
88227:M 03 May 2025 23:04:20.356 * Node c9185f683876252cbd80739f3a7e87a75c65090b () is no longer primary of shard a276c42d034322ac91d4a3be93243a40c26a9e39; removed all 0 slot(s) it used to own
88227:M 03 May 2025 23:04:20.356 * Node c9185f683876252cbd80739f3a7e87a75c65090b () is now part of shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
88227:M 03 May 2025 23:04:20.356 * Node c9185f683876252cbd80739f3a7e87a75c65090b () is now a replica of node 3343572579e378b54df1fb6850be8be76dd46e6a () in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
88227:M 03 May 2025 23:04:20.357 * Node 829dc125be5e6bed85216fa78b484311a004c590 () is no longer primary of shard d38b636bcfdfe2e0852878f99c6af0c6c58309b1; removed all 0 slot(s) it used to own
88227:M 03 May 2025 23:04:20.357 * Node 829dc125be5e6bed85216fa78b484311a004c590 () is now part of shard 8028c9ca458f8215491dd1a9694897a34d78f998
88227:M 03 May 2025 23:04:20.357 * Node 829dc125be5e6bed85216fa78b484311a004c590 () is now a replica of node 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 () in shard 8028c9ca458f8215491dd1a9694897a34d78f998
88227:M 03 May 2025 23:04:20.357 - Accepted 127.0.0.1:59892
88227:M 03 May 2025 23:04:20.358 * Node f848f8f2426110f2aa02d85bc35109efb050ee1c () is no longer primary of shard 79bbcf1834b8414fc6b9bc6ccee1db0d26f47001; removed all 0 slot(s) it used to own
88227:M 03 May 2025 23:04:20.358 * Node f848f8f2426110f2aa02d85bc35109efb050ee1c () is now part of shard 882eb57d01abe0fa09cac5f80857f74f4bbb4591
88227:M 03 May 2025 23:04:20.358 * Node f848f8f2426110f2aa02d85bc35109efb050ee1c () is now a replica of node 33dca58967ea807f71054db92c9bae8edb838d1a () in shard 882eb57d01abe0fa09cac5f80857f74f4bbb4591
88227:M 03 May 2025 23:04:20.358 * Replica 127.0.0.1:22617 asks for synchronization
88227:M 03 May 2025 23:04:20.358 * Full resync requested by replica 127.0.0.1:22617
88227:M 03 May 2025 23:04:20.358 * Replication backlog created, my new replication IDs are 'db50a446faa69161996f616e392a37fc535ae5b4' and '0000000000000000000000000000000000000000'
88227:M 03 May 2025 23:04:20.358 * Starting BGSAVE for SYNC with target: replicas sockets using: normal sync
88227:M 03 May 2025 23:04:20.359 * Background RDB transfer started by pid 88514 to pipe through parent process
88514:C 03 May 2025 23:04:20.359 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
88227:M 03 May 2025 23:04:20.361 * Diskless rdb transfer, done reading from pipe, 1 replicas still up.
88227:M 03 May 2025 23:04:20.361 # DEBUG LOG: ========== I am primary 2 ==========
88227:M 03 May 2025 23:04:20.367 * Background RDB transfer terminated with success
88227:M 03 May 2025 23:04:20.367 * Streamed RDB transfer with replica 127.0.0.1:22617 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming
88227:M 03 May 2025 23:04:20.367 * Synchronization with replica 127.0.0.1:22617 succeeded
88227:M 03 May 2025 23:04:20.700 * Cluster state changed: ok
### Starting test Cluster is up in tests/unit/cluster/failover2.tcl
### Starting test Cluster is writable in tests/unit/cluster/failover2.tcl
88227:M 03 May 2025 23:04:30.180 - Accepted 127.0.0.1:60505
88227:M 03 May 2025 23:04:30.222 - Client closed connection id=28 addr=127.0.0.1:60505 laddr=127.0.0.1:22620 fd=28 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=30 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=get user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=2394 tot-net-out=1048 tot-cmds=60
### Starting test Killing one primary node in tests/unit/cluster/failover2.tcl
### Starting test Wait for failover in tests/unit/cluster/failover2.tcl
88227:M 03 May 2025 23:04:33.819 - DB 0: 30 keys (0 volatile) in 210 slots HT.
88227:M 03 May 2025 23:04:35.907 * Node 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 () reported node 3343572579e378b54df1fb6850be8be76dd46e6a () as not reachable.
88227:M 03 May 2025 23:04:35.907 * Marking node 3343572579e378b54df1fb6850be8be76dd46e6a () as failing (quorum reached).
88227:M 03 May 2025 23:04:35.907 # Cluster state changed: fail
88227:M 03 May 2025 23:04:35.907 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
88227:M 03 May 2025 23:04:36.625 * Failover auth granted to 9bef15b514b96cb4317017ff68ef58f60226bd1e () for epoch 7
88227:M 03 May 2025 23:04:36.686 * Cluster state changed: ok
### Starting test Killing the new primary node in tests/unit/cluster/failover2.tcl
88227:M 03 May 2025 23:04:36.717 * Node c9185f683876252cbd80739f3a7e87a75c65090b () is now a replica of node 9bef15b514b96cb4317017ff68ef58f60226bd1e () in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
### Starting test Cluster should eventually be up again in tests/unit/cluster/failover2.tcl
### Starting test wait for new failover in tests/unit/cluster/failover2.tcl
88227:M 03 May 2025 23:04:38.875 - DB 0: 30 keys (0 volatile) in 210 slots HT.
88227:M 03 May 2025 23:04:42.984 * FAIL message received from c9185f683876252cbd80739f3a7e87a75c65090b () about 9bef15b514b96cb4317017ff68ef58f60226bd1e ()
88227:M 03 May 2025 23:04:42.984 # Cluster state changed: fail
88227:M 03 May 2025 23:04:42.984 # Cluster is currently down: At least one hash slot is not served by any available node. Please check the 'cluster-require-full-coverage' configuration.
88227:M 03 May 2025 23:04:43.084 * Node 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 () reported node 9bef15b514b96cb4317017ff68ef58f60226bd1e () as not reachable.
88227:M 03 May 2025 23:04:43.821 * Failover auth granted to c9185f683876252cbd80739f3a7e87a75c65090b () for epoch 8
### Starting test Restarting the previously killed primary nodes in tests/unit/cluster/failover2.tcl
88227:M 03 May 2025 23:04:43.845 * Node c9185f683876252cbd80739f3a7e87a75c65090b () reported node 3343572579e378b54df1fb6850be8be76dd46e6a () as not reachable.
88227:M 03 May 2025 23:04:43.849 * Cluster state changed: ok
### Starting test Make sure there is no failover timeout in tests/unit/cluster/failover2.tcl
88227:M 03 May 2025 23:04:43.872 - Node 3343572579e378b54df1fb6850be8be76dd46e6a has old slots configuration, sending an UPDATE message about c9185f683876252cbd80739f3a7e87a75c65090b
88227:M 03 May 2025 23:04:43.872 - Node 9bef15b514b96cb4317017ff68ef58f60226bd1e has old slots configuration, sending an UPDATE message about c9185f683876252cbd80739f3a7e87a75c65090b
88227:M 03 May 2025 23:04:43.877 * Clear FAIL state for node 3343572579e378b54df1fb6850be8be76dd46e6a (): primary without slots is reachable again.
88227:M 03 May 2025 23:04:43.877 * A failover occurred in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf; node 3343572579e378b54df1fb6850be8be76dd46e6a () failed over to node 9bef15b514b96cb4317017ff68ef58f60226bd1e () with a config epoch of 7
88227:M 03 May 2025 23:04:43.877 * Node 3343572579e378b54df1fb6850be8be76dd46e6a () is now a replica of node 9bef15b514b96cb4317017ff68ef58f60226bd1e () in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
88227:M 03 May 2025 23:04:43.888 * Clear FAIL state for node 9bef15b514b96cb4317017ff68ef58f60226bd1e (): primary without slots is reachable again.
88227:M 03 May 2025 23:04:43.888 * A failover occurred in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf; node 9bef15b514b96cb4317017ff68ef58f60226bd1e () failed over to node c9185f683876252cbd80739f3a7e87a75c65090b () with a config epoch of 8
88227:M 03 May 2025 23:04:43.888 * Node 9bef15b514b96cb4317017ff68ef58f60226bd1e () is now a replica of node c9185f683876252cbd80739f3a7e87a75c65090b () in shard 5fb1baf6553ebed1d5b242d432fbdcc98ba4d9cf
### Starting test Check for memory leaks (pid 88302) in tests/unit/cluster/failover2.tcl
88227:M 03 May 2025 23:04:43.921 - DB 0: 30 keys (0 volatile) in 210 slots HT.
88227:M 03 May 2025 23:04:44.094 * Node 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 () reported node 3343572579e378b54df1fb6850be8be76dd46e6a () is back online.
88227:M 03 May 2025 23:04:45.004 * Node 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 () reported node 9bef15b514b96cb4317017ff68ef58f60226bd1e () is back online.
88227:M 03 May 2025 23:04:45.235 * Node c9185f683876252cbd80739f3a7e87a75c65090b () reported node 3343572579e378b54df1fb6850be8be76dd46e6a () is back online.
### Starting test Check for memory leaks (pid 88273) in tests/unit/cluster/failover2.tcl
88227:M 03 May 2025 23:04:45.842 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:45.943 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:46.044 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:46.145 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:46.246 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:46.347 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:46.448 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:46.549 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:46.650 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:46.751 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:46.851 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:46.952 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:47.004 - Client closed connection id=3 addr=127.0.0.1:59772 laddr=127.0.0.1:22620 fd=14 name= age=29 idle=11 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|info user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=1748 tot-net-out=60609 tot-cmds=59
88227:M 03 May 2025 23:04:47.053 - Connection with Node 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 at 127.0.0.1:32621 failed: Connection refused
88227:M 03 May 2025 23:04:47.053 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:47.154 - Connection with Node 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 at 127.0.0.1:32621 failed: Connection refused
88227:M 03 May 2025 23:04:47.154 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:47.255 - Connection with Node 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 at 127.0.0.1:32621 failed: Connection refused
88227:M 03 May 2025 23:04:47.255 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:47.355 - Connection with Node 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 at 127.0.0.1:32621 failed: Connection refused
88227:M 03 May 2025 23:04:47.355 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:M 03 May 2025 23:04:48.160 - Connection with Node 0b7cd61315bc35c311baf5d07a51f94c3b6b10d9 at 127.0.0.1:32621 failed: Connection refused
88227:M 03 May 2025 23:04:48.160 - Connection with Node 3343572579e378b54df1fb6850be8be76dd46e6a at 127.0.0.1:32622 failed: Connection refused
88227:signal-handler (1746281088) Received SIGTERM scheduling shutdown...
88227:M 03 May 2025 23:04:48.261 * User requested shutdown...
88227:M 03 May 2025 23:04:48.267 * 1 of 1 replicas are in sync when shutting down.
88227:M 03 May 2025 23:04:48.271 * Removing the pid file.
88227:M 03 May 2025 23:04:48.274 * Saving the cluster configuration file before exiting.
88227:M 03 May 2025 23:04:48.326 * Removing the unix socket file.
88227:M 03 May 2025 23:04:48.335 # Valkey is now ready to exit, bye bye...
