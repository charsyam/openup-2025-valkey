### Starting server for test 
98148:M 03 May 2025 23:05:41.752 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode
98148:M 03 May 2025 23:05:41.752 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo
98148:M 03 May 2025 23:05:41.752 * Valkey version=255.255.255, bits=64, commit=06ac4d81, modified=0, pid=98148, just started
98148:M 03 May 2025 23:05:41.752 * Configuration loaded
98148:M 03 May 2025 23:05:41.753 * Increased maximum number of open files to 10032 (it was originally set to 256).
98148:M 03 May 2025 23:05:41.756 * monotonic clock: POSIX clock_gettime
98148:M 03 May 2025 23:05:41.765 # Failed to write PID file: Permission denied
                .+^+.                                                
            .+#########+.                                            
        .+########+########+.           Valkey 255.255.255 (06ac4d81/0) 64 bit
    .+########+'     '+########+.                                    
 .########+'     .+.     '+########.    Running in cluster mode
 |####+'     .+#######+.     '+####|    Port: 28137
 |###|   .+###############+.   |###|    PID: 98148                     
 |###|   |#####*'' ''*#####|   |###|                                 
 |###|   |####'  .-.  '####|   |###|                                 
 |###|   |###(  (@@@)  )###|   |###|          https://valkey.io      
 |###|   |####.  '-'  .####|   |###|                                 
 |###|   |#####*.   .*#####|   |###|                                 
 |###|   '+#####|   |#####+'   |###|                                 
 |####+.     +##|   |#+'     .+####|                                 
 '#######+   |##|        .+########'                                 
    '+###|   |##|    .+########+'                                    
        '|   |####+########+'                                        
             +#########+'                                            
                '+v+'                                                

98148:M 03 May 2025 23:05:41.766 # WARNING: The TCP backlog setting of 511 cannot be enforced because kern.ipc.somaxconn is set to the lower value of 128.
98148:M 03 May 2025 23:05:41.771 * No cluster configuration found, I'm dfc5ace834bf8709ce4d53628d62e169d0ad1cbb
98148:M 03 May 2025 23:05:41.795 * Server initialized
98148:M 03 May 2025 23:05:41.795 * Ready to accept connections tcp
98148:M 03 May 2025 23:05:41.795 * Ready to accept connections unix
98148:M 03 May 2025 23:05:41.894 - Accepted 127.0.0.1:57129
98148:M 03 May 2025 23:05:41.894 - Client closed connection id=2 addr=127.0.0.1:57129 laddr=127.0.0.1:28137 fd=14 name= age=0 idle=0 flags=N capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=33792 events=r cmd=ping user=default redir=-1 resp=2 lib-name= lib-ver= tot-net-in=7 tot-net-out=7 tot-cmds=1
98148:M 03 May 2025 23:05:41.900 - Accepted 127.0.0.1:57130
98148:M 03 May 2025 23:05:43.334 - Accepting cluster node connection from 127.0.0.1:57215
98148:M 03 May 2025 23:05:43.335 * IP address for this node updated to 127.0.0.1
98148:M 03 May 2025 23:05:43.499 - Accepting cluster node connection from 127.0.0.1:57240
98148:M 03 May 2025 23:05:43.510 - Accepting cluster node connection from 127.0.0.1:57251
98148:M 03 May 2025 23:05:43.549 - Accepting cluster node connection from 127.0.0.1:57254
98148:M 03 May 2025 23:05:43.551 - Accepting cluster node connection from 127.0.0.1:57260
98148:M 03 May 2025 23:05:43.578 - Accepting cluster node connection from 127.0.0.1:57275
98148:M 03 May 2025 23:05:43.580 * Successfully completed handshake with 2bb575c46a5d2a242b3ba5c0fb1c507d8182630a ()
98148:M 03 May 2025 23:05:43.583 * Successfully completed handshake with 3106074a164f0a44c70876cf0b52fdfc3ae1bc4f ()
98148:M 03 May 2025 23:05:43.786 # Missing implement of connection type tls
98148:S 03 May 2025 23:05:43.836 * Connecting to PRIMARY 127.0.0.1:28143
98148:S 03 May 2025 23:05:43.837 * PRIMARY <-> REPLICA sync started
98148:S 03 May 2025 23:05:43.839 * Cluster state changed: ok
98148:S 03 May 2025 23:05:43.840 * Node c8d15d16c89a26cb0ba936903cec1d0e9fd3e262 () is no longer primary of shard 540ff4f70b8a6955e8bec00e1d2e10520bf0ce5f; removed all 0 slot(s) it used to own
98148:S 03 May 2025 23:05:43.840 * Node c8d15d16c89a26cb0ba936903cec1d0e9fd3e262 () is now part of shard d8ca3ac7829db9ede2336486ae8d2e263bc8d04b
98148:S 03 May 2025 23:05:43.840 * Node c8d15d16c89a26cb0ba936903cec1d0e9fd3e262 () is now a replica of node d90aa247edd649ce1bf7ad48bef53f79c1c9f09f () in shard d8ca3ac7829db9ede2336486ae8d2e263bc8d04b
98148:S 03 May 2025 23:05:43.840 * Non blocking connect for SYNC fired the event.
98148:S 03 May 2025 23:05:43.842 * Primary replied to PING, replication can continue...
98148:S 03 May 2025 23:05:43.843 * Node 2bb575c46a5d2a242b3ba5c0fb1c507d8182630a () is no longer primary of shard 3d4c1a86b22a3df48f4611414955c484a68216cc; removed all 0 slot(s) it used to own
98148:S 03 May 2025 23:05:43.843 * Node 2bb575c46a5d2a242b3ba5c0fb1c507d8182630a () is now part of shard 0ca4bd28ec9160fa7de613682ce168931cc855bc
98148:S 03 May 2025 23:05:43.843 * Node 2bb575c46a5d2a242b3ba5c0fb1c507d8182630a () is now a replica of node 127dea3d74b3dab70fef165a86b9aeb1013b397c () in shard 0ca4bd28ec9160fa7de613682ce168931cc855bc
98148:S 03 May 2025 23:05:43.844 * Node 3106074a164f0a44c70876cf0b52fdfc3ae1bc4f () is no longer primary of shard 3b745b0d7b217589586affa823ba26bdb8a3eff7; removed all 0 slot(s) it used to own
98148:S 03 May 2025 23:05:43.844 * Node 3106074a164f0a44c70876cf0b52fdfc3ae1bc4f () is now part of shard d8ff73a3cba2685bb2e74df702707a7b692b4138
98148:S 03 May 2025 23:05:43.844 * Node 3106074a164f0a44c70876cf0b52fdfc3ae1bc4f () is now a replica of node 157e08adf87a6365c0d41f1f7a9ce1c8566bf971 () in shard d8ff73a3cba2685bb2e74df702707a7b692b4138
98148:S 03 May 2025 23:05:43.844 * Partial resynchronization not possible (no cached primary)
98148:S 03 May 2025 23:05:43.868 * Full resync from primary: 4b2146d4a76d886600708aa82859047bd713a489:0
98148:S 03 May 2025 23:05:43.868 # DEBUG LOG: ========== I am replica 6 ==========
98148:S 03 May 2025 23:05:43.869 * PRIMARY <-> REPLICA sync: receiving streamed RDB from primary with EOF to disk
98148:S 03 May 2025 23:05:43.872 * PRIMARY <-> REPLICA sync: Flushing old data
98148:S 03 May 2025 23:05:43.872 * PRIMARY <-> REPLICA sync: Loading DB in memory
98148:S 03 May 2025 23:05:43.872 * Loading RDB produced by Valkey version 255.255.255
98148:S 03 May 2025 23:05:43.872 * RDB age 0 seconds
98148:S 03 May 2025 23:05:43.872 * RDB memory usage when created 2.99 Mb
98148:S 03 May 2025 23:05:43.872 * Done loading RDB, keys loaded: 0, keys expired: 0.
98148:S 03 May 2025 23:05:43.872 * PRIMARY <-> REPLICA sync: Finished with success
### Starting test auto-failover-on-shutdown hands over primaryship to a fully sync'd replica - sigterm - shutdown-timeout: 0 in tests/unit/cluster/auto-failover-on-shutdown.tcl
98148:S 03 May 2025 23:05:54.706 * Forced failover primary request accepted (primary request from 'id=5 addr=127.0.0.1:28143 laddr=127.0.0.1:57330 fd=27 name= user=(superuser) lib-name= lib-ver=').
98148:S 03 May 2025 23:05:54.706 * Start of election delayed for 0 milliseconds (rank #0, primary rank #0, offset 451).
98148:S 03 May 2025 23:05:54.706 * Starting a failover election for epoch 7, node config epoch is 1
98148:S 03 May 2025 23:05:54.710 - Client closed connection id=5 addr=127.0.0.1:28143 laddr=127.0.0.1:57330 fd=27 name= age=11 idle=0 flags=M capa= db=0 sub=0 psub=0 ssub=0 multi=-1 watch=0 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=36 obl=0 oll=0 omem=0 tot-mem=18432 events=r cmd=cluster|failover user=(superuser) redir=-1 resp=2 lib-name= lib-ver= tot-net-in=451 tot-net-out=376 tot-cmds=13
98148:S 03 May 2025 23:05:54.711 * Connection with primary lost.
98148:S 03 May 2025 23:05:54.711 * Caching the disconnected primary state.
98148:S 03 May 2025 23:05:54.711 * Reconnecting to PRIMARY 127.0.0.1:28143
98148:S 03 May 2025 23:05:54.711 * PRIMARY <-> REPLICA sync started
98148:S 03 May 2025 23:05:54.714 # Error condition on socket for SYNC: Connection refused
98148:S 03 May 2025 23:05:54.717 * Currently unable to failover: Waiting for votes, but majority still not reached.
98148:S 03 May 2025 23:05:54.717 * Needed quorum: 2. Number of votes received so far: 1
98148:S 03 May 2025 23:05:54.720 * Failover election won: I'm the new primary.
98148:S 03 May 2025 23:05:54.720 * configEpoch set to 7 after successful failover
98148:S 03 May 2025 23:05:54.720 * Setting myself to primary in shard d8ca3ac7829db9ede2336486ae8d2e263bc8d04b after failover; my old primary is d90aa247edd649ce1bf7ad48bef53f79c1c9f09f ()
98148:M 03 May 2025 23:05:54.720 * Discarding previously cached primary state.
98148:M 03 May 2025 23:05:54.720 * Setting secondary replication ID to 4b2146d4a76d886600708aa82859047bd713a489, valid up to offset: 452. New replication ID is 64b40365d7cac04d2a0a8eab0be9d0e356cb3bdb
### Starting test Unable to find a replica to perform an auto failover - sigterm in tests/unit/cluster/auto-failover-on-shutdown.tcl
98148:M 03 May 2025 23:05:54.760 - Accepted 127.0.0.1:61514
98148:M 03 May 2025 23:05:54.760 - Connection with Node d90aa247edd649ce1bf7ad48bef53f79c1c9f09f at 127.0.0.1:38143 failed: Connection refused
98148:M 03 May 2025 23:05:54.774 * Node c8d15d16c89a26cb0ba936903cec1d0e9fd3e262 () is now a replica of node dfc5ace834bf8709ce4d53628d62e169d0ad1cbb () in shard d8ca3ac7829db9ede2336486ae8d2e263bc8d04b
98148:signal-handler (1746281154) Received SIGTERM scheduling shutdown...
98148:M 03 May 2025 23:05:54.861 * User requested shutdown...
98148:M 03 May 2025 23:05:54.861 * Removing the pid file.
98148:M 03 May 2025 23:05:54.861 * Unable to find a replica to perform the auto failover on shutdown.
98148:M 03 May 2025 23:05:54.861 * Saving the cluster configuration file before exiting.
98148:M 03 May 2025 23:05:54.897 * Removing the unix socket file.
98148:M 03 May 2025 23:05:54.899 # Valkey is now ready to exit, bye bye...
### Starting test Check for memory leaks (pid 98264) in tests/unit/cluster/auto-failover-on-shutdown.tcl
### Starting test Check for memory leaks (pid 98225) in tests/unit/cluster/auto-failover-on-shutdown.tcl
### Starting test Check for memory leaks (pid 98204) in tests/unit/cluster/auto-failover-on-shutdown.tcl
### Starting test Check for memory leaks (pid 98188) in tests/unit/cluster/auto-failover-on-shutdown.tcl
### Starting test Check for memory leaks (pid 98166) in tests/unit/cluster/auto-failover-on-shutdown.tcl
